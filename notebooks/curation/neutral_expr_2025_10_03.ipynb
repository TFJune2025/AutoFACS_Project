{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc4d287-c2df-4bcb-a6d6-0d5c08cd8987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total number of images found: 20334\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_images_in_folders(directory):\n",
    "    \"\"\"\n",
    "    Recursively counts image files in a given directory and its subdirectories.\n",
    "    \"\"\"\n",
    "    # A tuple of common image file extensions (case-insensitive)\n",
    "    image_extensions = ('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff', '.webp')\n",
    "    \n",
    "    image_count = 0\n",
    "    \n",
    "    # Check if the provided path is a valid directory\n",
    "    if not os.path.isdir(directory):\n",
    "        print(f\"Error: The path '{directory}' is not a valid directory.\")\n",
    "        return 0\n",
    "\n",
    "    # os.walk() efficiently traverses all directories and subdirectories\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check if the file ends with one of the image extensions\n",
    "            if file.lower().endswith(image_extensions):\n",
    "                image_count += 1\n",
    "                \n",
    "    return image_count\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "if __name__ == \"__main__\":\n",
    "    # ❗️ IMPORTANT: Change this to the path of your main folder!\n",
    "    folder_path = '/Users/natalyagrokh/AI/ml_expressions/img_datasets/ferckjalfag_dataset_full/hard_case'\n",
    "    \n",
    "    total_images = count_images_in_folders(folder_path)\n",
    "    \n",
    "    print(f\"✅ Total number of images found: {total_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9630a55e-adb1-4668-a36e-ae851868b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from google.api_core import client_options\n",
    "from google.api_core.client_options import ClientOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19b0b304-22d0-44b4-bbe5-ae3f8d47991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# Set your Google Cloud project details here.\n",
    "GCP_PROJECT_ID = \"mlexpimgsorting-v2\"  # Your new, working Project ID\n",
    "GCP_LOCATION = \"us-central1\"\n",
    "\n",
    "# This sets the specific environment variable the Google SDK requires\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"/Users/natalyagrokh/AI/img_curation/mlexpimgsorting-v2-c5a570b110c3.json\"\n",
    "\n",
    "DATASET_ROOT_DIR = Path(\"/Users/natalyagrokh/AI/ml_expressions/img_datasets/ferckjalfaga_dataset_adult\")\n",
    "OUTPUT_DIR = Path(\"/Users/natalyagrokh/AI/ml_expressions/img_datasets/inpained_neutral_speech\")\n",
    "TOTAL_SAMPLE_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b4cb72a-4ac9-4027-ad4c-64dac04104ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the Gemini 1.5 Pro model on Vertex AI to perform image inpainting.\n",
    "def perform_inpainting(image_path: Path, mask_path: Path, prompt: str, model: GenerativeModel):\n",
    "    \"\"\"Processes a single image and returns the inpainted image bytes or an error string.\"\"\"\n",
    "    try:\n",
    "        # Prepare the image and mask for the API call.\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            base_image_bytes = f.read()\n",
    "        with open(mask_path, \"rb\") as f:\n",
    "            mask_image_bytes = f.read()\n",
    "\n",
    "        base_image_part = Part.from_data(data=base_image_bytes, mime_type=\"image/jpeg\")\n",
    "        mask_image_part = Part.from_data(data=mask_image_bytes, mime_type=\"image/png\")\n",
    "\n",
    "        contents = [prompt, base_image_part, mask_image_part]\n",
    "\n",
    "        # Make the API call\n",
    "        response = model.generate_content(contents)\n",
    "\n",
    "        # Extract the generated image data\n",
    "        return response.candidates[0].content.parts[0].inline_data.data\n",
    "\n",
    "    except Exception as e:\n",
    "        # Return the error message if the API call fails\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f08cbc4-8196-4f3a-9387-8be2a27c73c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_samples(root_dir: Path, total_samples: int):\n",
    "    \"\"\"Scans subdirectories for images and returns a balanced, random sample.\"\"\"\n",
    "    images_by_category = defaultdict(list)\n",
    "    for filepath in root_dir.rglob(\"*.jpeg\"):\n",
    "        category = filepath.parent.name\n",
    "        images_by_category[category].append(filepath)\n",
    "\n",
    "    num_categories = len(images_by_category)\n",
    "    if num_categories == 0:\n",
    "        return []\n",
    "\n",
    "    samples_per_category = total_samples // num_categories\n",
    "    \n",
    "    sampled_files = []\n",
    "    for category, files in images_by_category.items():\n",
    "        num_to_sample = min(samples_per_category, len(files))\n",
    "        if num_to_sample > 0:\n",
    "            sampled_files.extend(random.sample(files, num_to_sample))\n",
    "            \n",
    "    return sampled_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "138da650-11ba-46a1-940e-02d735a2822a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transport' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m client_options_config \u001b[38;5;241m=\u001b[39m client_options\u001b[38;5;241m.\u001b[39mClientOptions(api_endpoint\u001b[38;5;241m=\u001b[39mapi_endpoint)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Define a transport with a 600-second (10-minute) timeout.\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m custom_transport \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241m.\u001b[39mgrpc\u001b[38;5;241m.\u001b[39mGenerativeServiceGrpcTransport(\n\u001b[1;32m     13\u001b[0m     client_options\u001b[38;5;241m=\u001b[39mclient_options_config,\n\u001b[1;32m     14\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600.0\u001b[39m \n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Initialize the model using the custom transport client.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m GenerativeModel(\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-2.5-pro\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m     transport\u001b[38;5;241m=\u001b[39mcustom_transport\n\u001b[1;32m     21\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transport' is not defined"
     ]
    }
   ],
   "source": [
    "# --- MAIN EXECUTION BLOCK ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Initialize the Vertex AI SDK.\n",
    "    vertexai.init(project=GCP_PROJECT_ID, location=GCP_LOCATION)\n",
    "    \n",
    "    # 2. Initialize the Model\n",
    "    # Create a custom client with a longer timeout.\n",
    "    api_endpoint = f\"{GCP_LOCATION}-aiplatform.googleapis.com\"\n",
    "    client_options_config = client_options.ClientOptions(api_endpoint=api_endpoint)\n",
    "    \n",
    "    # Define a transport with a 600-second (10-minute) timeout.\n",
    "    custom_transport = transport.grpc.GenerativeServiceGrpcTransport(\n",
    "        client_options=client_options_config,\n",
    "        timeout=600.0 \n",
    "    )\n",
    "    \n",
    "    # Initialize the model using the custom transport client.\n",
    "    model = GenerativeModel(\n",
    "        \"gemini-2.5-pro\",\n",
    "        transport=custom_transport\n",
    "    )\n",
    "    \n",
    "    OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "    \n",
    "    # 3. Get a sample of images to process\n",
    "    print(f\"Scanning for images in '{DATASET_ROOT_DIR}'...\")\n",
    "    image_samples = get_image_samples(DATASET_ROOT_DIR, TOTAL_SAMPLE_SIZE)\n",
    "    \n",
    "    if not image_samples:\n",
    "        print(\"No images found. Exiting.\")\n",
    "        exit()\n",
    "        \n",
    "    print(f\"Found and sampled {len(image_samples)} images for processing.\")\n",
    "\n",
    "    # 4. Define the mask and prompt\n",
    "    mask_path = Path(\"mask.png\")\n",
    "    prompt = \"Inpaint the masked area to remove the glasses, keeping the expression neutral.\"\n",
    "\n",
    "    if not mask_path.exists():\n",
    "        print(f\"Creating a dummy mask file at '{mask_path}'.\")\n",
    "        # ... (dummy mask creation code) ...\n",
    "        dummy_mask.save(mask_path)\n",
    "    \n",
    "    # 5. Loop through and process images\n",
    "    print(\"\\n--- Starting Inpainting Process ---\")\n",
    "    for image_path in tqdm(image_samples, desc=\"Inpainting Images\"):\n",
    "        result_data = perform_inpainting(image_path, mask_path, prompt, model)\n",
    "        \n",
    "        if isinstance(result_data, bytes):\n",
    "            relative_path = image_path.relative_to(DATASET_ROOT_DIR)\n",
    "            output_path = OUTPUT_DIR / relative_path\n",
    "            output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            with open(output_path, \"wb\") as f:\n",
    "                f.write(result_data)\n",
    "            # This print statement is removed from the loop to avoid clutter\n",
    "        else:\n",
    "            print(f\"FAILURE: Could not process {image_path.name}. Reason: {result_data}\")\n",
    "            \n",
    "    print(\"\\n--- Process Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4240d5f1-a129-4701-9dae-a07237591c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (img_curation_v3)",
   "language": "python",
   "name": "img_curation_v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
