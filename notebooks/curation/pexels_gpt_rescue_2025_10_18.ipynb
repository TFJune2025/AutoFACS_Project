{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f658f7-c3be-4667-9ee0-8b6f37d314c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Rescue partially cropped faces by tracing cropped filenames back to originals,\n",
    "re-detecting faces, and saving full, padded square crops with a `_rescued` suffix.\n",
    "\n",
    "Example:\n",
    "    python rescue_partial_faces.py \\\n",
    "        --bad_crops_dir /data/bad_crops \\\n",
    "        --originals_dir /data/originals \\\n",
    "        --output_dir /data/rescued \\\n",
    "        --yunet /models/face_detection_yunet_2023mar.onnx \\\n",
    "        --score_thresh 0.85 --margin 0.60\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93966124-5fa8-4198-9c07-5447ba13b54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob, argparse, json\n",
    "from typing import Optional, Tuple, List, Dict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "ALLOWED_EXTS = (\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac0aeaa-3381-4b21-93db-f2fd9a65b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Helpers: parsing & file lookup ----------\n",
    "\n",
    "def parse_root_and_index(cropped_filename: str) -> Tuple[str, Optional[int]]:\n",
    "    \"\"\"\n",
    "    Accepts names like:\n",
    "      image_66752_face_1.jpg\n",
    "      image_66752_face_1_padded.jpg\n",
    "      image_66752_face_1_rescued.jpg\n",
    "    Returns: (\"image_66752\", 1)\n",
    "    If no index, returns index=None.\n",
    "    \"\"\"\n",
    "    stem = os.path.splitext(os.path.basename(cropped_filename))[0]\n",
    "    stem = re.sub(r'_(padded|rescued)$', '', stem)   # strip trailing suffixes\n",
    "    m = re.match(r'^(.*)_face_(\\d+)$', stem)\n",
    "    if m:\n",
    "        return m.group(1), int(m.group(2))\n",
    "    # fallback: take everything before the first '_face_'\n",
    "    p = stem.split(\"_face_\")[0]\n",
    "    return p, None\n",
    "\n",
    "\n",
    "def find_original_by_root(root_id: str, originals_dir: str) -> Optional[str]:\n",
    "    \"\"\"Search recursively under originals_dir for an image whose basename is\n",
    "    exactly root_id (best), otherwise a basename that startswith(root_id).\"\"\"\n",
    "    # 1) exact basename match anywhere under originals_dir\n",
    "    for dirpath, _, filenames in os.walk(originals_dir):\n",
    "        for fn in filenames:\n",
    "            ext = os.path.splitext(fn.lower())[1]\n",
    "            if ext not in ALLOWED_EXTS:\n",
    "                continue\n",
    "            name = os.path.splitext(fn)[0]\n",
    "            if name == root_id:\n",
    "                return os.path.join(dirpath, fn)\n",
    "\n",
    "    # 2) fallback: prefix match (handles variants like image_66752_v2.jpg)\n",
    "    candidates = []\n",
    "    for dirpath, _, filenames in os.walk(originals_dir):\n",
    "        for fn in filenames:\n",
    "            ext = os.path.splitext(fn.lower())[1]\n",
    "            if ext not in ALLOWED_EXTS:\n",
    "                continue\n",
    "            name = os.path.splitext(fn)[0]\n",
    "            if name.startswith(root_id):\n",
    "                candidates.append(os.path.join(dirpath, fn))\n",
    "\n",
    "    if candidates:\n",
    "        # prefer the shortest basename (closest to exact), then lexicographic\n",
    "        candidates.sort(key=lambda p: (len(os.path.splitext(os.path.basename(p))[0]), p))\n",
    "        return candidates[0]\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# ---------- Helpers: geometry & cropping ----------\n",
    "\n",
    "def _expand_square_bbox_from_landmarks(landmarks, margin_ratio, img_w, img_h):\n",
    "    # landmarks: [x_r_eye, y_r_eye, x_l_eye, y_l_eye, x_nose, y_nose, x_r_mouth, y_r_mouth, x_l_mouth, y_l_mouth]\n",
    "    xs = landmarks[0::2]\n",
    "    ys = landmarks[1::2]\n",
    "    x_min, x_max = min(xs), max(xs)\n",
    "    y_min, y_max = min(ys), max(ys)\n",
    "    cx = (x_min + x_max) / 2.0\n",
    "    cy = (y_min + y_max) / 2.0\n",
    "    side = max(x_max - x_min, y_max - y_min)\n",
    "    side = int(round(side * (1.0 + margin_ratio)))\n",
    "    half = side // 2\n",
    "    x0 = int(round(cx - half))\n",
    "    y0 = int(round(cy - half))\n",
    "    return x0, y0, side, side\n",
    "\n",
    "\n",
    "def _safe_crop_with_padding(image, x, y, w, h, pad_mode=cv2.BORDER_REFLECT_101):\n",
    "    H, W = image.shape[:2]\n",
    "    left   = max(0, -x)\n",
    "    top    = max(0, -y)\n",
    "    right  = max(0, x + w - W)\n",
    "    bottom = max(0, y + h - H)\n",
    "    if any(v > 0 for v in (left, top, right, bottom)):\n",
    "        padded = cv2.copyMakeBorder(image, top, bottom, left, right, pad_mode)\n",
    "        x_p = x + left\n",
    "        y_p = y + top\n",
    "        return padded[y_p:y_p+h, x_p:x_p+w]\n",
    "    else:\n",
    "        return image[y:y+h, x:x+w]\n",
    "\n",
    "# ---------- Face detection & rescue ----------\n",
    "\n",
    "def make_yunet(model_path: str, score_thresh: float, nms_thresh: float, top_k: int):\n",
    "    det = cv2.FaceDetectorYN.create(\n",
    "        model=model_path,\n",
    "        config=\"\",\n",
    "        input_size=(320, 320),     # will be reset per image\n",
    "        score_threshold=score_thresh,\n",
    "        nms_threshold=nms_thresh,\n",
    "        top_k=top_k,\n",
    "    )\n",
    "    return det\n",
    "\n",
    "\n",
    "def redetect_and_save_all_faces_from_original(\n",
    "    original_img_path: str,\n",
    "    face_detector,\n",
    "    output_dir: str,\n",
    "    margin_ratio: float = 0.55,\n",
    "    min_side: int = 64,\n",
    ") -> List[str]:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    img = cv2.imread(original_img_path)\n",
    "    if img is None:\n",
    "        return []\n",
    "    H, W = img.shape[:2]\n",
    "    face_detector.setInputSize((W, H))\n",
    "    _, faces = face_detector.detect(img)\n",
    "    if faces is None or len(faces) == 0:\n",
    "        return []\n",
    "\n",
    "    saved = []\n",
    "    root = os.path.splitext(os.path.basename(original_img_path))[0]\n",
    "\n",
    "    for i, f in enumerate(faces):\n",
    "        box = list(map(int, f[:4]))\n",
    "        landmarks = list(map(int, f[4:14])) if len(f) >= 14 else []\n",
    "\n",
    "        # Landmark-first square; fallback to box-based expansion\n",
    "        if len(landmarks) >= 10:\n",
    "            x_sq, y_sq, w_sq, h_sq = _expand_square_bbox_from_landmarks(landmarks, margin_ratio, W, H)\n",
    "        else:\n",
    "            side = int(round(max(box[2], box[3]) * (1.0 + margin_ratio)))\n",
    "            cx = box[0] + box[2] // 2\n",
    "            cy = box[1] + box[3] // 2\n",
    "            x_sq = int(cx - side // 2); y_sq = int(cy - side // 2)\n",
    "            w_sq = h_sq = side\n",
    "\n",
    "        if min(w_sq, h_sq) < min_side:\n",
    "            continue\n",
    "\n",
    "        crop = _safe_crop_with_padding(img, x_sq, y_sq, w_sq, h_sq)\n",
    "        out_path = os.path.join(output_dir, f\"{root}_face_{i+1}_rescued.jpg\")\n",
    "        cv2.imwrite(out_path, crop)\n",
    "        saved.append(out_path)\n",
    "\n",
    "    return saved\n",
    "\n",
    "\n",
    "def rescue_from_bad_crops(\n",
    "    bad_crops_dir: str,\n",
    "    originals_dir: str,\n",
    "    output_dir: str,\n",
    "    face_detector,\n",
    "    margin_ratio: float = 0.55,\n",
    ") -> Dict[str, List[str]]:\n",
    "    \"\"\"Process each bad crop once by its root; redetect & save ALL faces from the original.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    bads = [os.path.join(bad_crops_dir, f) for f in os.listdir(bad_crops_dir)\n",
    "            if os.path.splitext(f.lower())[1] in ALLOWED_EXTS]\n",
    "    processed_roots = set()\n",
    "    rescued_index: Dict[str, List[str]] = {}\n",
    "\n",
    "    for path in sorted(bads):\n",
    "        root, _ = parse_root_and_index(path)\n",
    "        if root in processed_roots:\n",
    "            continue\n",
    "        orig = find_original_by_root(root, originals_dir)\n",
    "        if not orig:\n",
    "            # No original found; skip gracefully\n",
    "            processed_roots.add(root)\n",
    "            rescued_index[root] = []\n",
    "            continue\n",
    "\n",
    "        saved_paths = redetect_and_save_all_faces_from_original(\n",
    "            original_img_path=orig,\n",
    "            face_detector=face_detector,\n",
    "            output_dir=output_dir,\n",
    "            margin_ratio=margin_ratio,\n",
    "        )\n",
    "        processed_roots.add(root)\n",
    "        rescued_index[root] = saved_paths\n",
    "\n",
    "    return rescued_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e55de4-3d2d-43a4-a07a-00fbc3c3dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- JUPYTER NOTEBOOK ENTRYPOINT ----------\n",
    "\n",
    "def run_rescue(\n",
    "    bad_crops_dir: str,\n",
    "    originals_dir: str,\n",
    "    output_dir: str,\n",
    "    yunet_path: str,\n",
    "    score_thresh: float = 0.85,\n",
    "    nms_thresh: float = 0.3,\n",
    "    top_k: int = 5000,\n",
    "    margin: float = 0.60,\n",
    "    min_side: int = 64,\n",
    "    index_json: Optional[str] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run the rescue process inside Jupyter (no CLI parsing).\n",
    "    Returns a dict {root_id: [saved_paths]}.\n",
    "    \"\"\"\n",
    "    det = make_yunet(yunet_path, score_thresh, nms_thresh, top_k)\n",
    "\n",
    "    # patch in the min_side arg for convenience\n",
    "    global redetect_and_save_all_faces_from_original\n",
    "    orig_func = redetect_and_save_all_faces_from_original\n",
    "    def _wrapped_redetect(*fa, **fk):\n",
    "        fk.setdefault(\"min_side\", min_side)\n",
    "        return orig_func(*fa, **fk)\n",
    "    redetect_and_save_all_faces_from_original = _wrapped_redetect\n",
    "\n",
    "    rescued = rescue_from_bad_crops(\n",
    "        bad_crops_dir=bad_crops_dir,\n",
    "        originals_dir=originals_dir,\n",
    "        output_dir=output_dir,\n",
    "        face_detector=det,\n",
    "        margin_ratio=margin,\n",
    "    )\n",
    "\n",
    "    if index_json:\n",
    "        import json\n",
    "        with open(index_json, \"w\") as f:\n",
    "            json.dump(rescued, f, indent=2)\n",
    "\n",
    "    total = sum(len(v) for v in rescued.values())\n",
    "    print(f\"[Rescue] processed {len(rescued)} roots | saved {total} crops\")\n",
    "    return rescued"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_expressions_v5)",
   "language": "python",
   "name": "ml_expressions_v5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
