{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fac52904-736d-4077-8a86-187fbc9a09fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c959d25f-3803-4437-8dcc-1f27bf9a78a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# --- CONFIGURATION: UPDATE THESE PATHS ---\n",
    "# ==============================================================================\n",
    "# 1. Folder containing the original, full-sized images.\n",
    "ORIGINAL_IMAGES_FOLDER = \"/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/pexels_dataset_archive/pexels_scraped\"\n",
    "\n",
    "# 2. Folder containing the 1,400+ badly cropped face images.\n",
    "BAD_CROP_FOLDER = \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/pexels_dataset_archive/pexels_revisit\"\n",
    "\n",
    "# 3. Folder where the new, correctly cropped faces will be saved.\n",
    "RESCUED_FACES_FOLDER = \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/pexels_dataset_archive/gemini_rescue\"\n",
    "\n",
    "# 4. Path to the YuNet face detection model.\n",
    "YUNET_MODEL_PATH = \"face_detection_yunet_2023mar.onnx\"\n",
    "\n",
    "# --- TUNING PARAMETERS ---\n",
    "# Increases the crop area around the face. 0.35 means 35% padding on each side.\n",
    "PADDING_FACTOR = 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08a356e1-be9c-45f2-9b30-dfcab54b65dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# --- HELPER FUNCTIONS ---\n",
    "# ==============================================================================\n",
    "def find_source_image(base_filename, source_folder):\n",
    "    \"\"\"Searches for a source image with common extensions.\"\"\"\n",
    "    for ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']:\n",
    "        path = os.path.join(source_folder, base_filename + ext)\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    return None\n",
    "\n",
    "\n",
    "def create_source_image_map(source_folder):\n",
    "    \"\"\"Walks through all subdirectories to find image files and maps their base names to full paths.\"\"\"\n",
    "    image_map = {}\n",
    "    print(\"  Scanning source folder and all subdirectories for images...\")\n",
    "    # os.walk traverses the entire directory tree\n",
    "    for dirpath, _, filenames in tqdm(list(os.walk(source_folder)), desc=\"Mapping sources\"):\n",
    "        for f in filenames:\n",
    "            # Process only files with image extensions\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "                # Get filename without extension, e.g., 'image_123' from 'image_123.jpg'\n",
    "                base_name = os.path.splitext(f)[0]\n",
    "                # Store the full path for this base name\n",
    "                if base_name not in image_map:\n",
    "                    image_map[base_name] = os.path.join(dirpath, f)\n",
    "    print(f\"  Mapped {len(image_map)} unique source images.\")\n",
    "    return image_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f67baafd-b9c7-4d9b-acaf-1f72f8a605c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# --- UPDATED MAIN RESCUE LOGIC ---\n",
    "# ==============================================================================\n",
    "def rescue_improper_crops():\n",
    "    print(\"--- Starting Face Rescue Operation ---\")\n",
    "    \n",
    "    # --- Model and Folder Setup ---\n",
    "    if not os.path.exists(YUNET_MODEL_PATH):\n",
    "        print(f\"FATAL ERROR: Model file not found at '{YUNET_MODEL_PATH}'\")\n",
    "        sys.exit()\n",
    "\n",
    "    try:\n",
    "        face_detector = cv2.FaceDetectorYN.create(\n",
    "            model=YUNET_MODEL_PATH, config=\"\", input_size=(320, 320),\n",
    "            score_threshold=0.7\n",
    "        )\n",
    "        print(\"  Successfully initialized OpenCV FaceDetectorYN.\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Could not initialize the face detector. Error: {e}\")\n",
    "        sys.exit()\n",
    "\n",
    "    os.makedirs(RESCUED_FACES_FOLDER, exist_ok=True)\n",
    "\n",
    "    # --- Pre-scan and map all source images from the nested folders ---\n",
    "    source_image_map = create_source_image_map(ORIGINAL_IMAGES_FOLDER)\n",
    "\n",
    "    # --- Identify Unique Source Images to Process ---\n",
    "    bad_crop_files = os.listdir(BAD_CROP_FOLDER)\n",
    "    source_filenames_to_process = set()\n",
    "    for filename in bad_crop_files:\n",
    "        if '_face_' in filename:\n",
    "            base_name = filename.split('_face_')[0]\n",
    "            source_filenames_to_process.add(base_name)\n",
    "    \n",
    "    print(f\"  Found {len(source_filenames_to_process)} unique source images to re-process.\")\n",
    "\n",
    "    # --- Process Each Source Image ---\n",
    "    rescued_count = 0\n",
    "    for base_name in tqdm(list(source_filenames_to_process), desc=\"Rescuing faces\"):\n",
    "        # --- MODIFIED LINE: Use the map for a fast lookup instead of searching ---\n",
    "        source_image_path = source_image_map.get(base_name)\n",
    "        \n",
    "        if not source_image_path:\n",
    "            print(f\"\\n  WARNING: Could not find mapped source for '{base_name}'. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            image = cv2.imread(source_image_path)\n",
    "            if image is None: continue\n",
    "\n",
    "            img_height, img_width, _ = image.shape\n",
    "            face_detector.setInputSize((img_width, img_height))\n",
    "            _, faces = face_detector.detect(image)\n",
    "\n",
    "            if faces is not None:\n",
    "                for i, face_data in enumerate(faces):\n",
    "                    box = list(map(int, face_data[:4]))\n",
    "                    x, y, w, h = box\n",
    "                    \n",
    "                    pad_w = int(w * PADDING_FACTOR)\n",
    "                    pad_h = int(h * PADDING_FACTOR)\n",
    "                    \n",
    "                    x1 = max(0, x - pad_w)\n",
    "                    y1 = max(0, y - pad_h)\n",
    "                    x2 = min(img_width, x + w + pad_w)\n",
    "                    y2 = min(img_height, y + h + pad_h)\n",
    "                    \n",
    "                    rescued_crop = image[y1:y2, x1:x2]\n",
    "                    \n",
    "                    if rescued_crop.size > 0:\n",
    "                        output_filename = f\"{base_name}_face_{i+1}.jpg\"\n",
    "                        output_path = os.path.join(RESCUED_FACES_FOLDER, output_filename)\n",
    "                        cv2.imwrite(output_path, rescued_crop)\n",
    "                        rescued_count += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n  ERROR: Failed to process {source_image_path}: {e}\")\n",
    "\n",
    "    print(\"\\n--- Rescue Operation Complete ---\")\n",
    "    print(f\"  Successfully rescued and saved {rescued_count} faces to '{RESCUED_FACES_FOLDER}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c7477b-d030-4a9c-9418-cbfb6224d6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# --- EXECUTION BLOCK ---\n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    rescue_improper_crops()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_expressions_v5)",
   "language": "python",
   "name": "ml_expressions_v5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
