{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ad689-cdc5-4853-a902-ddbe8d5a6b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script is a test script connecting environment to google skd\n",
    "    # works on a dummy image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9630a55e-adb1-4668-a36e-ae851868b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19b0b304-22d0-44b4-bbe5-ae3f8d47991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# Set your Google Cloud project details here.\n",
    "GCP_PROJECT_ID = \"mlexpimgsorting-v2\"  # Your new, working Project ID\n",
    "GCP_LOCATION = \"us-central1\"\n",
    "\n",
    "# This sets the specific environment variable the Google SDK requires\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"/Users/natalyagrokh/AI/img_curation/mlexpimgsorting-v2-c5a570b110c3.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b4cb72a-4ac9-4027-ad4c-64dac04104ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the Gemini 1.5 Pro model on Vertex AI to perform image inpainting.\n",
    "\n",
    "def perform_inpainting(image_path: str, mask_path: str, prompt: str):\n",
    "    \n",
    "    print(f\"Starting inpainting process for: {image_path}\")\n",
    "\n",
    "    try:\n",
    "        # 1. Initialize the Vertex AI SDK with your project and location.\n",
    "        vertexai.init(project=GCP_PROJECT_ID, location=GCP_LOCATION)\n",
    "\n",
    "        # 2. Load the specific Gemini model from the initialized SDK.\n",
    "        # Note: The stable model name is \"gemini-1.5-pro-001\".\n",
    "        model = GenerativeModel(\"gemini-2.5-pro\")\n",
    "\n",
    "        # 3. Prepare the image and mask for the API call.\n",
    "        print(\"Loading image and mask files...\")\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            base_image_bytes = f.read()\n",
    "        \n",
    "        with open(mask_path, \"rb\") as f:\n",
    "            mask_image_bytes = f.read()\n",
    "        \n",
    "        base_image_part = Part.from_data(data=base_image_bytes, mime_type=\"image/png\")\n",
    "        mask_image_part = Part.from_data(data=mask_image_bytes, mime_type=\"image/png\")\n",
    "        \n",
    "        # 4. Construct the multimodal prompt using the correctly formatted parts.\n",
    "        contents = [prompt, base_image_part, mask_image_part]\n",
    "\n",
    "        # 5. Make the API call using the model object.\n",
    "        print(\"Sending request to Vertex AI API...\")\n",
    "        response = model.generate_content(contents)\n",
    "\n",
    "        print(\"Successfully received response from the model.\")\n",
    "        \n",
    "        # 6. Extract and save the generated image from the response.\n",
    "        0utput_image_bytes = response.candidates[0].content.parts[0].inline_data.data\n",
    "        with open(\"output_image.png\", \"wb\") as f:\n",
    "            f.write(output_image_bytes)\n",
    "        print(\"Saved generated image to output_image.png\")\n",
    "\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- An Error Occurred ---\")\n",
    "        print(f\"Error Type: {type(e).__name__}\")\n",
    "        print(f\"Error Details: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "138da650-11ba-46a1-940e-02d735a2822a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inpainting process for: face_image.png\n",
      "Loading image and mask files...\n",
      "Sending request to Vertex AI API...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalyagrokh/miniconda3/envs/img_curation_v3/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759493449.967962 1194559 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully received response from the model.\n",
      "Saved generated image to output_image.png\n",
      "\n",
      "--- Process Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- MAIN EXECUTION BLOCK ---\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Example Usage ---\n",
    "    # For inpainting, you need three things: the base image, a mask image,\n",
    "    # and a text prompt.\n",
    "    example_image_path = \"face_image.png\"\n",
    "    example_mask_path = \"mask.png\" # You will need to create this mask file.\n",
    "    example_prompt = \"This is an image of a person's face with a mask. Inpaint the masked area to remove the glasses, keeping the expression neutral.\"\n",
    "\n",
    "    # Create dummy files if they don't exist for demonstration.\n",
    "    if not os.path.exists(example_image_path):\n",
    "        print(f\"Creating a dummy image file at '{example_image_path}'.\")\n",
    "        dummy_image = Image.new('RGB', (100, 100), color='red')\n",
    "        dummy_image.save(example_image_path)\n",
    "\n",
    "    if not os.path.exists(example_mask_path):\n",
    "        print(f\"Creating a dummy mask file at '{example_mask_path}'.\")\n",
    "        # In a real scenario, the white area of the mask would cover the glasses.\n",
    "        dummy_mask = Image.new('RGB', (100, 100), color='black')\n",
    "        # For this dummy file, we'll make a white square in the middle.\n",
    "        for x in range(25, 75):\n",
    "            for y in range(25, 75):\n",
    "                dummy_mask.putpixel((x, y), (255, 255, 255))\n",
    "        dummy_mask.save(example_mask_path)\n",
    "\n",
    "    api_response = perform_inpainting(example_image_path, example_mask_path, example_prompt)\n",
    "\n",
    "    if api_response:\n",
    "        print(\"\\n--- Process Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4240d5f1-a129-4701-9dae-a07237591c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (img_curation_v3)",
   "language": "python",
   "name": "img_curation_v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
