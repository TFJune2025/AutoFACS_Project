{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64d0e707-26b6-415b-a17c-2078ec2e67cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "from PIL import Image, ImageFile\n",
    "import psutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38bc1938-8b60-47bb-aff0-a05dcd923867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Allow processing of large images\n",
    "Image.MAX_IMAGE_PIXELS = None  # Disable the decompression bomb limit\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True  # Allow loading truncated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "052754d9-7363-47ba-842d-af84d83ee6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset. Removed 0 unsupported files.\n"
     ]
    }
   ],
   "source": [
    "# use with new folders/files\n",
    "#Pre-filter Files Before Processing\n",
    "def clean_dataset(folder_path, valid_extensions=None):\n",
    "    if valid_extensions is None:\n",
    "        valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff'}\n",
    "    removed_files = 0\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if os.path.splitext(file)[1].lower() not in valid_extensions:\n",
    "                file_path = os.path.join(root, file)\n",
    "                os.remove(file_path)\n",
    "                removed_files += 1\n",
    "    print(f\"Cleaned dataset. Removed {removed_files} unsupported files.\")\n",
    "\n",
    "# Example usage\n",
    "clean_dataset(\"home/natalyagrokh/img_datasets/pexels_images_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a452aafb-39d4-4ff4-9473-096345c688ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Validate Image Files\n",
    "def is_valid_image(file_path):\n",
    "    try:\n",
    "        with Image.open(file_path) as img:\n",
    "            img.verify()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Invalid image {file_path}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a01b0186-7766-4cb1-8b48-ca35acf68e71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#batch processing function\n",
    "#batch processing function\n",
    "def process_in_batches(image_paths, batch_size, mtcnn, output_folder):\n",
    "    \"\"\"\n",
    "    Process images in batches, detecting and cropping faces.\n",
    "\n",
    "    Args:\n",
    "        image_paths (list): List of image file paths.\n",
    "        batch_size (int): Number of images to process per batch.\n",
    "        mtcnn (MTCNN): MTCNN face detection model.\n",
    "        output_folder (str): Path to the folder where cropped faces will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    processed_images = 0\n",
    "    errors = 0\n",
    "\n",
    "    for i in range(0, len(image_paths), batch_size):\n",
    "        batch = image_paths[i:i + batch_size]\n",
    "        for file_path in batch:\n",
    "            try:\n",
    "                # Open and validate image\n",
    "                with Image.open(file_path) as img:\n",
    "                    if img.size[0] * img.size[1] > 89478485:  # Check for oversized images\n",
    "                        print(f\"Skipping large image: {file_path}, size: {img.size[0]}x{img.size[1]}\")\n",
    "                        continue\n",
    "\n",
    "                if not is_valid_image(file_path):\n",
    "                    print(f\"Skipping invalid file: {file_path}\")\n",
    "                    continue\n",
    "\n",
    "                image = Image.open(file_path).convert(\"RGB\")\n",
    "                boxes, _ = mtcnn.detect(image)\n",
    "                if boxes is not None:\n",
    "                    for idx, box in enumerate(boxes):\n",
    "                        left, top, right, bottom = map(int, box)\n",
    "                        face = image.crop((left, top, right, bottom))\n",
    "                        output_path = os.path.join(output_folder, f\"{os.path.basename(file_path)}_face{idx+1}.jpg\")\n",
    "                        face.save(output_path)\n",
    "                processed_images += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                errors += 1\n",
    "                with open(\"error_log.txt\", \"a\") as log_file:\n",
    "                    log_file.write(f\"Error processing {file_path}: {e}\\n\")\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "        print(f\"Processed {len(batch)} images in batch. Total processed so far: {processed_images}. Errors: {errors}\")\n",
    "\n",
    "        # Monitor memory usage\n",
    "        memory_info = psutil.virtual_memory()\n",
    "        print(f\"Memory usage: {memory_info.percent}%\")\n",
    "        if memory_info.percent > 90:\n",
    "            print(\"High memory usage detected. Pausing for 30 seconds.\")\n",
    "            time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2206997-a197-4704-b9b4-4fb694724368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Face Cropping Function\n",
    "def crop_and_save_faces(input_folder, output_folder, batch_size=25):\n",
    "    \"\"\"\n",
    "    Detect and crop faces from images in a folder.\n",
    "\n",
    "    Args:\n",
    "        input_folder (str): Path to the folder containing input images.\n",
    "        output_folder (str): Path to the folder where cropped faces will be saved.\n",
    "        batch_size (int): Number of images to process per batch.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    mtcnn = MTCNN(keep_all=True, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Gather all image paths\n",
    "    image_paths = [\n",
    "        os.path.join(root, file)\n",
    "        for root, _, files in os.walk(input_folder)\n",
    "        for file in files if is_valid_image(os.path.join(root, file))\n",
    "    ]\n",
    "    print(f\"Total images found: {len(image_paths)}\")\n",
    "\n",
    "    process_in_batches(image_paths, batch_size, mtcnn, output_folder)\n",
    "    print(\"Face cropping complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dd9c4c2-6199-46ba-b822-ffdd1dd65e64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resource Monitoring\n",
    "def monitor_resources():\n",
    "    print(f\"CPU usage: {psutil.cpu_percent()}%\")\n",
    "    print(f\"Memory usage: {psutil.virtual_memory().percent}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b94d414-60ba-40bb-8523-57612a0db70e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images found: 4051\n",
      "Processed 25 images in batch. Total processed so far: 25. Errors: 0\n",
      "Memory usage: 31.1%\n",
      "Processed 25 images in batch. Total processed so far: 50. Errors: 0\n",
      "Memory usage: 29.3%\n",
      "Processed 25 images in batch. Total processed so far: 75. Errors: 0\n",
      "Memory usage: 29.7%\n",
      "Processed 25 images in batch. Total processed so far: 100. Errors: 0\n",
      "Memory usage: 30.1%\n",
      "Skipping large image: /home/natalyagrokh/img_datasets/temp_scraped_images/flickr_images_1/image_12843.jpg, size: 15370x10639\n",
      "Processed 25 images in batch. Total processed so far: 124. Errors: 0\n",
      "Memory usage: 29.2%\n",
      "Processed 25 images in batch. Total processed so far: 149. Errors: 0\n",
      "Memory usage: 29.4%\n",
      "Processed 25 images in batch. Total processed so far: 174. Errors: 0\n",
      "Memory usage: 29.2%\n",
      "Processed 25 images in batch. Total processed so far: 199. Errors: 0\n",
      "Memory usage: 29.4%\n",
      "Skipping large image: /home/natalyagrokh/img_datasets/temp_scraped_images/flickr_images_1/image_15651.jpg, size: 15370x10639\n",
      "Processed 25 images in batch. Total processed so far: 223. Errors: 0\n",
      "Memory usage: 29.8%\n",
      "Processed 25 images in batch. Total processed so far: 248. Errors: 0\n",
      "Memory usage: 30.9%\n",
      "Skipping large image: /home/natalyagrokh/img_datasets/temp_scraped_images/flickr_images_1/image_12437.jpg, size: 15370x10639\n",
      "Processed 25 images in batch. Total processed so far: 272. Errors: 0\n",
      "Memory usage: 29.7%\n",
      "Processed 25 images in batch. Total processed so far: 297. Errors: 0\n",
      "Memory usage: 29.3%\n",
      "Skipping large image: /home/natalyagrokh/img_datasets/temp_scraped_images/flickr_images_1/image_17755.jpg, size: 10608x10639\n",
      "Processed 25 images in batch. Total processed so far: 321. Errors: 0\n",
      "Memory usage: 31.3%\n",
      "Skipping large image: /home/natalyagrokh/img_datasets/temp_scraped_images/flickr_images_1/image_15952.jpg, size: 10608x10639\n",
      "Processed 25 images in batch. Total processed so far: 345. Errors: 0\n",
      "Memory usage: 29.5%\n",
      "Skipping large image: /home/natalyagrokh/img_datasets/temp_scraped_images/flickr_images_1/image_18055.jpg, size: 10608x10639\n",
      "Processed 25 images in batch. Total processed so far: 369. Errors: 0\n",
      "Memory usage: 31.4%\n",
      "Processed 25 images in batch. Total processed so far: 394. Errors: 0\n",
      "Memory usage: 29.5%\n",
      "Processed 25 images in batch. Total processed so far: 419. Errors: 0\n",
      "Memory usage: 29.6%\n",
      "Processed 25 images in batch. Total processed so far: 444. Errors: 0\n",
      "Memory usage: 30.1%\n",
      "Processed 25 images in batch. Total processed so far: 469. Errors: 0\n",
      "Memory usage: 30.2%\n",
      "Processed 25 images in batch. Total processed so far: 494. Errors: 0\n",
      "Memory usage: 29.9%\n",
      "Skipping large image: /home/natalyagrokh/img_datasets/temp_scraped_images/flickr_images_1/image_15250.jpg, size: 10608x10639\n",
      "Processed 25 images in batch. Total processed so far: 518. Errors: 0\n",
      "Memory usage: 30.3%\n",
      "Processed 25 images in batch. Total processed so far: 543. Errors: 0\n",
      "Memory usage: 30.2%\n",
      "Processed 25 images in batch. Total processed so far: 568. Errors: 0\n",
      "Memory usage: 30.8%\n",
      "Processed 25 images in batch. Total processed so far: 593. Errors: 0\n",
      "Memory usage: 30.6%\n",
      "Processed 25 images in batch. Total processed so far: 618. Errors: 0\n",
      "Memory usage: 30.2%\n",
      "Skipping large image: /home/natalyagrokh/img_datasets/temp_scraped_images/flickr_images_1/image_14648.jpg, size: 17767x10639\n",
      "Processed 25 images in batch. Total processed so far: 642. Errors: 0\n",
      "Memory usage: 30.6%\n",
      "Processed 25 images in batch. Total processed so far: 667. Errors: 0\n",
      "Memory usage: 30.6%\n",
      "Processed 25 images in batch. Total processed so far: 692. Errors: 0\n",
      "Memory usage: 31.1%\n",
      "Processed 25 images in batch. Total processed so far: 717. Errors: 0\n",
      "Memory usage: 30.6%\n",
      "Processed 25 images in batch. Total processed so far: 742. Errors: 0\n",
      "Memory usage: 30.3%\n",
      "Processed 25 images in batch. Total processed so far: 767. Errors: 0\n",
      "Memory usage: 30.4%\n",
      "Skipping large image: /home/natalyagrokh/img_datasets/temp_scraped_images/flickr_images_1/image_18456.jpg, size: 10608x10639\n",
      "Processed 25 images in batch. Total processed so far: 791. Errors: 0\n",
      "Memory usage: 30.4%\n",
      "Processed 25 images in batch. Total processed so far: 816. Errors: 0\n",
      "Memory usage: 30.6%\n",
      "Skipping large image: /home/natalyagrokh/img_datasets/temp_scraped_images/flickr_images_1/image_34297.jpg, size: 8593x10832\n",
      "Processed 25 images in batch. Total processed so far: 840. Errors: 0\n",
      "Memory usage: 30.3%\n",
      "Processed 25 images in batch. Total processed so far: 865. Errors: 0\n",
      "Memory usage: 30.3%\n",
      "Processed 25 images in batch. Total processed so far: 890. Errors: 0\n",
      "Memory usage: 30.7%\n",
      "Skipping large image: /home/natalyagrokh/img_datasets/temp_scraped_images/flickr_images_1/image_9532.jpg, size: 10608x10639\n",
      "Skipping large image: /home/natalyagrokh/img_datasets/temp_scraped_images/flickr_images_1/image_12542.jpg, size: 17767x10639\n",
      "Processed 25 images in batch. Total processed so far: 913. Errors: 0\n",
      "Memory usage: 30.2%\n",
      "Processed 25 images in batch. Total processed so far: 938. Errors: 0\n",
      "Memory usage: 30.5%\n",
      "Processed 25 images in batch. Total processed so far: 963. Errors: 0\n",
      "Memory usage: 30.7%\n",
      "Processed 25 images in batch. Total processed so far: 988. Errors: 0\n",
      "Memory usage: 30.2%\n",
      "Skipping large image: /home/natalyagrokh/img_datasets/temp_scraped_images/flickr_images_1/image_17855.jpg, size: 10608x10639\n",
      "Processed 25 images in batch. Total processed so far: 1012. Errors: 0\n",
      "Memory usage: 30.8%\n",
      "Processed 25 images in batch. Total processed so far: 1037. Errors: 0\n",
      "Memory usage: 30.5%\n",
      "Processed 25 images in batch. Total processed so far: 1062. Errors: 0\n",
      "Memory usage: 30.3%\n",
      "Processed 25 images in batch. Total processed so far: 1087. Errors: 0\n",
      "Memory usage: 30.3%\n",
      "Skipping large image: /home/natalyagrokh/img_datasets/temp_scraped_images/flickr_images_1/image_14350.jpg, size: 10608x10639\n",
      "Processed 25 images in batch. Total processed so far: 1111. Errors: 0\n",
      "Memory usage: 30.5%\n",
      "Processed 25 images in batch. Total processed so far: 1136. Errors: 0\n",
      "Memory usage: 30.4%\n",
      "Processed 25 images in batch. Total processed so far: 1161. Errors: 0\n",
      "Memory usage: 32.1%\n",
      "Processed 25 images in batch. Total processed so far: 1186. Errors: 0\n",
      "Memory usage: 30.2%\n",
      "Processed 25 images in batch. Total processed so far: 1211. Errors: 0\n",
      "Memory usage: 30.2%\n",
      "Skipping large image: /home/natalyagrokh/img_datasets/temp_scraped_images/flickr_images_1/image_15852.jpg, size: 10608x10639\n",
      "Processed 25 images in batch. Total processed so far: 1235. Errors: 0\n",
      "Memory usage: 30.7%\n",
      "Processed 25 images in batch. Total processed so far: 1260. Errors: 0\n",
      "Memory usage: 32.4%\n",
      "Processed 25 images in batch. Total processed so far: 1285. Errors: 0\n",
      "Memory usage: 30.4%\n",
      "Processed 25 images in batch. Total processed so far: 1310. Errors: 0\n",
      "Memory usage: 30.6%\n",
      "Processed 25 images in batch. Total processed so far: 1335. Errors: 0\n",
      "Memory usage: 31.4%\n",
      "Processed 25 images in batch. Total processed so far: 1360. Errors: 0\n",
      "Memory usage: 30.8%\n",
      "Processed 25 images in batch. Total processed so far: 1385. Errors: 0\n",
      "Memory usage: 30.6%\n",
      "Processed 25 images in batch. Total processed so far: 1410. Errors: 0\n",
      "Memory usage: 30.5%\n"
     ]
    }
   ],
   "source": [
    "# folder paths\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_FOLDER = \"/home/natalyagrokh/img_datasets/temp_scraped_images/flickr_images_1\"\n",
    "    OUTPUT_FOLDER = \"/home/natalyagrokh/img_datasets/curated_images/flickr_dataset_curatedr\"\n",
    "    BATCH_SIZE = 25\n",
    "\n",
    "    crop_and_save_faces(INPUT_FOLDER, OUTPUT_FOLDER, BATCH_SIZE)\n",
    "    \n",
    "# input_folder = \"/home/natalyagrokh/img_datasets/temp_scraped_images/flickr_images_1\"\n",
    "# output_folder = \"/home/natalyagrokh/img_datasets/curated_images/flickr_dataset_curated\"\n",
    "# crop_and_save_faces(input_folder, output_folder, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b7922-4eb5-4fd7-97b2-0ad28b0e61d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #works well on uncorrupted, true images\n",
    "# #runs into problems with corrupted or non-image files\n",
    "# #function filters high res imgs and crops out faces, saves faces only\n",
    "# def crop_and_save_faces(input_folder, output_folder):\n",
    "#     \"\"\"\n",
    "#     Detects faces in images, crops them, and saves them as individual files incrementally.\n",
    "#     Processes images one at a time to reduce memory usage.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - input_folder: Path to the folder containing input images.\n",
    "#     - output_folder: Path to save cropped face images.\n",
    "#     \"\"\"\n",
    "#     # Initialize MTCNN\n",
    "#     mtcnn = MTCNN(keep_all=True, device=\"cpu\")  # Use GPU if available\n",
    "\n",
    "#     # Ensure output folder exists\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "#     # Gather all image paths\n",
    "#     image_paths = []\n",
    "#     for root, _, files in os.walk(input_folder):\n",
    "#         for file in files:\n",
    "#             image_paths.append(os.path.join(root, file))\n",
    "\n",
    "#     total_images = len(image_paths)\n",
    "#     processed_images = 0\n",
    "#     errors = 0\n",
    "\n",
    "#     print(f\"Total images found: {total_images}\")\n",
    "\n",
    "#     for file_path in image_paths:\n",
    "#         try:\n",
    "#             # Open image\n",
    "#             image = Image.open(file_path).convert(\"RGB\")\n",
    "#             # Detect faces\n",
    "#             boxes, _ = mtcnn.detect(image)\n",
    "\n",
    "#             if boxes is not None:  # If faces are detected\n",
    "#                 for idx, box in enumerate(boxes):\n",
    "#                     # Crop and save each face\n",
    "#                     left, top, right, bottom = map(int, box)\n",
    "#                     face = image.crop((left, top, right, bottom))\n",
    "#                     output_path = os.path.join(output_folder, f\"{os.path.basename(file_path)}_face{idx+1}.jpg\")\n",
    "#                     face.save(output_path)\n",
    "#             processed_images += 1\n",
    "\n",
    "#             # Monitor memory usage\n",
    "#             memory_info = psutil.virtual_memory()\n",
    "#             if memory_info.percent > 90:  # If memory usage exceeds 90%, pause\n",
    "#                 print(\"High memory usage detected. Pausing for 30 seconds.\")\n",
    "#                 time.sleep(30)\n",
    "\n",
    "#         except Exception as e:\n",
    "#             errors += 1\n",
    "#             with open(\"error_log.txt\", \"a\") as log_file:\n",
    "#                 log_file.write(f\"Error processing {file_path}: {e}\\n\")\n",
    "#             print(f\"Error processing file {file_path}: {e}\")\n",
    "#             continue\n",
    "\n",
    "#         # Log progress every 100 images\n",
    "#         if processed_images % 100 == 0:\n",
    "#             print(f\"Processed {processed_images}/{total_images} images. Errors so far: {errors}\")\n",
    "\n",
    "#     print(f\"Processing complete. Total processed: {processed_images}. Total errors: {errors}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_expressions)",
   "language": "python",
   "name": "ml_expressions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
