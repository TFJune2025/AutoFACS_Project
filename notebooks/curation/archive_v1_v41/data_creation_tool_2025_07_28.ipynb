{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41f5dde-19de-4fef-b96c-e34e7a4539c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb79dff8-5860-47d5-b258-af45f2ab95bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. CONFIGURATION\n",
    "# ==============================================================================\n",
    "\n",
    "# --- IMPORTANT: Point this to the versioned folder from your last analysis run ---\n",
    "RUN_DIRECTORY = \"/Users/natalyagrokh/AI/ml_expressions/img_expressions/data_flywheel/V9_20250725_154347\"\n",
    "\n",
    "# Define the name for the new dataset folder\n",
    "OUTPUT_DATASET_NAME = \"CorrectionSet_V2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ce0ce3c-e18f-4082-af6f-8496ce3666ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 2. SCRIPT LOGIC\n",
    "# ==============================================================================\n",
    "\n",
    "# Reads manually curated log file and sorts reviewed images into \n",
    "    # binary classification dataset ('Emotion' vs. 'Non-Emotional_Action').\n",
    "def create_correction_dataset(run_dir, output_name):\n",
    "    # --- Setup Paths for BOTH review queues ---\n",
    "    micro_review_folder = os.path.join(run_dir, \"certainty_micro_expression_review\")\n",
    "    stable_review_folder = os.path.join(run_dir, \"certainty_stable_emotion_review\")\n",
    "    \n",
    "    micro_csv_path = os.path.join(micro_review_folder, \"simplified_review_log.csv\")\n",
    "    stable_csv_path = os.path.join(stable_review_folder, \"simplified_review_log.csv\")\n",
    "\n",
    "    output_dir = os.path.join(os.path.dirname(run_dir), output_name)\n",
    "    emotion_dir = os.path.join(output_dir, \"Emotion\")\n",
    "    action_dir = os.path.join(output_dir, \"Speech_Action\")\n",
    "\n",
    "    # Check if both required CSV files exist before proceeding\n",
    "    if not os.path.exists(micro_csv_path) or not os.path.exists(stable_csv_path):\n",
    "        print(f\"❌ Error: One or both review CSV files are missing.\")\n",
    "        if not os.path.exists(micro_csv_path):\n",
    "            print(f\"   - Missing: {micro_csv_path}\")\n",
    "        if not os.path.exists(stable_csv_path):\n",
    "            print(f\"   - Missing: {stable_csv_path}\")\n",
    "        return\n",
    "\n",
    "    # Create the new dataset directories\n",
    "    os.makedirs(emotion_dir, exist_ok=True)\n",
    "    os.makedirs(action_dir, exist_ok=True)\n",
    "    \n",
    "    # --- Load and Combine Both Curated CSVs ---\n",
    "    df_micro = pd.read_csv(micro_csv_path) if os.path.exists(micro_csv_path) else pd.DataFrame()\n",
    "    df_stable = pd.read_csv(stable_csv_path) if os.path.exists(stable_csv_path) else pd.DataFrame()\n",
    "    \n",
    "    combined_df = pd.concat([df_micro, df_stable]).drop_duplicates(subset=['face_crop_path']).reset_index(drop=True)\n",
    "    print(f\"✅ Loaded and combined both review logs. Total unique images to process: {len(combined_df)}\")\n",
    "\n",
    "    # --- Process and Sort Images ---\n",
    "    copied_count = 0\n",
    "    for _, row in tqdm(combined_df.iterrows(), total=combined_df.shape[0], desc=\"Sorting images\"):\n",
    "        actual_label = str(row.get('actual_label', '')).lower()\n",
    "        notes = str(row.get('notes', '')).lower()\n",
    "        \n",
    "        source_filename = row['face_crop_path']\n",
    "        # The source images could be in either review folder, so we check both.\n",
    "        source_path_micro = os.path.join(micro_review_folder, source_filename)    \n",
    "        source_path_stable = os.path.join(stable_review_folder, source_filename)\n",
    "        \n",
    "        source_path = source_path_micro if os.path.exists(source_path_micro) else source_path_stable\n",
    "        \n",
    "        if not os.path.exists(source_path):\n",
    "            print(f\"⚠️ Warning: Source image not found, skipping: {source_path}\")\n",
    "            continue\n",
    "\n",
    "        # --- The Sorting Logic ---\n",
    "        # If the actual_label is empty, it means the model was correct.\n",
    "        # This is a genuine, classifiable emotion.\n",
    "        if pd.isna(row.get('actual_label')) or row.get('actual_label') == '':\n",
    "             shutil.copy(source_path, emotion_dir)\n",
    "             copied_count += 1\n",
    "        # If your notes or labels indicate a non-emotional action, sort it accordingly.\n",
    "        elif any(keyword in actual_label for keyword in ['mid-speech', 'mid speech', 'laughter', 'mixed']):\n",
    "            shutil.copy(source_path, action_dir)\n",
    "            copied_count += 1\n",
    "        # Otherwise, it's a genuine emotion that was mislabeled by the original model.\n",
    "        else:\n",
    "            shutil.copy(source_path, emotion_dir)\n",
    "            copied_count += 1\n",
    "\n",
    "    print(f\"\\n✅ Success! Created the '{output_name}' dataset with {copied_count} images.\")\n",
    "    print(f\"   - Location: {output_dir}\")\n",
    "    print(f\"   - Emotion examples: {len(os.listdir(emotion_dir))}\")\n",
    "    print(f\"   - Speech Action examples: {len(os.listdir(action_dir))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83d604dd-5eb6-4f0b-8d93-271934646696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded and combined both review logs. Total unique images to process: 254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sorting images: 100%|███████████████████████| 254/254 [00:00<00:00, 1073.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Success! Created the 'CorrectionSet_V2' dataset with 254 images.\n",
      "   - Location: /Users/natalyagrokh/AI/ml_expressions/img_expressions/data_flywheel/CorrectionSet_V2\n",
      "   - Emotion examples: 107\n",
      "   - Speech Action examples: 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 3. MAIN EXECUTION BLOCK\n",
    "# ==============================================================================\n",
    "if __name__ == '__main__':\n",
    "    if not os.path.isdir(RUN_DIRECTORY):\n",
    "        print(f\"❌ Error: The specified RUN_DIRECTORY does not exist: {RUN_DIRECTORY}\")\n",
    "    else:\n",
    "        create_correction_dataset(\n",
    "            run_dir=RUN_DIRECTORY,\n",
    "            output_name=OUTPUT_DATASET_NAME\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cf4f22-9b0f-4d96-a01c-512659a9ef18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_expressions",
   "language": "python",
   "name": "ml_expressions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
