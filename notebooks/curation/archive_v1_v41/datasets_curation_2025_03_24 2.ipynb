{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7b05ecf-6efd-4a98-8813-aba9d1adcdf8",
   "metadata": {},
   "source": [
    "Adding the LFW headshots can be very useful, but there are some important considerations:\n",
    "\n",
    "1. **Improved Robustness:**  \n",
    "   - **Diverse, in‑the‑wild data** from LFW can help your model generalize better. Even if it doesn’t push accuracy to 100% on a controlled test set, it will likely perform more reliably on real-world images.\n",
    "   - More diversity in the training data often improves the model’s resilience to variations (lighting, pose, background) which is critical for deployment.\n",
    "\n",
    "2. **Accuracy Trade-Off:**  \n",
    "   - Achieving near 100% accuracy is rare, especially when you introduce challenging, \"wild\" images. Adding LFW may lower raw accuracy on a held‑out set (if that set is drawn from easier images), but it improves real-world performance.\n",
    "   - In other words, while your measured accuracy might drop compared to training only on controlled datasets, the model becomes more robust and practical.\n",
    "\n",
    "3. **Cost Efficiency:**  \n",
    "   - Manually sorting LFW headshots is a cost-effective way to expand your dataset rather than using more expensive GPU time for additional training iterations.\n",
    "   - More high-quality data can reduce the need for extensive hyperparameter tuning and retraining.\n",
    "\n",
    "### **Conclusion:**\n",
    "For money saving and to build a more robust model, it is **worth finishing the LFW sorting and integrating those photos** with your existing FERCKJA dataset. This will help your model learn a wider variety of facial expressions in different conditions, which is crucial for real-world performance—even if it might make near-perfect accuracy an unrealistic target.\n",
    "\n",
    "Would you like any further guidance on how to integrate and balance the datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e953d7ea-7ae5-4c20-995d-f12b5e076605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# --- Main Configuration ---\n",
    "INPUT_FOLDER = \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/pexels_dataset_archive/pexels_scraped\"\n",
    "OUTPUT_FOLDER = \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/pexels_dataset_archive/pexels_curated\"\n",
    "YUNET_MODEL_PATH = \"face_detection_yunet_2023mar.onnx\"\n",
    "MIN_WIDTH = 48\n",
    "MIN_HEIGHT = 48\n",
    "\n",
    "# ==============================================================================\n",
    "# STEP 1: Detect and Crop Faces using the High-Level FaceDetectorYN Class\n",
    "# ==============================================================================\n",
    "def crop_all_faces(input_folder, output_folder, model_path):\n",
    "    print(\"--- Starting Step 1: Face Detection and Cropping (CPU Mode) ---\")\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"FATAL ERROR: Model file not found at '{model_path}'\")\n",
    "        sys.exit()\n",
    "\n",
    "    # Initialize the high-level detector. It handles all the complexity internally.\n",
    "    try:\n",
    "        face_detector = cv2.FaceDetectorYN.create(\n",
    "            model=model_path,\n",
    "            config=\"\",\n",
    "            input_size=(320, 320), # The model will handle resizing internally\n",
    "            score_threshold=0.9\n",
    "        )\n",
    "        print(\"  Successfully initialized OpenCV FaceDetectorYN on CPU.\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Could not initialize the face detector. Error: {e}\")\n",
    "        sys.exit()\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    processed_files = 0\n",
    "    total_faces_found = 0\n",
    "\n",
    "    for dirpath, _, filenames in os.walk(input_folder):\n",
    "        for filename in filenames:\n",
    "            if not filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            \n",
    "            try:\n",
    "                image = cv2.imread(file_path)\n",
    "                if image is None:\n",
    "                    print(f\"  WARNING: Could not read image {filename}. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                height, width, _ = image.shape\n",
    "                # Set the detector's input size to the image's actual size for better accuracy\n",
    "                face_detector.setInputSize((width, height))\n",
    "\n",
    "                # The .detect() method handles everything: blob creation, forward pass, and post-processing\n",
    "                _, faces = face_detector.detect(image)\n",
    "                \n",
    "                # The result is None if no faces are found\n",
    "                if faces is not None:\n",
    "                    base_filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "                    for i, face_data in enumerate(faces):\n",
    "                        # Bounding box format is already [x, y, w, h]\n",
    "                        box = list(map(int, face_data[:4]))\n",
    "                        x, y, w, h = box\n",
    "                        \n",
    "                        if x >= 0 and y >= 0 and x + w <= width and y + h <= height:\n",
    "                            cropped_face = image[y:y+h, x:x+w]\n",
    "                            output_filename = f\"{base_filename}_face_{i+1}.jpg\"\n",
    "                            output_path = os.path.join(output_folder, output_filename)\n",
    "                            cv2.imwrite(output_path, cropped_face)\n",
    "                            total_faces_found += 1\n",
    "                \n",
    "                processed_files += 1\n",
    "                if processed_files % 100 == 0:\n",
    "                    print(f\"  Processed {processed_files} images...\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"  ERROR: An unexpected error occurred on {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "    print(f\"--- Step 1 Complete ---\")\n",
    "    print(f\"  Total source images processed: {processed_files}\")\n",
    "    print(f\"  Total faces found and saved: {total_faces_found}\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# (STEP 2 and 3 are unchanged)\n",
    "# ==============================================================================\n",
    "def remove_duplicate_faces(target_folder):\n",
    "    print(\"--- Starting Step 2: Removing Duplicate Faces ---\")\n",
    "    seen_files = {}\n",
    "    duplicates_to_remove = []\n",
    "    for root, _, files in os.walk(target_folder):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                file_size = os.path.getsize(file_path)\n",
    "                with open(file_path, \"rb\") as f:\n",
    "                    file_hash = hash(f.read())\n",
    "                if (file_size, file_hash) in seen_files:\n",
    "                    duplicates_to_remove.append(file_path)\n",
    "                else:\n",
    "                    seen_files[(file_size, file_hash)] = file_path\n",
    "            except Exception as e:\n",
    "                print(f\"Could not process {file_path} for duplicate check: {e}\")\n",
    "    if duplicates_to_remove:\n",
    "        print(f\"  Found {len(duplicates_to_remove)} duplicate images. Removing...\")\n",
    "        for dup_path in duplicates_to_remove:\n",
    "            try:\n",
    "                os.remove(dup_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to remove duplicate {dup_path}: {e}\")\n",
    "    else:\n",
    "        print(\"  No duplicate files were found.\")\n",
    "    print(f\"--- Step 2 Complete ---\\n\")\n",
    "\n",
    "def delete_small_images(target_folder, min_width, min_height):\n",
    "    print(f\"--- Starting Step 3: Deleting Images Smaller Than {min_width}x{min_height} ---\")\n",
    "    deleted_count = 0\n",
    "    for root, _, files in os.walk(target_folder):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                with Image.open(file_path) as img:\n",
    "                    width, height = img.size\n",
    "                    if width < min_width or height < min_height:\n",
    "                        img.close()\n",
    "                        os.remove(file_path)\n",
    "                        deleted_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path} for size check: {e}\")\n",
    "    if deleted_count > 0:\n",
    "        print(f\"  Deleted {deleted_count} images that were too small.\")\n",
    "    else:\n",
    "        print(\"  No images were smaller than the minimum size.\")\n",
    "    print(f\"--- Step 3 Complete ---\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if \"path/to/your\" in INPUT_FOLDER or \"path/to/your\" in OUTPUT_FOLDER:\n",
    "        print(\"Error: Please update the INPUT_FOLDER and OUTPUT_FOLDER variables at the top of the script before running.\")\n",
    "        sys.exit()\n",
    "\n",
    "    print(\"Starting Image Curation Pipeline...\")\n",
    "    print(\"===================================\")\n",
    "    \n",
    "    crop_all_faces(INPUT_FOLDER, OUTPUT_FOLDER, YUNET_MODEL_PATH)\n",
    "    remove_duplicate_faces(OUTPUT_FOLDER)\n",
    "    delete_small_images(OUTPUT_FOLDER, min_width=MIN_WIDTH, min_height=MIN_HEIGHT)\n",
    "    \n",
    "    print(\"===================================\")\n",
    "    print(\"Pipeline finished successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_expressions",
   "language": "python",
   "name": "ml_expressions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
