{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a2f98b6-211d-452f-af71-261e08cced7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from facenet_pytorch import MTCNN\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11addf66-3af9-4554-9fff-603156abace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function filters high res imgs and crops out faces, saves faces only\n",
    "#kills kernel b/c not enough RAM, process using GPU\n",
    "def crop_and_save_faces_batch(input_folder, output_folder, batch_size=10):\n",
    "    \"\"\"\n",
    "    Detects faces in images, crops them, and saves them as individual files in batches.\n",
    "    Includes error handling, progress saving, and logging.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_folder: Path to the folder containing input images.\n",
    "    - output_folder: Path to save cropped face images.\n",
    "    - batch_size: Number of images to process in one batch.\n",
    "    \"\"\"\n",
    "    # Initialize MTCNN\n",
    "    mtcnn = MTCNN(keep_all=True, device=\"cpu\")  # Use GPU if available\n",
    "\n",
    "    # Ensure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Gather all image paths\n",
    "    image_paths = []\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            image_paths.append(os.path.join(root, file))\n",
    "\n",
    "    total_images = len(image_paths)\n",
    "    processed_images = 0\n",
    "    errors = 0\n",
    "\n",
    "    print(f\"Total images found: {total_images}\")\n",
    "\n",
    "    # Process images in batches\n",
    "    for i in range(0, len(image_paths), batch_size):\n",
    "        batch_paths = image_paths[i:i + batch_size]\n",
    "\n",
    "        for file_path in batch_paths:\n",
    "            try:\n",
    "                # Open image\n",
    "                image = Image.open(file_path).convert(\"RGB\")\n",
    "                # Detect faces\n",
    "                boxes, _ = mtcnn.detect(image)\n",
    "\n",
    "                if boxes is not None:  # If faces are detected\n",
    "                    for idx, box in enumerate(boxes):\n",
    "                        # Crop and save each face\n",
    "                        left, top, right, bottom = map(int, box)\n",
    "                        face = image.crop((left, top, right, bottom))\n",
    "                        output_path = os.path.join(output_folder, f\"{os.path.basename(file_path)}_face{idx+1}.jpg\")\n",
    "                        face.save(output_path)\n",
    "                processed_images += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                errors += 1\n",
    "                with open(\"error_log.txt\", \"a\") as log_file:\n",
    "                    log_file.write(f\"Error processing {file_path}: {e}\\n\")\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Log progress\n",
    "        print(f\"Processed {processed_images}/{total_images} images. Errors so far: {errors}\")\n",
    "\n",
    "    print(f\"Processing complete. Total processed: {processed_images}. Total errors: {errors}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fb8623-5b7f-4121-b4aa-7b75295b68e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini dataset\n",
    "input_folder =  \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/mini_imgset\"\n",
    "output_folder = \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/mini_curated_dataset\"\n",
    "filtered_count = crop_and_save_faces_batch(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e52bcb8-92f6-48bd-a877-b707484c11b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function filters by face, discarding all others\n",
    "def filter_face_images(input_folder, output_folder, min_face_size=(50, 50)):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    total_images = 0\n",
    "    filtered_images = 0\n",
    "\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    # Read image\n",
    "                    img = cv2.imread(file_path)\n",
    "                    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    # Detect faces\n",
    "                    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=min_face_size)\n",
    "\n",
    "                    # If at least one face is detected, save the image to the output folder\n",
    "                    if len(faces) > 0:\n",
    "                        filtered_images += 1\n",
    "                        output_path = os.path.join(output_folder, file)\n",
    "                        Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)).save(output_path)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {file_path}: {e}\")\n",
    "                \n",
    "                total_images += 1\n",
    "\n",
    "    print(f\"Total images processed: {total_images}\")\n",
    "    print(f\"Filtered images with faces: {filtered_images}\")\n",
    "    return filtered_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fd263d5-6f3e-4023-9151-748bb482c031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function detects faces in (48,48) imgs\n",
    "def filter_low_res(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Filters images with faces for low-resolution images (e.g., 48x48).\n",
    "    Uses MTCNN for robust detection.\n",
    "\n",
    "    Parameters:\n",
    "    - input_folder: Path to the folder containing input images.\n",
    "    - output_folder: Path to save filtered images.\n",
    "    \"\"\"\n",
    "    # Initialize MTCNN\n",
    "    mtcnn = MTCNN(keep_all=True, device=\"cpu\")  # Use GPU if available\n",
    "    \n",
    "    # Ensure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    total_images = 0\n",
    "    filtered_images = 0\n",
    "\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            total_images += 1\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                # Open the image\n",
    "                image = Image.open(file_path).convert(\"RGB\")\n",
    "                # Temporarily resize to improve detection\n",
    "                resized_image = image.resize((256, 256))\n",
    "                # Detect faces\n",
    "                boxes, _ = mtcnn.detect(resized_image)\n",
    "                if boxes is not None:  # At least one face detected\n",
    "                    filtered_images += 1\n",
    "                    # Save the original image in output folder\n",
    "                    output_path = os.path.join(output_folder, file)\n",
    "                    image.save(output_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "    \n",
    "    print(f\"Total images processed: {total_images}\")\n",
    "    print(f\"Filtered images with faces: {filtered_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c1fcb7c-03f3-468a-91cb-c4e202619e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images processed: 981\n",
      "Filtered images with faces: 0\n"
     ]
    }
   ],
   "source": [
    "# ck_dataset\n",
    "input_folder = \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/ck_dataset\"\n",
    "output_folder = \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/filtered_ck_dataset\"\n",
    "filtered_count = filter_face_images(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6cf1db7-2b21-4698-9ba2-f3d05d37167c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images processed: 35887\n",
      "Filtered images with faces: 0\n"
     ]
    }
   ],
   "source": [
    "# fer_2013_dataset\n",
    "input_folder = \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/fer_2013_dataset\"\n",
    "output_folder = \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/filtered_fer_2013_dataset\"\n",
    "filtered_count = filter_face_images(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78efd87c-fa75-49dc-a859-248196f09e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images processed: 213\n",
      "Filtered images with faces: 213\n"
     ]
    }
   ],
   "source": [
    "# jaffe_dataset\n",
    "input_folder = \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/jaffe_dataset\"\n",
    "output_folder = \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/filtered_jaffe_dataset\"\n",
    "filtered_count = filter_face_images(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ab5e711-138a-4ef3-b88f-f4119d852f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images processed: 32203\n",
      "Filtered images with faces: 23085\n"
     ]
    }
   ],
   "source": [
    "# wider_face_dataset\n",
    "input_folder = \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/wider_face_dataset\"\n",
    "output_folder = \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/filtered_wider_face_dataset\"\n",
    "filtered_count = filter_face_images(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "736794d7-7373-4c44-9542-83cd92f49d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file .DS_Store: cannot identify image file '/Users/natalyagrokh/AI/ml_expressions/img_datasets/ck_dataset/.DS_Store'\n",
      "Error processing file 1.complete: cannot identify image file '/Users/natalyagrokh/AI/ml_expressions/img_datasets/ck_dataset/1.complete'\n",
      "Error processing file .DS_Store: cannot identify image file '/Users/natalyagrokh/AI/ml_expressions/img_datasets/ck_dataset/versions/.DS_Store'\n",
      "Error processing file .DS_Store: cannot identify image file '/Users/natalyagrokh/AI/ml_expressions/img_datasets/ck_dataset/versions/1/.DS_Store'\n",
      "Total images processed: 985\n",
      "Filtered images with faces: 981\n"
     ]
    }
   ],
   "source": [
    "# ck_dataset\n",
    "filter_low_res(\"/Users/natalyagrokh/AI/ml_expressions/img_datasets/ck_dataset\",\n",
    "               \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/filtered_ck_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe442e4a-9c2b-4863-a109-2ffbdc1ac781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ck_dataset - kills kernel b/c not enough RAM, processing on GPU best\n",
    "# filter_low_res(\"/Users/natalyagrokh/AI/ml_expressions/img_datasets/fer_2013_dataset\",\n",
    "#                 \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/filtered_fer_2013_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28603d0d-0c93-43cf-aa04-42aa9dc6d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wider_face_dataset\n",
    "input_folder = \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/wider_face_dataset\"\n",
    "output_folder = \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/filtered_wider_face_dataset\"\n",
    "crop_and_save_faces_batch(input_folder, output_folder, batch_size=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_expressions)",
   "language": "python",
   "name": "ml_expressions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
