{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68bb5294-3b07-43d6-b600-3485226991d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from facenet_pytorch import MTCNN\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
    "from torchvision import transforms as T\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff03b8e1-0da9-4d7d-a37a-750d1bd25d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 1. MTCNN Face Alignment\n",
    "# --------------------------\n",
    "mtcnn = MTCNN(image_size=224, post_process=True)\n",
    "\n",
    "def align_face(image):\n",
    "    aligned = mtcnn(image)\n",
    "    if aligned is None:\n",
    "        return image\n",
    "    return T.ToPILImage()(aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e02b0b-7461-4b11-876e-213cbcd3c853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Using model directory: /Users/natalyagrokh/AI/ml_expressions/img_expressions/V14_20250531_160421\n",
      "üå°Ô∏è Loaded precomputed temperature: 1.3240\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 2. Load and Apply Temperature Scaling\n",
    "# --------------------------\n",
    "\n",
    "mtcnn = MTCNN(image_size=224, post_process=True)\n",
    "\n",
    "def align_face(image):\n",
    "    aligned = mtcnn(image)\n",
    "    if aligned is None:\n",
    "        return image\n",
    "    return T.ToPILImage()(aligned)\n",
    "\n",
    "# Dynamically locate the most recent V*-tagged model directory\n",
    "MODEL_ROOT = \"/Users/natalyagrokh/AI/ml_expressions/img_expressions\"\n",
    "model_dirs = sorted(\n",
    "    [os.path.join(MODEL_ROOT, d) for d in os.listdir(MODEL_ROOT)\n",
    "     if d.startswith(\"V\") and os.path.isdir(os.path.join(MODEL_ROOT, d))],\n",
    "    key=lambda x: os.path.getmtime(x),\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "if not model_dirs:\n",
    "    raise FileNotFoundError(\"‚ùå No model directories found under MODEL_ROOT.\")\n",
    "\n",
    "latest_model_dir = model_dirs[0]\n",
    "print(f\"üìÅ Using model directory: {latest_model_dir}\")\n",
    "\n",
    "# Dynamically find logits and labels files inside latest directory\n",
    "logits_path = os.path.join(latest_model_dir, \"logits_eval_V14.npy\")\n",
    "labels_path = os.path.join(latest_model_dir, \"labels_eval_V14.npy\")\n",
    "\n",
    "try:\n",
    "    with open(os.path.join(latest_model_dir, \"temperature_V14.txt\")) as f:\n",
    "        TEMPERATURE = float(f.read().strip())\n",
    "    print(f\"üå°Ô∏è Loaded precomputed temperature: {TEMPERATURE:.4f}\")\n",
    "except Exception as e:\n",
    "    TEMPERATURE = 1.5  # üëà Recommended fallback for now\n",
    "    print(f\"‚ö†Ô∏è Could not load temperature. Using fallback: {TEMPERATURE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1a2269b-7011-4b7f-8ac0-fd18a6d937e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /Users/natalyagrokh/AI/ml_expressions/img_expressions/V14_20250531_160421 were not used when initializing ViTForImageClassification: ['classifier.1.bias', 'classifier.1.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at /Users/natalyagrokh/AI/ml_expressions/img_expressions/V14_20250531_160421 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Auto-loaded model from: /Users/natalyagrokh/AI/ml_expressions/img_expressions/V14_20250531_160421\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 3. Configuration\n",
    "# --------------------------\n",
    "\n",
    "model_path = model_dirs[0]\n",
    "print(f\"‚úÖ Auto-loaded model from: {model_path}\")\n",
    "\n",
    "# Load model and processor\n",
    "model = AutoModelForImageClassification.from_pretrained(model_path)\n",
    "processor = AutoImageProcessor.from_pretrained(model_path)\n",
    "\n",
    "BASE_CONFIDENCE_THRESHOLD = 0.35\n",
    "ENTROPY_THRESHOLD = 1.9\n",
    "MINORITY_CLASSES = {'disgust', 'fear', 'sadness'}\n",
    "MINORITY_CLASS_THRESHOLD = 0.38\n",
    "\n",
    "IMAGE_DIR = \"/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/celeba_dataset\"\n",
    "SORTED_OUTPUT_DIR = \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/celeba_dataset_sorted\"\n",
    "REVIEW_DIR = \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/celeba_dataset_tosort\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0f8e878-6d20-4403-96ea-5e1aac2a5a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --------------------------\n",
    "# # 1.5. GPU Environment Setup\n",
    "# # --------------------------\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Change this per parallel job (e.g., \"1\", \"2\", ...)\n",
    "# print(\"Process restricted to GPUs:\", os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "\n",
    "# # Optional: Monitor GPU usage\n",
    "# gpu_usage = subprocess.check_output([\"nvidia-smi\"]).decode(\"utf-8\")\n",
    "# print(\"Current GPU usage:\\n\", gpu_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45ee8490-9a2d-4d94-b914-a3e4a845ab05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using Apple M-series GPU (MPS backend).\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 4. Device Setup\n",
    "# --------------------------\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"‚úÖ Using Apple M-series GPU (MPS backend).\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"‚ö†Ô∏è MPS not available. Using CPU.\")\n",
    "\n",
    "model.to(device).eval()\n",
    "\n",
    "# Get label mapping\n",
    "id2label = model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dcf3487-0e06-4882-9fdd-83ac22d5c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 5. Prediction Function\n",
    "# --------------------------\n",
    "# def predict_label_with_confidence(image_path, topk=3):\n",
    "#     image = align_face(Image.open(image_path).convert(\"RGB\"))\n",
    "#     inputs = processor(image, return_tensors=\"pt\").to(model.device)\n",
    "#     with torch.no_grad():\n",
    "#         logits = model(**inputs).logits\n",
    "#         probs = F.softmax(logits / TEMPERATURE, dim=-1).squeeze()\n",
    "#         entropy = -torch.sum(probs * torch.log(probs + 1e-8)).item()\n",
    "#         top_probs, top_idxs = torch.topk(probs, topk)\n",
    "#     return [(id2label[i.item()], top_probs[i].item()) for i in range(topk)], entropy\n",
    "def predict_label_with_confidence(image_path, num_aug=3):\n",
    "    image = align_face(Image.open(image_path).convert(\"RGB\"))\n",
    "    aug = T.Compose([T.RandomHorizontalFlip(), T.ColorJitter(0.2, 0.2, 0.2)])\n",
    "\n",
    "    probs_all = []\n",
    "    for _ in range(num_aug):\n",
    "        aug_img = aug(image)\n",
    "        inputs = processor(aug_img, return_tensors=\"pt\").to(model.device)\n",
    "        logits = model(**inputs).logits\n",
    "        probs_all.append(F.softmax(logits / TEMPERATURE, dim=-1))\n",
    "\n",
    "    probs = torch.mean(torch.stack(probs_all), dim=0).squeeze()\n",
    "    entropy = -torch.sum(probs * torch.log(probs + 1e-8)).item()\n",
    "    conf, pred_idx = torch.max(probs, dim=-1)\n",
    "\n",
    "    return id2label[pred_idx.item()], conf.item(), entropy, probs\n",
    "\n",
    "# function aggregates predictions over multiple augmentations for each input\n",
    "def tta_inference(image, model, processor, device, N=5):\n",
    "    import torch.nn.functional as F\n",
    "    from torchvision import transforms as T\n",
    "\n",
    "    tta_transforms = [\n",
    "        T.Compose([]),  # original\n",
    "        T.Compose([T.RandomHorizontalFlip(p=1.0)]),\n",
    "        T.Compose([T.ColorJitter(0.3, 0.3, 0.3)]),\n",
    "        T.Compose([T.RandomRotation(10)]),\n",
    "        T.Compose([T.RandomResizedCrop(224, scale=(0.9, 1.0))]),\n",
    "    ]\n",
    "\n",
    "    probs_list = []\n",
    "    for t in tta_transforms:\n",
    "        img_aug = t(image)\n",
    "        inputs = processor(img_aug, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "            probs = F.softmax(logits / TEMPERATURE, dim=-1).cpu()\n",
    "        probs_list.append(probs)\n",
    "    probs_stack = torch.stack(probs_list, dim=0)\n",
    "    probs_mean = probs_stack.mean(dim=0).squeeze()\n",
    "    conf, pred_idx = torch.max(probs_mean, dim=-1)\n",
    "    entropy = -torch.sum(probs_mean * torch.log(probs_mean + 1e-8)).item()\n",
    "    return conf.item(), pred_idx.item(), entropy, probs_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5621960-26a7-45b4-916e-81ceeceefea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 6. Sorting Pipeline\n",
    "# --------------------------\n",
    "total_conf = 0.0\n",
    "total_entropy = 0.0\n",
    "num_samples = 0\n",
    "log_lines = []\n",
    "\n",
    "def sort_images():\n",
    "    global total_conf, total_entropy, num_samples  # Ensure global scope for tracking\n",
    "\n",
    "    os.makedirs(SORTED_OUTPUT_DIR, exist_ok=True)\n",
    "    os.makedirs(REVIEW_DIR, exist_ok=True)\n",
    "\n",
    "    valid_exts = {\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\"}\n",
    "    image_paths = [p for p in Path(IMAGE_DIR).rglob(\"*\") if p.suffix.lower() in valid_exts]\n",
    "\n",
    "    review_manifest, counts = [], Counter()\n",
    "\n",
    "    for img_path in tqdm(image_paths, desc=\"üîç Sorting images\"):\n",
    "        try:\n",
    "            label, conf, entropy, probs = predict_label_with_confidence(img_path)\n",
    "            top3 = [(id2label[i.item()], round(probs[i].item(), 3)) for i in torch.topk(probs, 3).indices]\n",
    "            log_line = f\"{str(img_path)} | pred={label} | conf={conf:.3f} | entropy={entropy:.3f} | top3={top3}\\n\"\n",
    "            log_lines.append(log_line)\n",
    "\n",
    "            num_samples += 1\n",
    "            total_conf += conf\n",
    "            total_entropy += entropy\n",
    "\n",
    "            threshold = MINORITY_CLASS_THRESHOLD if label in MINORITY_CLASSES else BASE_CONFIDENCE_THRESHOLD\n",
    "\n",
    "            if conf < 0.20 and entropy > 2.0:\n",
    "                reason = \"ood\"\n",
    "                label = \"unknown\"\n",
    "                dest_dir = os.path.join(REVIEW_DIR, \"unknown\")\n",
    "            elif conf < threshold or entropy > ENTROPY_THRESHOLD:\n",
    "                reason = \"thresholds\"\n",
    "                label = \"unknown\"\n",
    "                dest_dir = os.path.join(REVIEW_DIR, \"unknown\")\n",
    "            else:\n",
    "                reason = \"passed\"\n",
    "                dest_dir = os.path.join(SORTED_OUTPUT_DIR, label)\n",
    "\n",
    "            if reason != \"passed\":\n",
    "                review_manifest.append({\n",
    "                    \"file\": str(img_path),\n",
    "                    \"top3\": top3,\n",
    "                    \"confidence\": round(conf, 4),\n",
    "                    \"entropy\": round(entropy, 4),\n",
    "                    \"reason\": reason\n",
    "                })\n",
    "\n",
    "            os.makedirs(dest_dir, exist_ok=True)\n",
    "            shutil.copy2(img_path, os.path.join(dest_dir, os.path.basename(img_path)))\n",
    "            counts[label] += 1\n",
    "\n",
    "        except (UnidentifiedImageError, Exception) as e:\n",
    "            print(f\"‚ö†Ô∏è Error: {img_path} | {e}\")\n",
    "\n",
    "    with open(os.path.join(REVIEW_DIR, \"review_manifest.json\"), \"w\") as f:\n",
    "        json.dump(review_manifest, f, indent=2)\n",
    "\n",
    "    if num_samples > 0:\n",
    "        print(f\"\\nüìä Mean confidence: {total_conf / num_samples:.4f}\")\n",
    "        print(f\"üìä Mean entropy   : {total_entropy / num_samples:.4f}\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è No samples processed.\")\n",
    "\n",
    "    print(\"\\n‚úÖ Sorting complete.\")\n",
    "    print(\"üìä Image counts per class:\")\n",
    "    for label in sorted(counts):\n",
    "        print(f\"  {label:10s} : {counts[label]}\")\n",
    "\n",
    "    log_path = os.path.join(REVIEW_DIR, \"sorting_log.txt\")\n",
    "    with open(log_path, \"w\") as f:\n",
    "        f.writelines(log_lines)\n",
    "    print(f\"üìù Sorting log saved to: {log_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62a2713e-f636-456a-9bd5-233fb43101ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîç Sorting images:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 72223/101819 [3:48:00<1:50:36,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Error: /Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/celeba_dataset/172544.png | [Errno 28] No space left on device: '/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/celeba_dataset/172544.png' -> '/Users/natalyagrokh/AI/ml_expressions/img_datasets/celeba_dataset_tosort/unknown/172544.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîç Sorting images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101819/101819 [5:28:12<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Mean confidence: 0.1534\n",
      "üìä Mean entropy   : 2.1809\n",
      "\n",
      "‚úÖ Sorting complete.\n",
      "üìä Image counts per class:\n",
      "  unknown    : 101818\n",
      "üìù Sorting log saved to: /Users/natalyagrokh/AI/ml_expressions/img_datasets/celeba_dataset_tosort/sorting_log.txt\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 7. Run\n",
    "# --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    sort_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da9d5fb8-997b-46dc-8251-2de1da614d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 8. Visualization of Rejected Images (Post-Sorting)\n",
    "# --------------------------\n",
    "def visualize_rejected_review_images(manifest_path=None, max_images=25):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    if manifest_path is None:\n",
    "        manifest_path = os.path.join(REVIEW_DIR, \"review_manifest.json\")\n",
    "\n",
    "    if not os.path.exists(manifest_path):\n",
    "        print(f\"‚ö†Ô∏è No review manifest found at: {manifest_path}\")\n",
    "        return\n",
    "\n",
    "    with open(manifest_path) as f:\n",
    "        manifest = json.load(f)\n",
    "\n",
    "    print(f\"üñºÔ∏è Visualizing {min(len(manifest), max_images)} of {len(manifest)} rejected samples\")\n",
    "\n",
    "    for idx, entry in enumerate(manifest[:max_images]):\n",
    "        try:\n",
    "            img = Image.open(entry[\"file\"]).convert(\"RGB\")\n",
    "            plt.subplot(5, 5, idx + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(f\"{entry['top3'][0][0]}\\n{entry['confidence']:.2f}, {entry['entropy']:.2f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not open image {entry['file']}: {e}\")\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(REVIEW_DIR, \"rejected_grid.png\")\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    print(f\"üñºÔ∏è Saved rejected image grid to: {save_path}\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "691d10ed-e930-4cd4-8d97-cad358e226ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 9. Auto-Pseudo-Labeling Export\n",
    "# --------------------------\n",
    "def export_pseudo_labeled_images():\n",
    "    print(\"\\nüìÅ Exporting high-confidence CelebA images as pseudo-labels\")\n",
    "    pseudo_root = os.path.join(SORTED_OUTPUT_DIR, \"celeba_pseudo_labels\")\n",
    "    os.makedirs(pseudo_root, exist_ok=True)\n",
    "\n",
    "    for label in os.listdir(SORTED_OUTPUT_DIR):\n",
    "        label_dir = os.path.join(SORTED_OUTPUT_DIR, label)\n",
    "        if not os.path.isdir(label_dir) or label == \"celeba_pseudo_labels\":\n",
    "            continue\n",
    "        dest_dir = os.path.join(pseudo_root, label)\n",
    "        os.makedirs(dest_dir, exist_ok=True)\n",
    "        for img_file in os.listdir(label_dir):\n",
    "            if img_file.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".tif\")):\n",
    "                src = os.path.join(label_dir, img_file)\n",
    "                dst = os.path.join(dest_dir, img_file)\n",
    "                try:\n",
    "                    shutil.copy2(src, dst)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Skipping {src}: {e}\")\n",
    "    print(\"‚úÖ Pseudo-labeled CelebA export complete at:\", pseudo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7db10390-6f4a-4a8d-a66e-034c883b2103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîç Sorting images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101819/101819 [5:46:17<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Mean confidence: 0.1534\n",
      "üìä Mean entropy   : 2.1809\n",
      "\n",
      "‚úÖ Sorting complete.\n",
      "üìä Image counts per class:\n",
      "  unknown    : 101819\n",
      "üìù Sorting log saved to: /Users/natalyagrokh/AI/ml_expressions/img_datasets/celeba_dataset_tosort/sorting_log.txt\n",
      "üñºÔ∏è Visualizing 25 of 101819 rejected samples\n",
      "üñºÔ∏è Saved rejected image grid to: /Users/natalyagrokh/AI/ml_expressions/img_datasets/celeba_dataset_tosort/rejected_grid.png\n",
      "\n",
      "üìÅ Exporting high-confidence CelebA images as pseudo-labels\n",
      "‚úÖ Pseudo-labeled CelebA export complete at: /Users/natalyagrokh/AI/ml_expressions/img_datasets/celeba_dataset_sorted/celeba_pseudo_labels\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 10. Post-run Hook\n",
    "# --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    sort_images()\n",
    "    visualize_rejected_review_images()\n",
    "    export_pseudo_labeled_images()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_expressions)",
   "language": "python",
   "name": "ml_expressions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
