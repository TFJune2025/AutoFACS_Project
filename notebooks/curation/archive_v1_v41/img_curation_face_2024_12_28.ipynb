{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d0e707-26b6-415b-a17c-2078ec2e67cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79dc128a-e048-42a3-a711-60f10fd67fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-19 20:56:37.445255: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-19 20:56:40.079057: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/envs/ml_expressions/lib:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda-11.8/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.6/lib64\n",
      "2025-01-19 20:56:40.079260: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/envs/ml_expressions/lib:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda-11.8/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.6/lib64\n",
      "2025-01-19 20:56:40.079274: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.11.0\n",
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-19 20:56:42.369185: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-01-19 20:56:42.600999: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-01-19 20:56:42.604369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# Load YOLOv8 face detection model\n",
    "model = YOLO('yolov8n.pt')  # Replace with a face-specific model if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38bc1938-8b60-47bb-aff0-a05dcd923867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess the image\n",
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Prepares the image for YOLO face detection.\n",
    "    Parameters:\n",
    "    - image: Input image as a NumPy array.\n",
    "    Returns:\n",
    "    - The original image (YOLO handles resizing internally).\n",
    "    \"\"\"\n",
    "    return image  # YOLO handles preprocessing automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "052754d9-7363-47ba-842d-af84d83ee6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset. Removed 0 unsupported files.\n"
     ]
    }
   ],
   "source": [
    "# Function to check if an image contains a human face\n",
    "def has_human_face(image_path, confidence_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Detects if an image contains a human face using YOLOv8.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path: Path to the image file.\n",
    "    - confidence_threshold: Minimum confidence score for valid face detection.\n",
    "\n",
    "    Returns:\n",
    "    - True if a human face is detected with sufficient confidence, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = model.predict(image_path, conf=confidence_threshold, save=False)\n",
    "        return len(results[0].boxes) > 0  # Check if any bounding boxes were detected\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting face in {image_path}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a452aafb-39d4-4ff4-9473-096345c688ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Worker function for multiprocessing\n",
    "def worker(args):\n",
    "    file_path, input_folder, output_folder_faces, output_folder_non_faces, confidence_threshold = args\n",
    "    try:\n",
    "        image = cv2.imread(file_path)\n",
    "        if image is None:\n",
    "            return False  # Skip unreadable images\n",
    "\n",
    "        # Preprocess image\n",
    "        processed_image = preprocess_image(image)\n",
    "\n",
    "        # Check for human face\n",
    "        if has_human_face(file_path, confidence_threshold=confidence_threshold):\n",
    "            relative_path = os.path.relpath(file_path, input_folder)\n",
    "            output_path = os.path.join(output_folder_faces, relative_path)\n",
    "        else:\n",
    "            relative_path = os.path.relpath(file_path, input_folder)\n",
    "            output_path = os.path.join(output_folder_non_faces, relative_path)\n",
    "\n",
    "        # Save the image\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        cv2.imwrite(output_path, processed_image)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a01b0186-7766-4cb1-8b48-ca35acf68e71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Main function with batching\n",
    "def test_human_face_detection(input_folder, output_folder_faces, output_folder_non_faces, batch_size=500, confidence_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Processes all images in the input folder for human face detection.\n",
    "\n",
    "    Parameters:\n",
    "    - input_folder: Root folder of the input dataset.\n",
    "    - output_folder_faces: Folder for images detected as faces.\n",
    "    - output_folder_non_faces: Folder for images detected as non-faces.\n",
    "    - batch_size: Number of images to process before printing progress.\n",
    "    - confidence_threshold: Minimum confidence score for valid face detection.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder_faces, exist_ok=True)\n",
    "    os.makedirs(output_folder_non_faces, exist_ok=True)\n",
    "\n",
    "    image_paths = [\n",
    "        os.path.join(root, file)\n",
    "        for root, _, files in os.walk(input_folder)\n",
    "        for file in files\n",
    "    ]\n",
    "\n",
    "    total_images = len(image_paths)\n",
    "    kept_images = 0\n",
    "\n",
    "    # Process images in batches\n",
    "    for i in range(0, total_images, batch_size):\n",
    "        batch_paths = image_paths[i:i + batch_size]\n",
    "        args = [\n",
    "            (file_path, input_folder, output_folder_faces, output_folder_non_faces, confidence_threshold)\n",
    "            for file_path in batch_paths\n",
    "        ]\n",
    "\n",
    "        # Use multiprocessing for batch\n",
    "        with Pool(processes=4) as pool:\n",
    "            results = pool.map(worker, args)\n",
    "            kept_images += sum(results)\n",
    "\n",
    "        print(f\"Processed {min(i + batch_size, total_images)}/{total_images} images...\")\n",
    "\n",
    "    print(f\"Total images processed: {total_images}\")\n",
    "    print(f\"Images kept (faces): {kept_images}\")\n",
    "    print(f\"Images sorted as non-faces: {total_images - kept_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b7922-4eb5-4fd7-97b2-0ad28b0e61d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "input_folder = \"/home/natalyagrokh/img_datasets/test_images\"\n",
    "output_folder_faces = \"/home/natalyagrokh/img_datasets/combined_datasets_faces\"\n",
    "output_folder_non_faces = \"/home/natalyagrokh/img_datasets/combined_datasets_non_faces\"\n",
    "test_human_face_detection(input_folder, output_folder_faces, output_folder_non_faces, batch_size=500, confidence_threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
