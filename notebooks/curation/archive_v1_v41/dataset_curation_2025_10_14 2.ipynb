{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d03ba4e-718a-4b68-a5de-8001a0765f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Calibrate Stage 2 (scalar temperature on eval) --------------------------\n",
    "import json\n",
    "print(\"\\nðŸ§ª Calibrating Stage 2 (scalar T on eval set)...\")\n",
    "\n",
    "pred_eval = trainer_s2.predict(eval_dataset_s2)\n",
    "logits_s2_val = torch.from_numpy(pred_eval.predictions).to(device)   # [N, C]\n",
    "labels_s2_val = torch.from_numpy(pred_eval.label_ids).long().to(device)\n",
    "\n",
    "# If your S2 fitter takes (logits, labels), use it directly:\n",
    "T_s2 = fit_temperature(logits_s2_val, labels_s2_val)  # LBFGS-based; returns float\n",
    "\n",
    "# Save alongside the S2 export so inference can pick it up automatically\n",
    "s2_calib_path = os.path.join(SAVE_DIR, \"emotion_classifier_model\", \"stage2_calibration.json\")\n",
    "os.makedirs(os.path.dirname(s2_calib_path), exist_ok=True)\n",
    "with open(s2_calib_path, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"T\": float(max(1e-6, T_s2)),\n",
    "        \"val_size\": int(labels_s2_val.numel()),\n",
    "        \"notes\": \"Scalar temperature via NLL on eval; seed=42\"\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"âœ… S2 calibration done: T={T_s2:.3f} â†’ {s2_calib_path}\")\n",
    "\n",
    "# (Optional) if you want the final on-screen eval to reflect calibrated T:\n",
    "trainer_s2.compute_metrics = partial(\n",
    "    compute_metrics_with_confusion,\n",
    "    label_names=RELEVANT_CLASSES,\n",
    "    stage_name=\"Stage2\",\n",
    "    s2_temperature=float(T_s2),\n",
    ")\n",
    "_ = trainer_s2.evaluate(eval_dataset_s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57748442-e782-458c-8a9d-306ffd82e0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "V35 dataset preflight & curation helper (final, merged)\n",
    "------------------------------------------------------\n",
    "Automates 4 tasks before running V35 Stage-2 training:\n",
    "\n",
    "1) Shortlist parity check & regeneration from full inference log (thresholded by confidence).\n",
    "2) Patch-set assembly for fragile corridors (sadness/speech_action vs neutral_speech) using V34 artifacts,\n",
    "   with an integrated, safe \"top-up sadness\" step that prefers shortlist sources and falls back to full log.\n",
    "3) Label & file integrity checks (exists, readable image, label in RELEVANT_CLASSES).\n",
    "4) Split hygiene: ensure patch items are train-only (exclude any residing under eval_dir).\n",
    "\n",
    "Outputs:\n",
    "  - curation_shortlist_V35_auto.csv\n",
    "  - patch_V35.csv\n",
    "  - v35_prep_report.txt  (human-readable summary)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bab27d80-8479-4ff6-9ff8-c02909dc9db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# CONFIG\n",
    "# -----------------------------------------------------------------------------\n",
    "CONF_THRESHOLD = 0.85   # shortlist threshold\n",
    "RELEVANT_CLASSES = [\n",
    "    \"anger\",\"contempt\",\"disgust\",\"fear\",\"happiness\",\"neutral\",\n",
    "    \"questioning\",\"sadness\",\"surprise\",\"neutral_speech\",\"speech_action\"\n",
    "]\n",
    "\n",
    "# Your V35 run root (unchanged)\n",
    "V35_DIR = \"/Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V35_20251014_162112\"\n",
    "DATASET_ROOT = \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/ferckjalfaga_dataset_14_labels\"\n",
    "CONF_THRESHOLD = 0.85\n",
    "\n",
    "ARTIFACTS = {\n",
    "    \"full_inference\":  f\"{V35_DIR}/V35_full_inference_log.csv\",   # if not present, set to V34 log and note it\n",
    "    \"shortlist_auto\":  f\"{V35_DIR}/curation_shortlist_V36_auto.csv\",\n",
    "    \"shortlist_prev\":  f\"{V35_DIR}/curation_shortlist_V35.csv\",    # if absent, this will be skipped gracefully\n",
    "    \"patch\":           f\"{V35_DIR}/patch_V36.csv\"\n",
    "}\n",
    "\n",
    "# 1) Build shortlist from V35 full log (below threshold)\n",
    "n_short, n_total = build_shortlist(\n",
    "    ARTIFACTS[\"full_inference\"],\n",
    "    CONF_THRESHOLD,\n",
    "    ARTIFACTS[\"shortlist_auto\"]\n",
    ")\n",
    "print(f\"[Shortlist] threshold={CONF_THRESHOLD} â†’ {n_short} / {n_total} rows â†’ {ARTIFACTS['shortlist_auto']}\")\n",
    "\n",
    "# 2) Assemble patch (corridors + sadness top-up + cap speech_action)\n",
    "n_patch_raw, raw_counts = assemble_patch(ARTIFACTS, classes=[\n",
    "    'anger','contempt','disgust','fear','happiness','neutral','questioning',\n",
    "    'sadness','surprise','neutral_speech','speech_action'\n",
    "], out_csv=ARTIFACTS[\"patch\"])\n",
    "print(f\"[Patch] pre-validation rows={n_patch_raw} (counts by label={raw_counts})\")\n",
    "\n",
    "# 3) Validate (existence, read, no eval-leak); write back to same path\n",
    "n_in, n_drop_missing, n_drop_eval, n_out = validate_patch(\n",
    "    ARTIFACTS[\"patch\"], \n",
    "    classes=[\n",
    "        'anger','contempt','disgust','fear','happiness','neutral','questioning',\n",
    "        'sadness','surprise','neutral_speech','speech_action'\n",
    "    ],\n",
    "    stage2_train_dir=DATASET_ROOT,      # your data are organized by label folders; no split dirs\n",
    "    stage2_eval_dir=None,               # no dedicated val dir â€“ function handles None\n",
    "    out_csv=ARTIFACTS[\"patch\"]\n",
    ")\n",
    "print(f\"[Validate] input={n_in}, dropped_missing_or_unreadable={n_drop_missing}, \"\n",
    "      f\"dropped_eval_leak={n_drop_eval}, final={n_out} â†’ {ARTIFACTS['patch']}\")\n",
    "\n",
    "# Optional: dataset dirs for split hygiene. If unknown, leave as None.\n",
    "STAGE2_TRAIN_DIR = None  # e.g., \"/Users/you/datasets/stage2/train\"\n",
    "STAGE2_EVAL_DIR  = None  # e.g., \"/Users/you/datasets/stage2/val\"\n",
    "\n",
    "# Outputs go inside V34 root\n",
    "OUT_SHORTLIST = f\"{V34_ROOT}/curation_shortlist_V35_auto.csv\"\n",
    "OUT_PATCH     = f\"{V34_ROOT}/patch_V35.csv\"\n",
    "OUT_REPORT    = f\"{V34_ROOT}/v35_prep_report.txt\"\n",
    "ARTIFACTS[\"shortlist_auto\"] = OUT_SHORTLIST\n",
    "\n",
    "# --- class balancing / top-up knobs ---\n",
    "FLOOR_SADNESS       = 200      # ensure at least this many sadness examples in patch\n",
    "CAP_SPEECH_ACTION   = 900      # cap speech_action in patch\n",
    "TARGET_SADNESS_ADD  = 250      # preferred additional sadness to try add (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df9c5469-8b1a-4a97-8546-8aa25fa8c812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Helpers\n",
    "# -----------------------------------------------------------------------------\n",
    "def _ensure_dir(p: str):\n",
    "    Path(p).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _load_csv_safe(path: str) -> Optional[pd.DataFrame]:\n",
    "    if not path or not Path(path).exists():\n",
    "        return None\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _open_ok(img_path: str) -> bool:\n",
    "    try:\n",
    "        with Image.open(img_path) as im:\n",
    "            im.verify()  # quick decode check\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _guess_path_column(df: pd.DataFrame) -> Optional[str]:\n",
    "    candidates = [\"filepath\",\"file_path\",\"path\",\"image_path\",\"img_path\",\"file\",\"image\",\"filename\"]\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _guess_label_column(df: pd.DataFrame) -> Optional[str]:\n",
    "    candidates = [\"label\",\"target_label\",\"true_label\",\"assigned_label\",\"class\",\"category\"]\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _is_under_dir(child: str, parent: str) -> bool:\n",
    "    try:\n",
    "        child_path = Path(child).resolve()\n",
    "        parent_path = Path(parent).resolve()\n",
    "        return parent_path in child_path.parents or child_path == parent_path\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Shortlist parity check & regeneration\n",
    "# -----------------------------------------------------------------------------\n",
    "def build_shortlist(full_inference_csv: str, threshold: float, out_csv: str) -> Tuple[int, int]:\n",
    "    df = _load_csv_safe(full_inference_csv)\n",
    "    if df is None:\n",
    "        return 0, 0\n",
    "    if \"confidence\" not in df.columns:\n",
    "        # cannot compute; write empty file with header if possible\n",
    "        df0 = pd.DataFrame(columns=list(df.columns))\n",
    "        _ensure_dir(out_csv)\n",
    "        df0.to_csv(out_csv, index=False)\n",
    "        return 0, len(df)\n",
    "    mask = df[\"confidence\"] < threshold\n",
    "    shortlist = df.loc[mask].copy()\n",
    "    _ensure_dir(out_csv)\n",
    "    shortlist.to_csv(out_csv, index=False)\n",
    "    return len(shortlist), len(df)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Patch-set assembly (corridor-focused + curated sources + top-up sadness)\n",
    "# -----------------------------------------------------------------------------\n",
    "def assemble_patch(artifacts: Dict[str,str],\n",
    "                   classes: List[str],\n",
    "                   out_csv: str) -> Tuple[int, Dict[str,int]]:\n",
    "    \"\"\"\n",
    "    Build a patch set from curated + hard_negatives + (previous & auto) shortlists.\n",
    "    * Dedupes by filepath.\n",
    "    * Infers label from folder name if missing.\n",
    "    * Prioritizes corridor (sadness/neutral_speech/speech_action).\n",
    "    * TOP-UP: add sadness from shortlist_auto/shortlist_prev/full_log (safe, deduped).\n",
    "    * Applies FLOOR/CAP (sadness floor, speech_action cap).\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    # 2.1) Include curated + hard-negatives + shortlists (NOT the full log here)\n",
    "    for key in [\n",
    "        \"curated_additions\",\n",
    "        \"curated_additions_merged\",\n",
    "        \"hard_neg_1\",\n",
    "        \"hard_neg_2\",\n",
    "        \"shortlist_prev\",\n",
    "        \"shortlist_auto\",\n",
    "    ]:\n",
    "        p = artifacts.get(key)\n",
    "        df = _load_csv_safe(p)\n",
    "        if df is not None and not df.empty:\n",
    "            df[\"__source\"] = key\n",
    "            frames.append(df)\n",
    "\n",
    "    if not frames:\n",
    "        _ensure_dir(out_csv)\n",
    "        pd.DataFrame(columns=[\"filepath\",\"label\",\"__source\"]).to_csv(out_csv, index=False)\n",
    "        return 0, {}\n",
    "\n",
    "    big = pd.concat(frames, axis=0, ignore_index=True)\n",
    "\n",
    "    # 2.2) Standardize columns\n",
    "    path_col = _guess_path_column(big)\n",
    "    if path_col is None:\n",
    "        # heuristic: fall back to first column that looks like a path\n",
    "        for col in big.columns:\n",
    "            if big[col].astype(str).str.contains(r\"/|\\\\\").any():\n",
    "                path_col = col\n",
    "                break\n",
    "    if path_col is None:\n",
    "        _ensure_dir(out_csv)\n",
    "        pd.DataFrame(columns=[\"filepath\",\"label\",\"__source\"]).to_csv(out_csv, index=False)\n",
    "        return 0, {}\n",
    "\n",
    "    big = big.rename(columns={path_col: \"filepath\"})\n",
    "    if \"label\" not in big.columns:\n",
    "        big[\"label\"] = \"\"\n",
    "\n",
    "    # infer label from folder name if missing/invalid\n",
    "    def _infer_label_from_path(fp, classes):\n",
    "        try:\n",
    "            parent = Path(str(fp)).parent.name\n",
    "            return parent if parent in classes else \"\"\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "\n",
    "    big[\"label\"] = big[\"label\"].where(\n",
    "        big[\"label\"].isin(classes),\n",
    "        big[\"filepath\"].apply(lambda x: _infer_label_from_path(x, classes))\n",
    "    )\n",
    "\n",
    "    # keep only recognized labels + non-null paths\n",
    "    big = big.dropna(subset=[\"filepath\"]).copy()\n",
    "    big[\"filepath\"] = big[\"filepath\"].astype(str)\n",
    "    big = big[big[\"label\"].isin(classes)].copy()\n",
    "\n",
    "    # 2.3) Dedup by filepath (keep first occurrence per source order)\n",
    "    big = big.drop_duplicates(subset=[\"filepath\"], keep=\"first\")\n",
    "\n",
    "    # 2.4) Priority-first ordering (corridor first)\n",
    "    if \"predicted_class\" in big.columns:\n",
    "        mask_corridor = big[\"predicted_class\"].isin([\"neutral_speech\",\"sadness\",\"speech_action\"])\n",
    "    else:\n",
    "        mask_corridor = big[\"label\"].isin([\"neutral_speech\",\"sadness\",\"speech_action\"])\n",
    "    mask_corridor = mask_corridor.reindex(big.index, fill_value=False)\n",
    "\n",
    "    patch = pd.concat([big[mask_corridor], big[~mask_corridor]], ignore_index=True)\n",
    "\n",
    "\n",
    "    # 2.5) TOP-UP sadness (prefer shortlist_auto, then shortlist_prev, then full log) â€” robust\n",
    "    have_sad = int((patch[\"label\"] == \"sadness\").sum())\n",
    "    need_floor = max(0, FLOOR_SADNESS - have_sad)\n",
    "    \n",
    "    # Also try to add up to TARGET_SADNESS_ADD total new sadness samples (without exceeding availability)\n",
    "    target_add = max(need_floor, TARGET_SADNESS_ADD if have_sad < FLOOR_SADNESS else 0)\n",
    "    \n",
    "    if target_add > 0:\n",
    "        # choose candidate source\n",
    "        cands = None\n",
    "        for key in (\"shortlist_auto\", \"shortlist_prev\"):\n",
    "            cands = _load_csv_safe(artifacts.get(key, \"\"))\n",
    "            if cands is not None and not cands.empty:\n",
    "                cands[\"__source\"] = key\n",
    "                break\n",
    "        if cands is None:\n",
    "            cands = _load_csv_safe(artifacts.get(\"full_inference\", \"\"))\n",
    "            if cands is not None and not cands.empty:\n",
    "                cands[\"__source\"] = \"full_inference\"\n",
    "    \n",
    "        if cands is not None and not cands.empty:\n",
    "            # ---- normalize path column for cands ----\n",
    "            path_col_c = _guess_path_column(cands)\n",
    "            if path_col_c is None:\n",
    "                # heuristic: pick any column that looks like a path\n",
    "                for col in cands.columns:\n",
    "                    try:\n",
    "                        if cands[col].astype(str).str.contains(r\"/|\\\\\").any():\n",
    "                            path_col_c = col\n",
    "                            break\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            if path_col_c is None:\n",
    "                # cannot proceed without a path column\n",
    "                pass\n",
    "            else:\n",
    "                if path_col_c != \"filepath\":\n",
    "                    cands = cands.rename(columns={path_col_c: \"filepath\"})\n",
    "                cands = cands.dropna(subset=[\"filepath\"]).copy()\n",
    "                cands[\"filepath\"] = cands[\"filepath\"].astype(str)\n",
    "    \n",
    "                # ensure expected columns exist\n",
    "                for col in [\"predicted_class\", \"top2_class\", \"confidence\"]:\n",
    "                    if col not in cands.columns:\n",
    "                        cands[col] = None\n",
    "    \n",
    "                # build sadness corridor mask\n",
    "                has_pred = \"predicted_class\" in cands.columns and cands[\"predicted_class\"].notna().any()\n",
    "                if has_pred:\n",
    "                    mask_sad = (\n",
    "                        (cands[\"predicted_class\"] == \"sadness\") |\n",
    "                        (\n",
    "                            (cands[\"predicted_class\"] == \"neutral_speech\") &\n",
    "                            (\n",
    "                                (cands.get(\"top2_class\") == \"sadness\") |\n",
    "                                (cands.get(\"confidence\").fillna(1.0) <= 0.90)\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                    sad_cands = cands.loc[mask_sad, [\"filepath\", \"predicted_class\", \"confidence\"]].copy()\n",
    "                else:\n",
    "                    # fallback: infer from folder name if no predictions present\n",
    "                    sad_cands = cands[[\"filepath\"]].copy()\n",
    "                    sad_cands[\"__folder_label\"] = sad_cands[\"filepath\"].apply(\n",
    "                        lambda p: Path(p).parent.name if isinstance(p, str) else \"\"\n",
    "                    )\n",
    "                    sad_cands = sad_cands[sad_cands[\"__folder_label\"] == \"sadness\"].copy()\n",
    "    \n",
    "                # existence check and dedupe against current patch\n",
    "                sad_cands = sad_cands[sad_cands[\"filepath\"].map(lambda p: os.path.isfile(p))]\n",
    "                already = set(patch[\"filepath\"].astype(str))\n",
    "                sad_cands = sad_cands[~sad_cands[\"filepath\"].isin(already)]\n",
    "    \n",
    "                # bias by lower confidence first if available\n",
    "                if \"confidence\" in sad_cands.columns:\n",
    "                    try:\n",
    "                        sad_cands = sad_cands.sort_values(by=\"confidence\", ascending=True, na_position=\"last\")\n",
    "                    except Exception:\n",
    "                        pass\n",
    "    \n",
    "                # take up to target_add\n",
    "                if len(sad_cands) > target_add:\n",
    "                    sad_cands = sad_cands.head(target_add)\n",
    "    \n",
    "                if not sad_cands.empty:\n",
    "                    add_df = sad_cands[[\"filepath\"]].copy()\n",
    "                    add_df[\"label\"] = \"sadness\"\n",
    "                    patch = pd.concat([patch, add_df], ignore_index=True)\n",
    "                    patch = patch.drop_duplicates(subset=[\"filepath\"], keep=\"first\")\n",
    "\n",
    "    # 2.6) CAP speech_action if needed\n",
    "    sa_count = int((patch[\"label\"] == \"speech_action\").sum())\n",
    "    if sa_count > CAP_SPEECH_ACTION:\n",
    "        keep_sa = patch[patch[\"label\"] == \"speech_action\"].sample(\n",
    "            n=CAP_SPEECH_ACTION, random_state=42, replace=False\n",
    "        )\n",
    "        non_sa = patch[patch[\"label\"] != \"speech_action\"]\n",
    "        patch  = pd.concat([non_sa, keep_sa], ignore_index=True)\n",
    "\n",
    "    # 2.7) Write out\n",
    "    _ensure_dir(out_csv)\n",
    "    patch.to_csv(out_csv, index=False)\n",
    "\n",
    "    counts = patch[\"label\"].value_counts().to_dict()\n",
    "    return len(patch), counts\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Validate + sanitize patch (files/labels/split hygiene)\n",
    "# -----------------------------------------------------------------------------\n",
    "def validate_patch(in_csv: str,\n",
    "                   classes: List[str],\n",
    "                   train_dir: Optional[str],\n",
    "                   eval_dir: Optional[str],\n",
    "                   out_csv: str) -> Tuple[int,int,int,int]:\n",
    "    \"\"\"\n",
    "    Validate and sanitize a patch CSV:\n",
    "      - keep only rows with existing files\n",
    "      - keep only labels in `classes`\n",
    "      - optionally drop rows that live under `eval_dir` (leak guard)\n",
    "      - write cleaned CSV to `out_csv`\n",
    "    Returns: (n_input, n_dropped_missing, n_dropped_eval, n_output)\n",
    "    \"\"\"\n",
    "    def _ensure_dir_local(p: str):\n",
    "        Path(os.path.dirname(p) or \".\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def _safe_read(csv_path: str) -> Optional[pd.DataFrame]:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            return df if not df.empty else None\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    df = _safe_read(in_csv)\n",
    "    if df is None:\n",
    "        _ensure_dir_local(out_csv)\n",
    "        pd.DataFrame(columns=[\"filepath\",\"label\"]).to_csv(out_csv, index=False)\n",
    "        return (0, 0, 0, 0)\n",
    "\n",
    "    # normalize columns\n",
    "    if \"filepath\" not in df.columns:\n",
    "        for c in df.columns:\n",
    "            if df[c].astype(str).str.contains(r\"/|\\\\\").any():\n",
    "                df = df.rename(columns={c: \"filepath\"})\n",
    "                break\n",
    "    if \"filepath\" not in df.columns:\n",
    "        _ensure_dir_local(out_csv)\n",
    "        pd.DataFrame(columns=[\"filepath\",\"label\"]).to_csv(out_csv, index=False)\n",
    "        return (0, 0, 0, 0)\n",
    "\n",
    "    if \"label\" not in df.columns:\n",
    "        df[\"label\"] = \"\"\n",
    "\n",
    "    n_input = len(df)\n",
    "\n",
    "    # drop missing/unreadable files\n",
    "    df[\"filepath\"] = df[\"filepath\"].astype(str)\n",
    "    mask_exists = df[\"filepath\"].apply(lambda p: os.path.isfile(p))\n",
    "    n_drop_missing = int((~mask_exists).sum())\n",
    "    df = df[mask_exists].copy()\n",
    "\n",
    "    # keep only allowed labels\n",
    "    df[\"label\"] = df[\"label\"].astype(str)\n",
    "    df = df[df[\"label\"].isin(classes)].copy()\n",
    "\n",
    "    # drop eval-leak rows, if eval_dir provided\n",
    "    n_drop_eval = 0\n",
    "    if eval_dir:\n",
    "        eval_dir_resolved = str(Path(eval_dir).resolve())\n",
    "        def _is_in_eval(p):\n",
    "            try:\n",
    "                return str(Path(p).resolve()).startswith(eval_dir_resolved + os.sep)\n",
    "            except Exception:\n",
    "                return False\n",
    "        mask_eval = df[\"filepath\"].apply(_is_in_eval)\n",
    "        n_drop_eval = int(mask_eval.sum())\n",
    "        df = df[~mask_eval].copy()\n",
    "\n",
    "    # dedupe by filepath\n",
    "    df = df.drop_duplicates(subset=[\"filepath\"], keep=\"first\")\n",
    "\n",
    "    # write out\n",
    "    _ensure_dir_local(out_csv)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "\n",
    "    n_output = len(df)\n",
    "    return (n_input, n_drop_missing, n_drop_eval, n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "420c1c3a-85cf-443d-887e-e98f039d1fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Shortlist] threshold=0.85 â†’ 5207 / 26902 rows written to /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V34_20251013_211825/curation_shortlist_V35_auto.csv\n",
      "[Shortlist] previous shortlist detected: /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V34_20251013_211825/curation_shortlist_V34.csv (rows=2590)\n",
      "[Patch] pre-validation rows=1924 (counts by label={'speech_action': 900, 'neutral_speech': 320, 'sadness': 200, 'happiness': 189, 'neutral': 157, 'surprise': 65, 'questioning': 60, 'fear': 20, 'contempt': 12, 'anger': 1})\n",
      "[Validate] input=1924, dropped_missing_or_unreadable=0, dropped_eval_leak=0, final=1924 â†’ /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V34_20251013_211825/patch_V35.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 4) Driver\n",
    "# -----------------------------------------------------------------------------\n",
    "def main():\n",
    "    report_lines = []\n",
    "\n",
    "    # (1) Shortlist regeneration\n",
    "    n_short, n_total = build_shortlist(ARTIFACTS[\"full_inference\"], CONF_THRESHOLD, OUT_SHORTLIST)\n",
    "    report_lines.append(f\"[Shortlist] threshold={CONF_THRESHOLD} â†’ {n_short} / {n_total} rows written to {OUT_SHORTLIST}\")\n",
    "\n",
    "    # Compare against prior shortlist if present\n",
    "    prev = _load_csv_safe(ARTIFACTS[\"shortlist_prev\"])\n",
    "    if prev is not None:\n",
    "        report_lines.append(f\"[Shortlist] previous shortlist detected: {ARTIFACTS['shortlist_prev']} (rows={len(prev)})\")\n",
    "\n",
    "    # (2) Assemble patch (includes corridor priority + TOP-UP sadness + CAP speech_action)\n",
    "    n_patch_raw, raw_counts = assemble_patch(ARTIFACTS, RELEVANT_CLASSES, OUT_PATCH)\n",
    "    report_lines.append(f\"[Patch] pre-validation rows={n_patch_raw} (counts by label={raw_counts})\")\n",
    "\n",
    "    # (3) Validate patch files/labels and enforce split hygiene\n",
    "    n_in, n_drop_missing, n_drop_eval, n_out = validate_patch(\n",
    "        OUT_PATCH, RELEVANT_CLASSES, STAGE2_TRAIN_DIR, STAGE2_EVAL_DIR, OUT_PATCH\n",
    "    )\n",
    "    report_lines.append(\n",
    "        f\"[Validate] input={n_in}, dropped_missing_or_unreadable={n_drop_missing}, \"\n",
    "        f\"dropped_eval_leak={n_drop_eval}, final={n_out} â†’ {OUT_PATCH}\"\n",
    "    )\n",
    "\n",
    "    # (4) Save summary report\n",
    "    report = \"\\n\".join(report_lines) + \"\\n\"\n",
    "    Path(OUT_REPORT).write_text(report, encoding=\"utf-8\")\n",
    "    print(report)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_expressions_v5)",
   "language": "python",
   "name": "ml_expressions_v5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
