{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67062f7c-3007-415a-8ff6-b61afbf15e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c446e86-0669-40cc-9afe-52288611a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. CONFIGURATION\n",
    "# ==============================================================================\n",
    "\n",
    "# --- IMPORTANT: Point this to the folder containing your two review queues ---\n",
    "# This is the output folder from your last completed video analysis run.\n",
    "RUN_DIRECTORY = \"/Users/natalyagrokh/AI/ml_expressions/img_expressions/data_flywheel/V8_20250722_130942\"\n",
    "\n",
    "# --- Define the name for the new, consolidated training set ---\n",
    "OUTPUT_DATASET_NAME = \"CorrectionSet_V2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ff9f564-8380-4947-ad7d-f5a9d807e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 2. SCRIPT LOGIC\n",
    "# ==============================================================================\n",
    "\n",
    "# Reads two manually curated review logs, finds original face crops,\n",
    "    # and sorts them into new binary dataset for training V2 Gatekeeper\n",
    "def build_final_correction_set(run_dir, output_name):\n",
    "    \n",
    "    \n",
    "    # --- Setup Paths ---\n",
    "    micro_expr_folder = os.path.join(run_dir, \"micro_expression_review_queue\")\n",
    "    stable_expr_folder = os.path.join(run_dir, \"stable_emotion_review_queue\")\n",
    "    \n",
    "    micro_expr_csv = os.path.join(micro_expr_folder, \"simplified_review_log_me.csv\")\n",
    "    stable_expr_csv = os.path.join(stable_expr_folder, \"simplified_review_log_se.csv\")\n",
    "\n",
    "    output_dir = os.path.join(os.path.dirname(run_dir), output_name)\n",
    "    emotion_dir = os.path.join(output_dir, \"emotion\")\n",
    "    action_dir = os.path.join(output_dir, \"speech_Action\")\n",
    "\n",
    "    # --- Create the new dataset directories ---\n",
    "    os.makedirs(emotion_dir, exist_ok=True)\n",
    "    os.makedirs(action_dir, exist_ok=True)\n",
    "    \n",
    "    # --- Load and Combine Both Curated CSVs ---\n",
    "    df_micro = pd.read_csv(micro_expr_csv)\n",
    "    df_stable = pd.read_csv(stable_expr_csv)\n",
    "    combined_df = pd.concat([df_micro, df_stable]).drop_duplicates(subset=['face_crop_path']).reset_index(drop=True)\n",
    "    print(f\"✅ Loaded and combined both review logs. Total unique images to process: {len(combined_df)}\")\n",
    "\n",
    "    # --- Process and Sort Images ---\n",
    "    copied_count = 0\n",
    "    for _, row in tqdm(combined_df.iterrows(), total=combined_df.shape[0], desc=\"Sorting Images\"):\n",
    "        # The source images are in two different folders, so we check both.\n",
    "        source_filename = row['face_crop_path']\n",
    "        source_path_micro = os.path.join(micro_expr_folder, source_filename)\n",
    "        source_path_stable = os.path.join(stable_expr_folder, source_filename)\n",
    "        \n",
    "        source_path = source_path_micro if os.path.exists(source_path_micro) else source_path_stable\n",
    "\n",
    "        if not os.path.exists(source_path):\n",
    "            continue\n",
    "\n",
    "        actual_label = str(row.get('actual_label', '')).lower()\n",
    "        \n",
    "        # --- The Sorting Logic ---\n",
    "        # If actual_label is empty, the original prediction was correct -> Emotion\n",
    "        if pd.isna(row.get('actual_label')) or row.get('actual_label') == '':\n",
    "             shutil.copy(source_path, emotion_dir)\n",
    "             copied_count += 1\n",
    "        # If your notes indicate a non-emotional action, sort it into 'Speech_Action'\n",
    "        elif any(keyword in actual_label for keyword in ['mid-speech', 'mid speech', 'laughter', 'mixed']):\n",
    "            shutil.copy(source_path, action_dir)\n",
    "            copied_count += 1\n",
    "        # Otherwise, it's a genuine emotion that was mislabeled by the V29 model.\n",
    "        else:\n",
    "            shutil.copy(source_path, emotion_dir)\n",
    "            copied_count += 1\n",
    "\n",
    "    print(f\"\\n✅ Success! Created the '{output_name}' dataset with {copied_count} images.\")\n",
    "    print(f\"   - Location: {output_dir}\")\n",
    "    print(f\"   - Emotion examples: {len(os.listdir(emotion_dir))}\")\n",
    "    print(f\"   - Speech_Action examples: {len(os.listdir(action_dir))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56d84a6f-625b-4b61-9ddf-c6cb5cb87d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded and combined both review logs. Total unique images to process: 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sorting Images: 100%|███████████████████████| 192/192 [00:00<00:00, 1101.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Success! Created the 'CorrectionSet_V2' dataset with 192 images.\n",
      "   - Location: /Users/natalyagrokh/AI/ml_expressions/img_expressions/data_flywheel/CorrectionSet_V2\n",
      "   - Emotion examples: 47\n",
      "   - Speech_Action examples: 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 3. MAIN EXECUTION BLOCK\n",
    "# ==============================================================================\n",
    "if __name__ == '__main__':\n",
    "    build_final_correction_set(\n",
    "        run_dir=RUN_DIRECTORY,\n",
    "        output_name=OUTPUT_DATASET_NAME\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278147e6-1228-4502-9a08-78c43173fe9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_expressions",
   "language": "python",
   "name": "ml_expressions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
