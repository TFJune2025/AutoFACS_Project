{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a216be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d7827b-4558-4646-8c69-8d983d975809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_faces_in_news(query_list, output_dir, max_results=10, delay=5):\n",
    "    \"\"\"\n",
    "    Scrapes Wikimedia Commons for images based on a list of search queries.\n",
    "\n",
    "    Args:\n",
    "        query_list (list): List of search queries (e.g., [\"face AND news\", \"portrait AND news\"]).\n",
    "        output_dir (str): Directory to save the images.\n",
    "        max_results (int): Maximum number of images to download per query.\n",
    "        delay (int): Delay (in seconds) between API calls to avoid rate limits.\n",
    "    \"\"\"\n",
    "    base_url = \"https://commons.wikimedia.org/w/api.php\"\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Loop through each search query\n",
    "    for query in query_list:\n",
    "        print(f\"\\nSearching for: '{query}'\\n\" + \"-\" * 40)\n",
    "        query_exhausted = False  # Flag to detect when no more results are found\n",
    "\n",
    "        # Step 1: Search for images\n",
    "        search_params = {\n",
    "            \"action\": \"query\",\n",
    "            \"format\": \"json\",\n",
    "            \"list\": \"search\",\n",
    "            \"srsearch\": query,\n",
    "            \"srnamespace\": 6,  # Media files only\n",
    "            \"srlimit\": max_results  # Limit the number of results\n",
    "        }\n",
    "        response = requests.get(base_url, params=search_params)\n",
    "        search_results = response.json().get('query', {}).get('search', [])\n",
    "\n",
    "        if not search_results:\n",
    "            print(f\"No more images found for query: '{query}'. Moving to the next query.\\n\")\n",
    "            continue  # Skip to the next query if no results are found\n",
    "\n",
    "        # Step 2: Download each image\n",
    "        for result in search_results:\n",
    "            title = result['title']  # e.g., \"File:Example.jpg\"\n",
    "            \n",
    "            # Get image information (URL and metadata)\n",
    "            image_info_params = {\n",
    "                \"action\": \"query\",\n",
    "                \"format\": \"json\",\n",
    "                \"titles\": title,\n",
    "                \"prop\": \"imageinfo\",\n",
    "                \"iiprop\": \"url|extmetadata|size\"  # Fetch image URLs and metadata\n",
    "            }\n",
    "            image_info_response = requests.get(base_url, params=image_info_params)\n",
    "            pages = image_info_response.json().get('query', {}).get('pages', {})\n",
    "\n",
    "            for page_id, page_data in pages.items():\n",
    "                if \"imageinfo\" in page_data:\n",
    "                    image_url = page_data[\"imageinfo\"][0][\"url\"]\n",
    "                    ext_metadata = page_data[\"imageinfo\"][0].get(\"extmetadata\", {})\n",
    "                    license_info = ext_metadata.get(\"LicenseShortName\", {}).get(\"value\", \"Unknown License\")\n",
    "\n",
    "                    # Step 3: Download the image\n",
    "                    image_data = requests.get(image_url).content\n",
    "                    file_name = os.path.join(output_dir, title.replace(\"File:\", \"\").replace(\" \", \"_\"))\n",
    "\n",
    "                    with open(file_name, 'wb') as file:\n",
    "                        file.write(image_data)\n",
    "                        print(f\"Downloaded: {file_name} (License: {license_info})\")\n",
    "\n",
    "                    # Delay to avoid rate-limiting\n",
    "                    time.sleep(delay)\n",
    "\n",
    "        # Flagging query as exhausted\n",
    "        if len(search_results) < max_results:\n",
    "            print(f\"No more results for query: '{query}'.\\n\")\n",
    "            query_exhausted = True\n",
    "\n",
    "        # Log completion of the current query\n",
    "        if not query_exhausted:\n",
    "            print(f\"Finished processing all available images for query: '{query}'.\\n\")\n",
    "\n",
    "    print(\"Scraping and downloading completed for all queries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d360b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "query_combinations = [\n",
    "    \"face AND news\",\n",
    "    \"portrait AND journalist\",\n",
    "    \"headshot AND news\",\n",
    "    \"reporter AND face\",\n",
    "    \"journalist portrait\"\n",
    "]\n",
    "\n",
    "scrape_faces_in_news(\n",
    "    query_list=query_combinations,\n",
    "    output_dir=\"faces_in_news_images\",\n",
    "    max_results=10,  # Limit to 10 images per query\n",
    "    delay=5  # 5 seconds between requests\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_expressions)",
   "language": "python",
   "name": "ml_expressions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
