{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b0e7e1-88a8-416e-8872-d526e883e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d81e12-41a7-459d-ab6e-3e94ddde84be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save downloaded pexels images\n",
    "SAVE_DIR = \"/home/natalyagrokh/img_datasets/pexels_images_2\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7894cec-4510-45a6-b73f-e6d2e4976858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set your Pexels credentials\n",
    "load_dotenv()\n",
    "\n",
    "PEXELS_API_KEY = os.getenv(\"PEXELS_API_KEY\")\n",
    "\n",
    "if not PEXELS_API_KEY:\n",
    "    raise ValueError(\"PEXELS_API_KEY not found in .env file\")\n",
    "\n",
    "PEXELS_API_URL = \"https://api.pexels.com/v1/search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35aa181-8716-40e2-adc2-31366cf4885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persistent Tracking: Load previously downloaded URLs\n",
    "def load_downloaded_urls(file_path=\"/home/natalyagrokh/img_datasets/downloaded_urls.json\"):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            urls = set(json.load(f))\n",
    "        print(f\"Loaded {len(urls)} previously downloaded URLs from {file_path}.\")\n",
    "        return urls\n",
    "    else:\n",
    "        return set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d104e26-0b3c-4856-afcb-6dde64c4f933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persistent Tracking: Save downloaded URLs\n",
    "def save_downloaded_urls(downloaded_urls, file_path=\"/home/natalyagrokh/img_datasets/downloaded_urls.json\"):\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(list(downloaded_urls), f)\n",
    "    print(f\"Saved {len(downloaded_urls)} downloaded URLs to {file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f362d558-8eac-413c-8464-32aa744bdf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download and save images from Pexels\n",
    "# max_batches=200,  == set based on a 200/hr api call max policy by pexels\n",
    "# batch_size=80 == set on a max 80 imgs / api call policy\n",
    "# wait_time=3600 == set to automate hourly calls\n",
    "def auto_pexels_images(query, max_batches=200, batch_size=80, wait_time=3600):\n",
    "    \"\"\"\n",
    "    Automatically fetch and save images from Pexels in batches, respecting API quotas.\n",
    "\n",
    "    Args:\n",
    "        query (str): Search query for images (e.g., \"people's faces\").\n",
    "        max_batches (int): Maximum number of batches to fetch per run.\n",
    "        batch_size (int): Number of images per batch.\n",
    "        wait_time (int): Time to wait between full runs, in seconds.\n",
    "    \"\"\"\n",
    "    MAX_RETRIES = 3  # Number of retries for a failed download\n",
    "    api_call_count = 0  # Initialize API call counter\n",
    "\n",
    "    while True:\n",
    "        # Load previously downloaded URLs\n",
    "        downloaded_urls = load_downloaded_urls()\n",
    "\n",
    "        # Check existing images to determine the starting index\n",
    "        existing_files = [f for f in os.listdir(SAVE_DIR) if f.startswith(\"image_\") and f.endswith(\".jpg\")]\n",
    "        existing_numbers = [int(f.split(\"_\")[1].split(\".\")[0]) for f in existing_files if f.split(\"_\")[1].split(\".\")[0].isdigit()]\n",
    "        start_index = max(existing_numbers) + 1 if existing_numbers else 1\n",
    "\n",
    "        total_downloaded = 0\n",
    "        page = 1\n",
    "\n",
    "        while total_downloaded < max_batches * batch_size:\n",
    "            headers = {\"Authorization\": PEXELS_API_KEY}\n",
    "            params = {\n",
    "                \"query\": query, \n",
    "                \"per_page\": batch_size, \n",
    "                \"page\": page\n",
    "            }\n",
    "\n",
    "            response = requests.get(PEXELS_API_URL, headers=headers, params=params)\n",
    "            api_call_count += 1  # Increment API call counter\n",
    "            print(f\"API Calls Made: {api_call_count}\")\n",
    "\n",
    "            if response.status_code == 429:  # Handle rate limiting (Too Many Requests)\n",
    "                print(\"Rate limit reached. Waiting for 60 seconds before retrying...\")\n",
    "                time.sleep(60)  # Wait for 60 seconds before retrying\n",
    "                continue  # Retry the same request\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Error: {response.status_code} - {response.text}\")\n",
    "                break\n",
    "\n",
    "            data = response.json()\n",
    "            photos = data.get(\"photos\", [])\n",
    "\n",
    "            if not photos:\n",
    "                print(\"No more photos available.\")\n",
    "                break\n",
    "\n",
    "            for photo in photos:\n",
    "                image_url = photo[\"src\"][\"original\"]\n",
    "\n",
    "                if image_url in downloaded_urls:\n",
    "                    print(f\"Skipped duplicate URL: {image_url}\")\n",
    "                    continue\n",
    "\n",
    "                for attempt in range(MAX_RETRIES):\n",
    "                    try:\n",
    "                        response = requests.get(image_url, timeout=120)\n",
    "                        if response.status_code == 200:\n",
    "                            file_name = os.path.join(SAVE_DIR, f\"image_{start_index + total_downloaded}.jpg\")\n",
    "                            with open(file_name, \"wb\") as f:\n",
    "                                f.write(response.content)\n",
    "                            print(f\"Downloaded: {file_name}\")\n",
    "\n",
    "                            downloaded_urls.add(image_url)\n",
    "                            total_downloaded += 1\n",
    "                            break\n",
    "                    except (requests.ConnectionError, requests.Timeout) as e:\n",
    "                        print(f\"Attempt {attempt + 1} failed for {image_url}: {e}\")\n",
    "                        if attempt == MAX_RETRIES - 1:\n",
    "                            print(f\"Failed to download after {MAX_RETRIES} attempts: {image_url}\")\n",
    "                            with open(\"failed_urls.log\", \"a\") as log_file:\n",
    "                                log_file.write(image_url + \"\\n\")\n",
    "\n",
    "            page += 1  # Move to the next page\n",
    "\n",
    "            if total_downloaded >= max_batches * batch_size:\n",
    "                break\n",
    "\n",
    "        # Save updated downloaded URLs\n",
    "        save_downloaded_urls(downloaded_urls)\n",
    "\n",
    "        print(f\"Total images downloaded: {total_downloaded}\")\n",
    "        print(f\"Process completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\")\n",
    "\n",
    "        # Wait before the next full run\n",
    "        print(f\"Waiting for {wait_time / 60} minutes before the next run...\")\n",
    "        time.sleep(wait_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991cd8ff-7e20-426e-ae26-9f04567bbf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with desired search query\n",
    "auto_pexels_images(query=\"surprise\", max_batches=200, batch_size=80, wait_time=3600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_expressions)",
   "language": "python",
   "name": "ml_expressions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
