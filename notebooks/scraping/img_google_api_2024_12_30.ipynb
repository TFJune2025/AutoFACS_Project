{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125d14af-b766-44a7-b9b1-11b8708b6d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import json\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab649b-8d63-425c-b0bf-dd9fc3979fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download and save images from Pexels\n",
    "def auto_pexels_images(query, max_batches=5, batch_size=80, wait_time=3600):\n",
    "    \"\"\"\n",
    "    Automatically fetch and save images from Pexels in batches, respecting API quotas.\n",
    "\n",
    "    Args:\n",
    "        query (str): Search query for images (e.g., \"people's faces\").\n",
    "        max_batches (int): Maximum number of batches to fetch per run.\n",
    "        batch_size (int): Number of images per batch.\n",
    "        wait_time (int): Time to wait between full runs, in seconds.\n",
    "    \"\"\"\n",
    "    MAX_RETRIES = 3  # Number of retries for a failed download\n",
    "    api_call_count = 0  # Initialize API call counter\n",
    "\n",
    "    while True:\n",
    "        # Load previously downloaded URLs\n",
    "        downloaded_urls = load_downloaded_urls()\n",
    "\n",
    "        # Check existing images to determine the starting index\n",
    "        existing_files = [f for f in os.listdir(SAVE_DIR) if f.startswith(\"image_\") and f.endswith(\".jpg\")]\n",
    "        existing_numbers = [int(f.split(\"_\")[1].split(\".\")[0]) for f in existing_files if f.split(\"_\")[1].split(\".\")[0].isdigit()]\n",
    "        start_index = max(existing_numbers) + 1 if existing_numbers else 1\n",
    "\n",
    "        total_downloaded = 0\n",
    "        page = 1\n",
    "\n",
    "        while total_downloaded < max_batches * batch_size:\n",
    "            headers = {\"Authorization\": PEXELS_API_KEY}\n",
    "            params = {\n",
    "                \"query\": query, \n",
    "                \"per_page\": batch_size, \n",
    "                \"page\": page\n",
    "            }\n",
    "\n",
    "            response = requests.get(PEXELS_API_URL, headers=headers, params=params)\n",
    "            api_call_count += 1  # Increment API call counter\n",
    "            print(f\"API Calls Made: {api_call_count}\")\n",
    "\n",
    "            if response.status_code == 429:  # Handle rate limiting (Too Many Requests)\n",
    "                print(\"Rate limit reached. Waiting for 60 seconds before retrying...\")\n",
    "                time.sleep(60)  # Wait for 60 seconds before retrying\n",
    "                continue  # Retry the same request\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Error: {response.status_code} - {response.text}\")\n",
    "                break\n",
    "\n",
    "            data = response.json()\n",
    "            photos = data.get(\"photos\", [])\n",
    "\n",
    "            if not photos:\n",
    "                print(\"No more photos available.\")\n",
    "                break\n",
    "\n",
    "            for photo in photos:\n",
    "                image_url = photo[\"src\"][\"original\"]\n",
    "\n",
    "                if image_url in downloaded_urls:\n",
    "                    print(f\"Skipped duplicate URL: {image_url}\")\n",
    "                    continue\n",
    "\n",
    "                for attempt in range(MAX_RETRIES):\n",
    "                    try:\n",
    "                        response = requests.get(image_url, timeout=120)\n",
    "                        if response.status_code == 200:\n",
    "                            file_name = os.path.join(SAVE_DIR, f\"image_{start_index + total_downloaded}.jpg\")\n",
    "                            with open(file_name, \"wb\") as f:\n",
    "                                f.write(response.content)\n",
    "                            print(f\"Downloaded: {file_name}\")\n",
    "\n",
    "                            downloaded_urls.add(image_url)\n",
    "                            total_downloaded += 1\n",
    "                            break\n",
    "                    except (requests.ConnectionError, requests.Timeout) as e:\n",
    "                        print(f\"Attempt {attempt + 1} failed for {image_url}: {e}\")\n",
    "                        if attempt == MAX_RETRIES - 1:\n",
    "                            print(f\"Failed to download after {MAX_RETRIES} attempts: {image_url}\")\n",
    "                            with open(\"failed_urls.log\", \"a\") as log_file:\n",
    "                                log_file.write(image_url + \"\\n\")\n",
    "\n",
    "            page += 1  # Move to the next page\n",
    "\n",
    "            if total_downloaded >= max_batches * batch_size:\n",
    "                break\n",
    "\n",
    "        # Save updated downloaded URLs\n",
    "        save_downloaded_urls(downloaded_urls)\n",
    "\n",
    "        print(f\"Total images downloaded: {total_downloaded}\")\n",
    "        print(f\"Process completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\")\n",
    "\n",
    "        # Wait before the next full run\n",
    "        print(f\"Waiting for {wait_time / 60} minutes before the next run...\")\n",
    "        time.sleep(wait_time)\n",
    "\n",
    "# Call the function with your desired search query\n",
    "auto_pexels_images(query=\"people's faces\", max_batches=5, batch_size=80, wait_time=3600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b3b1b-80ea-43bc-bf9f-1a4f4793e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "load_dotenv()\n",
    "\n",
    "PEXELS_API_KEY = os.getenv(\"PEXELS_API_KEY\")\n",
    "\n",
    "if not PEXELS_API_KEY:\n",
    "    raise ValueError(\"PEXELS_API_KEY not found in .env file\")\n",
    "\n",
    "PEXELS_API_URL = \"https://api.pexels.com/v1/search\"\n",
    "\n",
    "CSE_ID = \"a22d39ffb0f5145d9\"  \n",
    "QUERY = \"people's faces\"\n",
    "OUTPUT_DIR = \"google_images\"\n",
    "NUM_IMAGES = 100  # Google API allows up to 100/day for free tier access\n",
    "BATCH_SIZE = 20    # Number of images per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26b8d510-9a64-4ede-8f7d-55a6d397f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persistent Tracking: Load previously downloaded URLs\n",
    "def load_downloaded_urls(file_path=\"downloaded_google_urls.json\"):\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            with open(file_path, \"r\") as f:\n",
    "                urls = set(json.load(f))\n",
    "            print(f\"Loaded {len(urls)} previously downloaded URLs from {file_path}.\")\n",
    "            return urls\n",
    "        except (json.JSONDecodeError, ValueError):\n",
    "            print(f\"File {file_path} is empty or invalid. Starting with an empty URL set.\")\n",
    "            return set()\n",
    "    else:\n",
    "        return set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "584ce250-7ba9-42ed-89b7-c059ff926fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persistent Tracking: Save downloaded URLs\n",
    "def save_downloaded_urls(downloaded_urls, file_path=\"downloaded_google_urls.json\"):\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(list(downloaded_urls), f)\n",
    "    print(f\"Saved {len(downloaded_urls)} downloaded URLs to {file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66fa07e7-3066-4c93-aece-396985b88c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persistent Tracking: Load previously computed image hashes\n",
    "def load_image_hashes(file_path=\"image_hashes.json\"):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            hashes = set(json.load(f))\n",
    "        print(f\"Loaded {len(hashes)} previously computed image hashes from {file_path}.\")\n",
    "        return hashes\n",
    "    else:\n",
    "        return set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abc2f122-5f6e-460a-bc28-d8f0e9298b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persistent Tracking: Save image hashes\n",
    "def save_image_hashes(image_hashes, file_path=\"image_hashes.json\"):\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(list(image_hashes), f)\n",
    "    print(f\"Saved {len(image_hashes)} image hashes to {file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf10c81e-c122-4b80-801c-1ebf5d9d68d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_image_hash(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        return hashlib.md5(f.read()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26940b52-f8e6-40ff-bd82-cbb1b890e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download and save images from Google Custom Search API\n",
    "def google_search_images(api_key, cse_id, query, output_dir, num_images=900, batch_size=10):\n",
    "    \"\"\"\n",
    "    Search and download images from Google Custom Search API.\n",
    "\n",
    "    Args:\n",
    "        api_key (str): Google Custom Search API key.\n",
    "        cse_id (str): Custom Search Engine ID.\n",
    "        query (str): Search query (e.g., \"people's faces\").\n",
    "        output_dir (str): Directory to save images.\n",
    "        num_images (int): Number of images to fetch.\n",
    "        batch_size (int): Number of images per batch.\n",
    "    \"\"\"\n",
    "    # Base URL for Google Custom Search\n",
    "    url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load previously downloaded URLs\n",
    "    downloaded_urls = load_downloaded_urls()\n",
    "\n",
    "    # Load previously computed image hashes\n",
    "    image_hashes = load_image_hashes()\n",
    "\n",
    "    # Check existing images to determine the starting index\n",
    "    existing_files = [f for f in os.listdir(output_dir) if f.endswith(\".jpg\")]\n",
    "    existing_numbers = [int(f.split(\".\")[0]) for f in existing_files if f.split(\".\")[0].isdigit()]\n",
    "    start_index = max(existing_numbers) + 1 if existing_numbers else 1\n",
    "\n",
    "    downloaded = 0\n",
    "    start = 1\n",
    "\n",
    "    while downloaded < num_images:\n",
    "        params = {\n",
    "            \"q\": query,                     # Search query\n",
    "            \"cx\": cse_id,                   # Custom Search Engine ID\n",
    "            \"key\": api_key,                 # API key\n",
    "            \"searchType\": \"image\",          # Specify image search\n",
    "            \"num\": min(batch_size, 10),     # Max 10 results per request\n",
    "            \"start\": start                  # Pagination\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, params=params)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "            break\n",
    "\n",
    "        results = response.json()\n",
    "\n",
    "        # Download images\n",
    "        for item in results.get(\"items\", []):\n",
    "            image_url = item[\"link\"]\n",
    "\n",
    "            if image_url in downloaded_urls:\n",
    "                print(f\"Skipped duplicate URL: {image_url}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                img_data = requests.get(image_url).content\n",
    "                file_name = os.path.join(output_dir, f\"{start_index + downloaded}.jpg\")\n",
    "                with open(file_name, \"wb\") as f:\n",
    "                    f.write(img_data)\n",
    "                print(f\"Downloaded: {file_name}\")\n",
    "\n",
    "                # Compute hash and check for duplicate content\n",
    "                image_hash = compute_image_hash(file_name)\n",
    "                if image_hash in image_hashes:\n",
    "                    print(f\"Removed duplicate content: {file_name}\")\n",
    "                    os.remove(file_name)\n",
    "                    continue\n",
    "                else:\n",
    "                    image_hashes.add(image_hash)\n",
    "\n",
    "                downloaded_urls.add(image_url)\n",
    "                downloaded += 1\n",
    "\n",
    "                if downloaded >= num_images:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading {image_url}: {e}\")\n",
    "\n",
    "        # Update start index for next batch\n",
    "        start += 10\n",
    "        if \"items\" not in results:\n",
    "            break\n",
    "\n",
    "    # Save updated downloaded URLs\n",
    "    save_downloaded_urls(downloaded_urls)\n",
    "\n",
    "    # Save updated image hashes\n",
    "    save_image_hashes(image_hashes)\n",
    "\n",
    "    print(f\"Total images downloaded: {downloaded}\")\n",
    "    print(f\"Process completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96af0776-03e0-465e-a1f9-45d44a722bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded_google_urls.json is empty or invalid. Starting with an empty URL set.\n",
      "Downloaded: google_images/101.jpg\n",
      "Downloaded: google_images/102.jpg\n",
      "Downloaded: google_images/103.jpg\n",
      "Downloaded: google_images/104.jpg\n",
      "Downloaded: google_images/105.jpg\n",
      "Downloaded: google_images/106.jpg\n",
      "Downloaded: google_images/107.jpg\n",
      "Downloaded: google_images/108.jpg\n",
      "Downloaded: google_images/109.jpg\n",
      "Downloaded: google_images/110.jpg\n",
      "Downloaded: google_images/111.jpg\n",
      "Downloaded: google_images/112.jpg\n",
      "Downloaded: google_images/113.jpg\n",
      "Downloaded: google_images/114.jpg\n",
      "Downloaded: google_images/115.jpg\n",
      "Downloaded: google_images/116.jpg\n",
      "Downloaded: google_images/117.jpg\n",
      "Downloaded: google_images/118.jpg\n",
      "Downloaded: google_images/119.jpg\n",
      "Downloaded: google_images/120.jpg\n",
      "Downloaded: google_images/121.jpg\n",
      "Downloaded: google_images/122.jpg\n",
      "Downloaded: google_images/123.jpg\n",
      "Downloaded: google_images/124.jpg\n",
      "Downloaded: google_images/125.jpg\n",
      "Downloaded: google_images/126.jpg\n",
      "Downloaded: google_images/127.jpg\n",
      "Downloaded: google_images/128.jpg\n",
      "Downloaded: google_images/129.jpg\n",
      "Downloaded: google_images/130.jpg\n",
      "Downloaded: google_images/131.jpg\n",
      "Downloaded: google_images/132.jpg\n",
      "Downloaded: google_images/133.jpg\n",
      "Downloaded: google_images/134.jpg\n",
      "Downloaded: google_images/135.jpg\n",
      "Downloaded: google_images/136.jpg\n",
      "Downloaded: google_images/137.jpg\n",
      "Downloaded: google_images/138.jpg\n",
      "Downloaded: google_images/139.jpg\n",
      "Downloaded: google_images/140.jpg\n",
      "Downloaded: google_images/141.jpg\n",
      "Downloaded: google_images/142.jpg\n",
      "Downloaded: google_images/143.jpg\n",
      "Downloaded: google_images/144.jpg\n",
      "Downloaded: google_images/145.jpg\n",
      "Downloaded: google_images/146.jpg\n",
      "Downloaded: google_images/147.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Call the function\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgoogle_search_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAPI_KEY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCSE_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQUERY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_IMAGES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[32], line 60\u001b[0m, in \u001b[0;36mgoogle_search_images\u001b[0;34m(api_key, cse_id, query, output_dir, num_images, batch_size)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     img_data \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_url\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     61\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_index\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mdownloaded\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_expressions/lib/python3.9/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_expressions/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_expressions/lib/python3.9/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_expressions/lib/python3.9/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_expressions/lib/python3.9/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_expressions/lib/python3.9/site-packages/urllib3/connectionpool.py:716\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 716\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    730\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_expressions/lib/python3.9/site-packages/urllib3/connectionpool.py:468\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    463\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    466\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    467\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_expressions/lib/python3.9/site-packages/urllib3/connectionpool.py:463\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 463\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    467\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_expressions/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_expressions/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_expressions/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_expressions/lib/python3.9/socket.py:716\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 716\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_expressions/lib/python3.9/ssl.py:1275\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1274\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_expressions/lib/python3.9/ssl.py:1133\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "google_search_images(API_KEY, CSE_ID, QUERY, OUTPUT_DIR, NUM_IMAGES, BATCH_SIZE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_expressions)",
   "language": "python",
   "name": "ml_expressions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
