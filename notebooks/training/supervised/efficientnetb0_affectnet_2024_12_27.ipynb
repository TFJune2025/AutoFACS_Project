{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3944606f-c331-4646-a9c1-89688c455931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 12:26:37.322689: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from autogluon.multimodal import MultiModalPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44c6103e-0b07-4754-a5d9-8f2cfb5ebe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data\n",
    "X = np.load(\"preproc_affectnet/X_affectnet.npy\")\n",
    "y = np.load(\"preproc_affectnet/y_affectnet.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d42964e-00ba-47aa-9e1f-1f51ff8478ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data (if needed) to add a grayscale channel\n",
    "if len(X.shape) == 3:\n",
    "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c5d76db-002c-4bd0-82b0-c3617669f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1551ceb-68dd-4841-ae48-916f5c04dea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the labels\n",
    "num_classes = len(np.unique(y))  # Determine the number of unique classes\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_val = to_categorical(y_val, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de94b822-a7af-4d1f-850d-42d9fd7cba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights to handle imbalanced datasets\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y),\n",
    "    y=y\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47e18a84-099c-4abb-a866-695dc3283538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define EfficientNetB0 Model\n",
    "base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(48, 48, 3))\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Lambda(lambda x: tf.image.grayscale_to_rgb(x)),  # Convert grayscale to RGB\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bda665e-ed2f-42b3-be9e-fde73cac3b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"final_trained_model.keras\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\"),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=3, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "095f829c-275e-4e74-a296-2cb64a443311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 393ms/step - accuracy: 0.3053 - loss: 1.8526 - val_accuracy: 0.1576 - val_loss: 2.2258 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 395ms/step - accuracy: 0.5054 - loss: 1.3543 - val_accuracy: 0.2901 - val_loss: 1.8122 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 392ms/step - accuracy: 0.5541 - loss: 1.2309 - val_accuracy: 0.1576 - val_loss: 2.9853 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 391ms/step - accuracy: 0.6022 - loss: 1.1380 - val_accuracy: 0.1782 - val_loss: 2.5476 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - accuracy: 0.6245 - loss: 1.0870  \n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 393ms/step - accuracy: 0.6245 - loss: 1.0870 - val_accuracy: 0.1576 - val_loss: 2.5968 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 416ms/step - accuracy: 0.6766 - loss: 0.9302 - val_accuracy: 0.1326 - val_loss: 3.0262 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 433ms/step - accuracy: 0.7183 - loss: 0.8352 - val_accuracy: 0.4617 - val_loss: 1.4762 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 447ms/step - accuracy: 0.7282 - loss: 0.7947 - val_accuracy: 0.3745 - val_loss: 2.4210 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 476ms/step - accuracy: 0.7487 - loss: 0.7458 - val_accuracy: 0.3545 - val_loss: 1.9727 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - accuracy: 0.7721 - loss: 0.6820  \n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 457ms/step - accuracy: 0.7721 - loss: 0.6820 - val_accuracy: 0.1492 - val_loss: 4.0670 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 383ms/step - accuracy: 0.7907 - loss: 0.6254 - val_accuracy: 0.6123 - val_loss: 1.1906 - learning_rate: 1.0000e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 382ms/step - accuracy: 0.7998 - loss: 0.5925 - val_accuracy: 0.6273 - val_loss: 1.1748 - learning_rate: 1.0000e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 383ms/step - accuracy: 0.8030 - loss: 0.5876 - val_accuracy: 0.6204 - val_loss: 1.2201 - learning_rate: 1.0000e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 385ms/step - accuracy: 0.8090 - loss: 0.5728 - val_accuracy: 0.6238 - val_loss: 1.2133 - learning_rate: 1.0000e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - accuracy: 0.8036 - loss: 0.5869  \n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 386ms/step - accuracy: 0.8036 - loss: 0.5868 - val_accuracy: 0.6225 - val_loss: 1.2299 - learning_rate: 1.0000e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 386ms/step - accuracy: 0.8074 - loss: 0.5703 - val_accuracy: 0.6299 - val_loss: 1.2123 - learning_rate: 1.0000e-06\n",
      "Epoch 17/20\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 385ms/step - accuracy: 0.8101 - loss: 0.5606 - val_accuracy: 0.6281 - val_loss: 1.2121 - learning_rate: 1.0000e-06\n",
      "Epoch 17: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,  # Adjust epochs as needed\n",
    "    batch_size=32,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94d0fbab-ab78-4d71-8ff4-c2aebca34065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - accuracy: 0.6165 - loss: 1.2496\n",
      "Validation Accuracy with EfficientNetB0: 62.81%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=1)\n",
    "print(f\"Validation Accuracy with EfficientNetB0: {val_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3db0033f-ec73-4ef5-8267-a3e1202559ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoGluon MultiModalPredictor\n",
    "# Prepare the AutoGluon data using the saved dataset\n",
    "autogluon_data = pd.DataFrame({\n",
    "    \"image\": [Image.fromarray((x.squeeze() * 255).astype(np.uint8), \"L\").convert(\"RGB\") for x in X],\n",
    "    \"label\": y\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28d35890-a3c6-450b-a309-3daecf9c1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to Pandas DataFrame for AutoGluon compatibility\n",
    "X_df = pd.DataFrame(X.reshape(X.shape[0], -1))  # Flatten the image data\n",
    "y_df = pd.DataFrame(y, columns=[\"label\"])  # Add the label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95ae0dd3-fd13-4012-a325-8d33b61efd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features and labels into one DataFrame\n",
    "autogluon_data = pd.concat([X_df, y_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81797f89-cfb5-46e7-86c5-ff5cc07014ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241227_201239\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.9.21\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Jun 24 00:56:10 PDT 2024; root:xnu-8020.240.18.709.2~1/RELEASE_X86_64\n",
      "CPU Count:          8\n",
      "Pytorch Version:    2.2.2\n",
      "CUDA Version:       CUDA is not available\n",
      "Memory Avail:       6.24 GB / 16.00 GB (39.0%)\n",
      "Disk Space Avail:   136.15 GB / 233.57 GB (58.3%)\n",
      "===================================================\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t8 unique label values:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "\n",
      "AutoMM starts to create your model. ✨✨✨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir /Users/natalyagrokh/AI/ml_expressions/Facial_Recognition (JoshBrew)/AutogluonModels/ag-20241227_201239\n",
      "    ```\n",
      "\n",
      "Seed set to 0\n",
      "GPU Count: 0\n",
      "GPU Count to be Used: 0\n",
      "\n",
      "/opt/anaconda3/envs/ml_expressions/lib/python3.9/site-packages/autogluon/multimodal/utils/environment.py:131: UserWarning: Only CPU is detected in the instance. This may result in slow speed for MultiModalPredictor. Consider using an instance with GPU support.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name              | Type               | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | model             | FT_Transformer     | 1.7 M  | train\n",
      "1 | validation_metric | MulticlassAccuracy | 0      | train\n",
      "2 | loss_func         | CrossEntropyLoss   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "1.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 M     Total params\n",
      "6.816     Total estimated model params size (MB)\n",
      "65        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d199dc804f4f40c89c215285206f3d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize and train the AutoGluon predictor\n",
    "predictor = MultiModalPredictor(label=\"label\")\n",
    "predictor.fit(autogluon_data, presets=\"best_quality\", time_limit=3600)\n",
    "print(\"AutoGluon training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9d26a3-5194-4eed-8e11-21c20b41162d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_expressions)",
   "language": "python",
   "name": "ml_expressions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
