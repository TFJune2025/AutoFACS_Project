{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3944606f-c331-4646-a9c1-89688c455931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 16:43:59.578833: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-16 16:44:02.430178: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda-11.8/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.6/lib64\n",
      "2025-02-16 16:44:02.430416: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda-11.8/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.6/lib64\n",
      "2025-02-16 16:44:02.430445: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, Input, GlobalAveragePooling2D, Lambda\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44c6103e-0b07-4754-a5d9-8f2cfb5ebe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data\n",
    "X = np.load(\"/home/natalyagrokh/imgs_preprocessed/preproc_affectnet/X_affectnet.npy\")\n",
    "y = np.load(\"/home/natalyagrokh/imgs_preprocessed/preproc_affectnet/y_affectnet.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d42964e-00ba-47aa-9e1f-1f51ff8478ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data (if needed) to add a grayscale channel\n",
    "if len(X.shape) == 3:\n",
    "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c5d76db-002c-4bd0-82b0-c3617669f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1551ceb-68dd-4841-ae48-916f5c04dea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the labels\n",
    "num_classes = len(np.unique(y))  # Determine the number of unique classes\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_val = to_categorical(y_val, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de94b822-a7af-4d1f-850d-42d9fd7cba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights to handle imbalanced datasets\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y),\n",
    "    y=y\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47e18a84-099c-4abb-a866-695dc3283538",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 16:44:13.267855: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-16 16:44:13.682719: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-16 16:44:13.688067: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-16 16:44:13.692801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-16 16:44:13.694452: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-16 16:44:13.697750: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-16 16:44:13.700830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-16 16:44:14.049184: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-16 16:44:14.052561: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      " I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-16 16:44:14.057309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13764 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "# Define EfficientNetB0 Model\n",
    "base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(48, 48, 3))\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bda665e-ed2f-42b3-be9e-fde73cac3b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        \"final_trained_model_weights.h5\", \n",
    "        monitor=\"val_accuracy\", \n",
    "        save_best_only=True, \n",
    "        mode=\"max\", \n",
    "        save_weights_only=True\n",
    "    ),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=3, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "095f829c-275e-4e74-a296-2cb64a443311",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48, 48, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48, 48, 3), dtype=tf.float32, name='efficientnetb0_input'), name='efficientnetb0_input', description=\"created by layer 'efficientnetb0_input'\"), but it was called on an input with incompatible shape (None, 48, 48, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48, 48, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48, 48, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, 48, 48, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48, 48, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48, 48, 3), dtype=tf.float32, name='efficientnetb0_input'), name='efficientnetb0_input', description=\"created by layer 'efficientnetb0_input'\"), but it was called on an input with incompatible shape (None, 48, 48, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48, 48, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48, 48, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, 48, 48, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 16:44:36.556048: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/efficientnetb0/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-02-16 16:44:39.465769: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8907\n",
      "2025-02-16 16:44:40.390559: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7efd4407cd80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-02-16 16:44:40.390595: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2025-02-16 16:44:40.445847: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-02-16 16:44:40.912471: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 48, 48, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48, 48, 3), dtype=tf.float32, name='efficientnetb0_input'), name='efficientnetb0_input', description=\"created by layer 'efficientnetb0_input'\"), but it was called on an input with incompatible shape (None, 48, 48, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48, 48, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48, 48, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, 48, 48, 1).\n",
      "776/776 [==============================] - 72s 42ms/step - loss: 1.6504 - accuracy: 0.3727 - val_loss: 2.4652 - val_accuracy: 0.1268 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "776/776 [==============================] - 32s 41ms/step - loss: 1.3384 - accuracy: 0.5165 - val_loss: 3.0159 - val_accuracy: 0.0922 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "776/776 [==============================] - 29s 38ms/step - loss: 1.2308 - accuracy: 0.5667 - val_loss: 2.8913 - val_accuracy: 0.2109 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "776/776 [==============================] - ETA: 0s - loss: 1.1557 - accuracy: 0.5998 \n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "776/776 [==============================] - 32s 41ms/step - loss: 1.1557 - accuracy: 0.5998 - val_loss: 2.9064 - val_accuracy: 0.1229 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "776/776 [==============================] - 29s 37ms/step - loss: 0.9885 - accuracy: 0.6594 - val_loss: 4.6908 - val_accuracy: 0.1272 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "776/776 [==============================] - 31s 41ms/step - loss: 0.9327 - accuracy: 0.6832 - val_loss: 4.1774 - val_accuracy: 0.1464 - lr: 1.0000e-04\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,  # Adjust epochs as needed\n",
    "    batch_size=32,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94d0fbab-ab78-4d71-8ff4-c2aebca34065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 4s 18ms/step - loss: 4.1774 - accuracy: 0.1464\n",
      "Validation Accuracy with EfficientNetB0: 14.64%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=1)\n",
    "print(f\"Validation Accuracy with EfficientNetB0: {val_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4a90485-a3e0-4e77-94ca-9b4d91379632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 81). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: final_efficientnet_trained_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: final_efficientnet_trained_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full model saved successfully as a SavedModel in 'final_efficientnet_trained_model'.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Save the entire model using the lower-level API.\n",
    "tf.saved_model.save(model, \"final_efficientnet_trained_model\")\n",
    "print(\"Full model saved successfully as a SavedModel in 'final_efficientnet_trained_model'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48f690c6-1d2e-47ff-988b-dc4d275a1561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture saved to JSON at /home/natalyagrokh/img_expressions/final_efficientnet_trained_model_2_architecture.json.\n",
      "Model weights saved to H5 at /home/natalyagrokh/img_expressions/final_efficientnet_trained_model_2_weights.h5.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define a custom encoder to handle EagerTensors\n",
    "def custom_encoder(o):\n",
    "    # If the object is an EagerTensor, convert it to a list.\n",
    "    if hasattr(o, \"numpy\"):\n",
    "        return o.numpy().tolist()\n",
    "    # Otherwise, use the default string representation.\n",
    "    raise TypeError(f\"Object of type {type(o)} is not JSON serializable\")\n",
    "\n",
    "# Get the model configuration dictionary.\n",
    "model_config = model._updated_config()\n",
    "\n",
    "# Serialize the configuration with the custom encoder.\n",
    "model_json = json.dumps(model_config, default=custom_encoder)\n",
    "\n",
    "# Save the architecture to a JSON file.\n",
    "arch_path = \"/home/natalyagrokh/img_expressions/final_efficientnet_trained_model_2_architecture.json\"\n",
    "with open(arch_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "print(f\"Model architecture saved to JSON at {arch_path}.\")\n",
    "\n",
    "# Save the model weights to an H5 file.\n",
    "weights_path = \"/home/natalyagrokh/img_expressions/final_efficientnet_trained_model_2_weights.h5\"\n",
    "model.save_weights(weights_path)\n",
    "print(f\"Model weights saved to H5 at {weights_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28d35890-a3c6-450b-a309-3daecf9c1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # doesn't work -> throws a type error\n",
    "# model.save(\"final_efficientnet_trained_model.h5\", save_format=\"h5\")\n",
    "# print(\"Keras model saved successfully as 'final_efficientnet_trained_model'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb9383f-b863-42b1-90f7-2ed51a6a188b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_expressions) (Local)",
   "language": "python",
   "name": "ml_expressions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
