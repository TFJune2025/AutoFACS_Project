{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd75e632-a752-4170-a436-0a2d1bf1a03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# ==============================================================================\n",
    "# SCRIPT: V30_Training_Script.py\n",
    "#\n",
    "# PURPOSE:\n",
    "# This script trains a multi-class classification model (V30) for emotion\n",
    "# recognition. It is an updated version of the V29 script, modified to\n",
    "# incorporate new 'speech_action' and 'hard_case' labels to improve\n",
    "# robustness and handle ambiguity.\n",
    "# ==============================================================================\n",
    "\n",
    "#%%\n",
    "# V30 changes:\n",
    "    # section #1 - Added 'speech_action' and 'hard_case' to the list of labels.\n",
    "    # section #2 - Updated TargetedSmoothedCrossEntropyLoss to also disable smoothing for the new labels.\n",
    "    # section #8 - Added new labels to the targeted augmentation list.\n",
    "    # section #10 - Added new labels to the weighted sampling list.\n",
    "    # overview: Fully integrate 'speech_action' and 'hard_case' into the training pipeline.\n",
    "\n",
    "#%%\n",
    "# --------------------------\n",
    "# 0. Imports\n",
    "# --------------------------\n",
    "# Standard Library Imports\n",
    "import datasets\n",
    "import csv\n",
    "import gc\n",
    "import glob\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Third-Party Imports\n",
    "import accelerate\n",
    "import dill\n",
    "import face_recognition\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import transformers\n",
    "\n",
    "# From Imports\n",
    "from collections import Counter\n",
    "from datasets import ClassLabel, Dataset, Features, Image as DatasetsImage, concatenate_datasets, load_dataset\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from imagehash import phash, hex_to_hash\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageOps, ExifTags, UnidentifiedImageError\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, log_loss, precision_recall_fscore_support\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import AdamW, LBFGS\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import (\n",
    "    GaussianBlur,\n",
    "    RandAugment,\n",
    "    RandomAffine,\n",
    "    RandomApply,\n",
    "    RandomPerspective,\n",
    "    RandomAdjustSharpness,\n",
    "    ToPILImage,\n",
    "    ToTensor\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    AutoModelForImageClassification,\n",
    "    EarlyStoppingCallback,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "\n",
    "#%%\n",
    "# --------------------------\n",
    "# 1. Global Configurations\n",
    "# --------------------------\n",
    "RUN_INFERENCE = True  # Toggle this off to disable running inference\n",
    "\n",
    "# MODIFICATION: Instruct user to update this path to their new consolidated dataset.\n",
    "# --- IMPORTANT: Update this path to your new dataset folder ---\n",
    "# This folder should contain subdirectories for the original 10 emotions\n",
    "# PLUS the new 'speech_action' and 'hard_case' folders.\n",
    "IMAGE_DIR = \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/consolidated_dataset_for_v30\"\n",
    "BASE_PATH = IMAGE_DIR\n",
    "MODEL_ROOT = \"/Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training\"\n",
    "\n",
    "# MODIFICATION: Added 'speech_action' and 'hard_case' to the list of labels.\n",
    "LABEL_NAMES = [\n",
    "    'anger', 'disgust', 'fear', 'happiness', 'neutral',\n",
    "    'questioning', 'sadness', 'surprise', 'contempt', 'unknown',\n",
    "    'speech_action', 'hard_case'\n",
    "]\n",
    "id2label = dict(enumerate(LABEL_NAMES))\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "HARD_CLASS_NAMES = ['contempt', 'disgust', 'fear', 'questioning']\n",
    "hard_class_ids = [label2id[n] for n in HARD_CLASS_NAMES]\n",
    "\n",
    "VALID_EXTENSIONS = (\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\")\n",
    "\n",
    "def is_valid_image(filename):\n",
    "    return filename.lower().endswith(VALID_EXTENSIONS) and not filename.startswith(\"._\")\n",
    "\n",
    "label_mapping = {name.lower(): name for name in LABEL_NAMES}\n",
    "\n",
    "# üî¢ Dynamically determine the next version\n",
    "def get_next_version(base_dir):\n",
    "    all_entries = glob.glob(os.path.join(base_dir, \"V*_*\"))\n",
    "    existing = [\n",
    "        os.path.basename(d) for d in all_entries if os.path.isdir(d)\n",
    "    ]\n",
    "    versions = [\n",
    "        int(d[1:].split(\"_\")[0]) for d in existing\n",
    "        if d.startswith(\"V\") and \"_\" in d and d[1:].split(\"_\")[0].isdigit()\n",
    "    ]\n",
    "    next_version = max(versions, default=0) + 1\n",
    "    return f\"V{next_version}\"\n",
    "\n",
    "# Automatically create a versioned output folder\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "VERSION = get_next_version(\"/Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training\")\n",
    "VERSION_TAG = VERSION + \"_\" + timestamp\n",
    "SAVE_DIR = os.path.join(\"/Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training\", VERSION_TAG)\n",
    "LOGITS_PATH = os.path.join(SAVE_DIR, f\"logits_eval_{VERSION}.npy\")\n",
    "LABELS_PATH = os.path.join(SAVE_DIR, f\"labels_eval_{VERSION}.npy\")\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "print(f\"üìÅ Output directory created: {SAVE_DIR}\")\n",
    "\n",
    "\n",
    "#%%\n",
    "# --------------------------\n",
    "# 2. Utility Functions (Metrics & Calibration)\n",
    "# --------------------------\n",
    "\n",
    "# ------------------------------------------\n",
    "# Part A: Data Preparation & Augmentation\n",
    "# ------------------------------------------\n",
    "\n",
    "# üó∫Ô∏è Injects 'image_path' to dataset BEFORE any map/filter\n",
    "def add_image_path(example):\n",
    "    img_obj = example[\"image\"]\n",
    "    path = getattr(img_obj, \"filename\", None)\n",
    "    if path is None:\n",
    "        if \"file\" in example:\n",
    "            path = os.path.join(BASE_PATH, example[\"file\"])\n",
    "        else:\n",
    "            path = \"\"\n",
    "    example[\"image_path\"] = path\n",
    "    return example\n",
    "\n",
    "# üè∑Ô∏è Standardizes labels from various sources (int, str, filepath) to a consistent integer ID.\n",
    "def reconcile_labels(example):\n",
    "    label = example.get(\"label\", None)\n",
    "    if isinstance(label, int):\n",
    "        original_label = dataset.features[\"label\"].int2str(label).strip().lower()\n",
    "    elif isinstance(label, str):\n",
    "        original_label = label.strip().lower()\n",
    "    else:\n",
    "        file_path = example[\"image_path\"]\n",
    "        original_label = os.path.basename(os.path.dirname(file_path)).lower() if file_path else None\n",
    "    \n",
    "    pretrain_label = label_mapping.get(original_label)\n",
    "    example[\"label\"] = label2id[pretrain_label] if pretrain_label is not None else -1\n",
    "    return example\n",
    "\n",
    "# üîç Computes a perceptual hash (pHash) for an image to find visually similar duplicates.\n",
    "def compute_hash(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"L\").resize((64, 64))\n",
    "        return str(phash(img))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# üì¶ Applies augmentations and processes images on-the-fly for each batch.\n",
    "class DataCollatorWithAugmentation:\n",
    "    def __init__(self, processor, augment_dict):\n",
    "        self.processor = processor\n",
    "        self.augment_dict = augment_dict\n",
    "\n",
    "    def __call__(self, features):\n",
    "        processed_images = []\n",
    "        for x in features:\n",
    "            label = x[\"label\"]\n",
    "            aug_pipeline = self.augment_dict.get(label, data_augment)\n",
    "            rgb_image = x[\"image\"].convert(\"RGB\")\n",
    "            augmented_image = aug_pipeline(rgb_image)\n",
    "            processed_images.append(augmented_image)\n",
    "\n",
    "        batch = self.processor(\n",
    "            images=processed_images,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        batch[\"labels\"] = torch.tensor([x[\"label\"] for x in features], dtype=torch.long)\n",
    "        return batch\n",
    "\n",
    "# ------------------------------------------\n",
    "# Part B: Model & Training Components\n",
    "# ------------------------------------------\n",
    "      \n",
    "# üèãÔ∏è Defines a custom Trainer that uses targeted loss function\n",
    "class CustomLossTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_fct = TargetedSmoothedCrossEntropyLoss(smoothing=0.05)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss = self.loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "        \n",
    "# üîÑ Implements Cross-Entropy Loss with Targeted Label Smoothing for multiple classes\n",
    "# Smoothing turned OFF for 'contempt', 'disgust', and now 'speech_action', 'hard_case'\n",
    "class TargetedSmoothedCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, smoothing=0.05):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "        # MODIFICATION: Added 'speech_action' and 'hard_case' to ensure the model\n",
    "        # makes confident, sharp predictions for these critical new classes.\n",
    "        self.target_class_ids = [label2id['contempt'], label2id['disgust'], label2id['speech_action'], label2id['hard_case']]\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        num_classes = logits.size(1)\n",
    "        with torch.no_grad():\n",
    "            smooth_labels = torch.full_like(logits, self.smoothing / (num_classes - 1))\n",
    "            smooth_labels.scatter_(1, target.unsqueeze(1), 1.0 - self.smoothing)\n",
    "            \n",
    "            target_mask = torch.isin(target, torch.tensor(self.target_class_ids, device=target.device))\n",
    "            \n",
    "            if target_mask.any():\n",
    "                sharp_labels = F.one_hot(target[target_mask], num_classes=num_classes).float()\n",
    "                smooth_labels[target_mask] = sharp_labels\n",
    "        \n",
    "        log_probs = F.log_softmax(logits, dim=1)\n",
    "        loss = -(smooth_labels * log_probs).sum(dim=1).mean()\n",
    "        return loss\n",
    "\n",
    "# üìä Compute Metrics with Confusion Matrix Logging\n",
    "def compute_metrics_with_confusion(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    report = classification_report(labels, preds, target_names=LABEL_NAMES, output_dict=True)\n",
    "    print(classification_report(labels, preds, target_names=LABEL_NAMES))\n",
    "\n",
    "    np.save(os.path.join(SAVE_DIR, f\"logits_eval_{VERSION}.npy\"), logits)\n",
    "    np.save(os.path.join(SAVE_DIR, f\"labels_eval_{VERSION}.npy\"), labels)\n",
    "\n",
    "    f1s = [report[name][\"f1-score\"] for name in LABEL_NAMES]\n",
    "    recalls = [report[name][\"recall\"] for name in LABEL_NAMES]\n",
    "    precisions = [report[name][\"precision\"] for name in LABEL_NAMES]\n",
    "\n",
    "    softmax_probs = F.softmax(torch.tensor(logits), dim=-1)\n",
    "    entropies = -torch.sum(softmax_probs * torch.log(softmax_probs + 1e-12), dim=-1)\n",
    "    entropy_per_class = []\n",
    "    for idx, class_name in enumerate(LABEL_NAMES):\n",
    "        mask = (np.array(labels) == idx)\n",
    "        if mask.any():\n",
    "            class_entropy = entropies[mask].mean().item()\n",
    "            entropy_per_class.append((class_name, class_entropy))\n",
    "        else:\n",
    "            entropy_per_class.append((class_name, 0.0))\n",
    "    sorted_entropy = sorted(entropy_per_class, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    epoch_metrics_path = os.path.join(SAVE_DIR, \"per_class_metrics.csv\")\n",
    "    epoch = getattr(trainer.state, \"epoch\", None) if \"trainer\" in globals() else None\n",
    "    df_row = pd.DataFrame({\n",
    "        \"epoch\": [epoch],\n",
    "        **{f\"f1_{n}\": [f] for n, f in zip(LABEL_NAMES, f1s)},\n",
    "        **{f\"recall_{n}\": [r] for n, r in zip(LABEL_NAMES, recalls)},\n",
    "        **{f\"precision_{n}\": [p] for n, p in zip(LABEL_NAMES, precisions)},\n",
    "        **{f\"entropy_{n}\": [e] for n, e in entropy_per_class}\n",
    "    })\n",
    "    if os.path.exists(epoch_metrics_path):\n",
    "        df_row.to_csv(epoch_metrics_path, mode=\"a\", header=False, index=False)\n",
    "    else:\n",
    "        df_row.to_csv(epoch_metrics_path, mode=\"w\", header=True, index=False)\n",
    "\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    plt.figure(figsize=(10, 8)) # Increased figure size for more labels\n",
    "    sns.heatmap(\n",
    "        cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "        xticklabels=LABEL_NAMES,\n",
    "        yticklabels=LABEL_NAMES\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(SAVE_DIR, f\"confusion_matrix_epoch_{VERSION}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    confusion_pairs = [\n",
    "        ((LABEL_NAMES[i], LABEL_NAMES[j]), cm[i][j])\n",
    "        for i in range(len(LABEL_NAMES))\n",
    "        for j in range(len(LABEL_NAMES)) if i != j\n",
    "    ]\n",
    "    top_confusions = sorted(confusion_pairs, key=lambda x: x[1], reverse=True)[:5] # Increased to top 5\n",
    "    print(\"\\nTop 5 confused class pairs:\")\n",
    "    for (true_label, pred_label), count in top_confusions:\n",
    "        print(f\"  - {true_label} ‚Üí {pred_label}: {count} instances\")\n",
    "\n",
    "    avg_entropy = entropies.mean().item()\n",
    "    print(f\"\\nüß† Avg prediction entropy: {avg_entropy:.4f}\")\n",
    "\n",
    "    print(\"\\nüîç Class entropies (sorted):\")\n",
    "    for class_name, entropy in sorted_entropy:\n",
    "        print(f\"  - {class_name}: entropy = {entropy:.4f}\")\n",
    "\n",
    "    accuracy = (preds == labels).mean()\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "# ... (Other utility functions like save_model_and_processor remain the same) ...\n",
    "\n",
    "#%%\n",
    "# --------------------------\n",
    "# 3. Auto-Load V29 Golden Checkpoint\n",
    "# --------------------------\n",
    "# MODIFICATION: Now loading from V29 as the starting point.\n",
    "model_path = \"/Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V29_20250710_082807\"\n",
    "print(f\"‚úÖ Explicitly loading V29 checkpoint from: {model_path}\")\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(model_path)\n",
    "processor = AutoImageProcessor.from_pretrained(model_path)\n",
    "\n",
    "# Reset the classifier head for new training with the new labels\n",
    "model.classifier = nn.Linear(model.config.hidden_size, len(LABEL_NAMES))\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id\n",
    "model.config.num_labels = len(LABEL_NAMES)\n",
    "print(\"‚úÖ Classifier head reset for new training.\")\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"\\nüñ•Ô∏è Using device:\", device)\n",
    "model.to(device).eval()\n",
    "\n",
    "\n",
    "#%%\n",
    "# --------------------------\n",
    "# 4. Load and Prepare Dataset\n",
    "# --------------------------\n",
    "# (This section remains largely the same, assuming IMAGE_DIR points to the new dataset)\n",
    "print(\"üîç Counting valid image files on disk for verification...\")\n",
    "expected_file_count = len(\n",
    "    [p for p in Path(BASE_PATH).rglob(\"*\") if is_valid_image(p.name)]\n",
    ")\n",
    "print(f\"‚úÖ Found {expected_file_count} image files in {BASE_PATH}\")\n",
    "\n",
    "datasets.disable_caching()\n",
    "print(\"‚úÖ Datasets caching disabled for this run to ensure fresh data load.\")\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"imagefolder\",\n",
    "    data_dir=BASE_PATH,\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "dataset = dataset.map(add_image_path, desc=\"Add file path to each record\")\n",
    "dataset = dataset.map(reconcile_labels, desc=\"Re-labeling dataset (preserving image_path)\")\n",
    "dataset = dataset.filter(lambda x: x[\"label\"] != -1)\n",
    "\n",
    "final_count = len(dataset)\n",
    "print(f\"‚úÖ Total examples after filtering: {final_count}\")\n",
    "\n",
    "\n",
    "#%%\n",
    "# --------------------------\n",
    "# 5. Data Curation (If needed, e.g., removing hard negatives from a previous run)\n",
    "# --------------------------\n",
    "# For V30, we are starting fresh with the new labels, so we skip the hard-negative\n",
    "# removal from V24. If you have a new exclusion list, you can add that logic here.\n",
    "curated_dataset = dataset\n",
    "print(\"‚úÖ Using the full dataset for V30 training.\")\n",
    "\n",
    "\n",
    "#%%\n",
    "# --------------------------\n",
    "# 6. Dataset Label Overview\n",
    "# --------------------------\n",
    "# (This section remains the same, will now show counts for new labels)\n",
    "# ...\n",
    "\n",
    "\n",
    "#%%\n",
    "# --------------------------\n",
    "# 7. Perceptual Clustering\n",
    "# --------------------------\n",
    "# (This section can remain the same)\n",
    "# ...\n",
    "\n",
    "#%%\n",
    "# --------------------------\n",
    "# 8. Class Frequency-Aware Augmentation Targeting\n",
    "# --------------------------\n",
    "label_freqs = Counter(curated_dataset[\"label\"])\n",
    "label_id2name = {v: k for k, v in label2id.items()}\n",
    "label_name2id = {v: k for k, v in label_id2name.items()}\n",
    "\n",
    "minority_by_count = sorted(label_freqs, key=label_freqs.get)[:3]\n",
    "minority_by_name = [label_id2name[i] for i in minority_by_count]\n",
    "minority_by_name = [n for n in minority_by_name if n != \"unknown\"]\n",
    "\n",
    "# MODIFICATION: Added 'speech_action' and 'hard_case' to the manual focus list\n",
    "# to ensure they receive strong augmentation.\n",
    "manual_focus_classes = ['disgust', 'questioning', 'contempt', 'speech_action', 'hard_case']\n",
    "\n",
    "minority_class_names = list(set(minority_by_name + manual_focus_classes))\n",
    "minority_classes = [label_name2id[name] for name in minority_class_names]\n",
    "print(f\"üéØ Targeted minority augmentation will apply to: {minority_class_names}\")\n",
    "\n",
    "\n",
    "#%%\n",
    "# --------------------------\n",
    "# 9. Define Data Augmentation\n",
    "# --------------------------\n",
    "# (This section remains the same)\n",
    "data_augment = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(10),\n",
    "    T.ColorJitter(brightness=0.1, contrast=0.1)\n",
    "])\n",
    "\n",
    "minority_aug = T.Compose([\n",
    "    RandAugment(num_ops=2, magnitude=9),\n",
    "    T.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    T.ColorJitter(0.3, 0.3, 0.3, 0.1),\n",
    "])\n",
    "print(\"‚úÖ Augmentation pipelines defined.\")\n",
    "\n",
    "\n",
    "#%%\n",
    "# --------------------------\n",
    "# 10. Balance Dataset\n",
    "# --------------------------\n",
    "# (This section's logic is mostly the same, but the hard_classes list is updated)\n",
    "MINORITY_CAP = 2250 # You may need to adjust this based on the size of your new classes\n",
    "balanced_subsets = []\n",
    "label_counts = Counter(curated_dataset[\"label\"])\n",
    "print(\"Original label distribution:\", label_counts)\n",
    "\n",
    "for label, count in label_counts.items():\n",
    "    subset = curated_dataset.filter(lambda x: x['label'] == label, num_proc=1)\n",
    "    class_name = LABEL_NAMES[label]\n",
    "    if class_name == \"unknown\":\n",
    "        balanced_subsets.append(subset)\n",
    "    elif count < MINORITY_CAP:\n",
    "        multiplier = MINORITY_CAP // len(subset)\n",
    "        remainder = MINORITY_CAP % len(subset)\n",
    "        subset = concatenate_datasets([subset] * multiplier + [subset.select(range(remainder))])\n",
    "        balanced_subsets.append(subset)\n",
    "    else:\n",
    "        balanced_subsets.append(subset)\n",
    "\n",
    "train_dataset = concatenate_datasets(balanced_subsets).shuffle(seed=42)\n",
    "print(\"After balancing:\", Counter(train_dataset['label']))\n",
    "\n",
    "# MODIFICATION: Added 'speech_action' and 'hard_case' to the weighted sampling.\n",
    "# This gives them 2x importance during training.\n",
    "hard_classes = ['contempt', 'disgust', 'questioning', 'surprise', 'fear', 'speech_action', 'hard_case']\n",
    "hard_class_ids = [label2id[c] for c in hard_classes]\n",
    "\n",
    "weights = [2.0 if l in hard_class_ids else 1.0 for l in train_dataset[\"label\"]]\n",
    "weights = torch.DoubleTensor(weights)\n",
    "sampler = torch.utils.data.WeightedRandomSampler(\n",
    "    weights=weights,\n",
    "    num_samples=len(weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "# ... (the rest of the script for splitting, training, and analysis remains the same) ...\n",
    "\n",
    "#%%\n",
    "# --------------------------\n",
    "# 11. Optimizer, Scheduler, and Training\n",
    "# --------------------------\n",
    "\n",
    "# --- Part A: Train/Validation Split on CURATED Data ---\n",
    "split_dataset = curated_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "eval_dataset = split_dataset[\"test\"]\n",
    "print(f\"‚úÖ Curated data split into {len(train_dataset)} training and {len(eval_dataset)} validation samples.\")\n",
    "\n",
    "\n",
    "# --- Part B: Define Training Arguments ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=SAVE_DIR,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    learning_rate=4e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    logging_dir=os.path.join(SAVE_DIR, \"logs\"),\n",
    "    logging_strategy=\"epoch\",\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=3,\n",
    "    early_stopping_threshold=0.001\n",
    ")\n",
    "\n",
    "# --- Part C: Instantiate the Data Collator ---\n",
    "minority_augment_map = {label_id: minority_aug for label_id in minority_classes}\n",
    "data_collator = DataCollatorWithAugmentation(\n",
    "    processor=processor,\n",
    "    augment_dict=minority_augment_map\n",
    ")\n",
    "\n",
    "# --- Part D: Discriminative Learning Rate Optimizer Setup ---\n",
    "head_lr = 5e-5\n",
    "backbone_lr = 2e-7\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "for name, param in model.vit.encoder.layer[-4:].named_parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': model.classifier.parameters(), 'lr': head_lr},\n",
    "    {'params': model.vit.encoder.layer[-4:].parameters(), 'lr': backbone_lr}\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, weight_decay=0.01)\n",
    "\n",
    "# --- Part E: Trainer Initialization and Execution ---\n",
    "trainer = CustomLossTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics_with_confusion,\n",
    "    optimizers=(optimizer, None),\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[early_stop_callback]\n",
    ")\n",
    "\n",
    "# --- Part F: Train the Model and Finalize ---\n",
    "print(f\"\\n--- Starting {VERSION} Training with on-the-fly processing ---\")\n",
    "trainer.train()\n",
    "print(\"--- Training Finished ---\")\n",
    "\n",
    "# --- (The rest of the script, sections 12-19, for inference and analysis can remain the same) ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_expressions",
   "language": "python",
   "name": "ml_expressions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
