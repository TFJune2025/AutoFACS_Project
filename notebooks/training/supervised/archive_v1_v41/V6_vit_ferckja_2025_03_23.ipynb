{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0c4bf3f-ff2f-4c32-b3fe-e9f629103d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #In lambdalabs jupyter lab instance, run these:\n",
    "# pip install transformers\n",
    "# pip install tf-keras\n",
    "# pip install --upgrade \"numpy<2\"\n",
    "# pip install datasets\n",
    "# pip install --upgrade datasets pillow\n",
    "# pip install --upgrade \"accelerate>=0.26.0\"\n",
    "# #then check dependency warnings\n",
    "# pip check\n",
    "# #if any issues run these SEPARATELY!\n",
    "# pip install debugpy\n",
    "# c\n",
    "# # then install these\n",
    "# sudo apt-get update\n",
    "# sudo apt-get install python3-cairo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a44363c9-25c0-44ac-b96b-7750c9d67c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 13:58:37.628409: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742738317.651580    4431 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742738317.659552    4431 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742738317.678797    4431 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742738317.678880    4431 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742738317.678889    4431 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742738317.678897    4431 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-23 13:58:37.684825: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from datasets import load_dataset, Image as DatasetsImage\n",
    "from functools import partial\n",
    "from io import BytesIO\n",
    "from transformers import (\n",
    "    AutoImageProcessor, \n",
    "    AutoModelForImageClassification, \n",
    "    EarlyStoppingCallback,\n",
    "    TrainingArguments, \n",
    "    Trainer\n",
    ")\n",
    "from torch import nn\n",
    "from PIL import Image, ImageOps, ExifTags, UnidentifiedImageError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303f23fe-c59c-44c7-8267-db92d617acf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --------------------------\n",
    "# # 0. GPU Environment Setup for Multi-GPU Optimization (GPUs 0)\n",
    "# # --------------------------\n",
    "# # Limit process to specific GPUs\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# print(\"Process restricted to GPUs:\", os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "\n",
    "# # Ensure pip executables are available\n",
    "# os.environ[\"PATH\"] = f\"{os.path.expanduser('~/.local/bin')}:\" + os.environ[\"PATH\"]\n",
    "\n",
    "# # Enable memory growth for TensorFlow\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#         print(\"Memory growth enabled on GPUs.\")\n",
    "#     except RuntimeError as e:\n",
    "#         print(\"Error configuring GPUs:\", e)\n",
    "# print(\"GPUs available to this process (as seen by TensorFlow):\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# # Optional: Monitor current GPU usage\n",
    "# gpu_usage = subprocess.check_output([\"nvidia-smi\"]).decode(\"utf-8\")\n",
    "# print(\"Current GPU usage:\\n\", gpu_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a085a370-8ea9-47a9-9125-3ddc4e5ac28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTForImageClassification(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 1. Load Model (V4 base)\n",
    "# --------------------------\n",
    "model_path = \"/home/ubuntu/MLexpressionsStorage/vit_final_independent_V4\"\n",
    "model = AutoModelForImageClassification.from_pretrained(model_path)\n",
    "processor = AutoImageProcessor.from_pretrained(model_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "222b5dff-a5f8-4800-80f3-b58c16fb5c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original unique labels: [0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 37081/37081 [00:05<00:00, 7077.46 examples/s]\n",
      "Filter: 100%|██████████| 37081/37081 [01:19<00:00, 468.21 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped unique labels (numerical): [0, 1, 2, 3, 6, 4, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 2. Prepare Dataset \n",
    "# --------------------------\n",
    "dataset = load_dataset(\n",
    "    \"imagefolder\",\n",
    "    data_dir=\"/home/ubuntu/MLexpressionsStorage/img_datasets/combo_ferckja_dataset\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "# ----- Label Reconciliation for Locally Pre-Trained Model -----\n",
    "# Assume 'dataset' is already loaded from your image folder dataset.\n",
    "# (For example, using: dataset = load_dataset(\"imagefolder\", data_dir=\"...\", split=\"train\"))\n",
    "\n",
    "# Optionally, inspect the original unique labels:\n",
    "try:\n",
    "    original_labels = dataset.unique(\"label\")\n",
    "    print(\"Original unique labels:\", original_labels)\n",
    "except Exception as e:\n",
    "    print(\"Unable to retrieve original unique labels:\", e)\n",
    "\n",
    "# Define a mapping from eight original labels to seven target classes\n",
    "# Update mapping using lowercase keys\n",
    "label_mapping = {\n",
    "    'anger': 'Angry', 'contempt': 'Disgust', 'disgust': 'Disgust',\n",
    "    'fear': 'Fear', 'happiness': 'Happy', 'sadness': 'Sad',\n",
    "    'surprise': 'Surprise', 'neutral': 'Neutral'\n",
    "}\n",
    "\n",
    "# Numerical mapping for the pre-trained model's labels.\n",
    "num_mapping = {\n",
    "    'Angry': 0, 'Disgust': 1, 'Fear': 2, 'Happy': 3,\n",
    "    'Sad': 4, 'Surprise': 5, 'Neutral': 6\n",
    "}\n",
    "\n",
    "def reconcile_labels(example):\n",
    "    # Convert the label to a lowercase string.\n",
    "    if isinstance(example[\"label\"], int):\n",
    "        # Convert integer label to string using the dataset's features.\n",
    "        original = dataset.features[\"label\"].int2str(example[\"label\"]).strip().lower()\n",
    "    else:\n",
    "        original = example[\"label\"].strip().lower()\n",
    "    \n",
    "    # Map the original label to the new label.\n",
    "    mapped = label_mapping.get(original)\n",
    "    if mapped is None:\n",
    "        # Mark unrecognized labels as -1 for filtering.\n",
    "        example[\"label\"] = -1\n",
    "    else:\n",
    "        # Convert to numerical label.\n",
    "        example[\"label\"] = num_mapping[mapped]\n",
    "    return example\n",
    "\n",
    "# Apply the mapping function.\n",
    "dataset = dataset.map(reconcile_labels)\n",
    "# Filter out any examples with unrecognized labels.\n",
    "dataset = dataset.filter(lambda x: x[\"label\"] != -1)\n",
    "\n",
    "# Verify the final set of labels (should be only 7 unique values).\n",
    "mapped_unique_labels = dataset.unique(\"label\")\n",
    "print(\"Mapped unique labels (numerical):\", mapped_unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ed3bd65-cca6-4ef2-9da7-a4ff5e14d3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 37081/37081 [07:52<00:00, 78.42 examples/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in dataset: [0, 1, 2, 3, 6, 4, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 3. Stronger Augmentation Pipeline\n",
    "# --------------------------\n",
    "data_augment = T.Compose([\n",
    "    T.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomVerticalFlip(p=0.2),\n",
    "    T.RandomRotation(15),\n",
    "    T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.05),\n",
    "    T.RandomGrayscale(p=0.1)\n",
    "])\n",
    "\n",
    "def transform(example):\n",
    "    image = example[\"image\"]\n",
    "    # Ensure image is loaded as a PIL Image\n",
    "    if not isinstance(image, Image.Image):\n",
    "        image = Image.open(image)\n",
    "    # Convert to RGB if needed\n",
    "    if image.mode != \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "    # Apply augmentation\n",
    "    image = data_augment(image)\n",
    "    # Process image using the processor (this produces a tensor in the correct format)\n",
    "    inputs = processor(image, return_tensors=\"pt\")\n",
    "    # Remove the extra batch dimension (we process images individually)\n",
    "    inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n",
    "    # Add the label back\n",
    "    inputs[\"labels\"] = example[\"label\"]\n",
    "    return inputs\n",
    "\n",
    "# Apply the transformation to the dataset while preserving the 'label' column.\n",
    "dataset = dataset.map(\n",
    "    partial(transform),\n",
    "    remove_columns=[col for col in dataset.column_names if col not in [\"label\", \"image\"]]\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# New Step: Compute Unique Labels from the Final Preprocessed Column\n",
    "# --------------------------\n",
    "unique_labels = dataset.unique(\"labels\")\n",
    "print(\"Unique labels in dataset:\", unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b603a2d1-4be2-4d09-b8f0-15d9173a955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 4. Train-Validation Split\n",
    "# --------------------------\n",
    "split_dataset = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "eval_dataset = split_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3e0db3c-19e1-4028-b656-2cc5f489ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 5. Define Training Arguments for Robust Fine-Tuning\n",
    "# --------------------------\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./vit_finetuned_v5\",    # Directory to save checkpoints and the final model\n",
    "    eval_strategy=\"epoch\",           # Evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",                 # Save checkpoint at each epoch\n",
    "    learning_rate=3e-5,                    # A conservative learning rate for fine-tuning\n",
    "    per_device_train_batch_size=8,         # Adjust based on your CPU memory limits\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,                    # Fine-tune for a few epochs (adjust as needed)\n",
    "    load_best_model_at_end=True,           # Automatically load the best model when training finishes\n",
    "    metric_for_best_model=\"accuracy\",      # Monitor accuracy for best model selection\n",
    "    logging_dir=\"./logs\",                  # Directory for TensorBoard logs\n",
    "    warmup_ratio=0.2,                      # Increased for smoother ramp-up\n",
    "    save_total_limit=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2017feae-0053-4b51-8104-c4133c8eb1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 6. Define a Compute Metrics Function for Evaluation\n",
    "# --------------------------\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70cce034-202d-42a6-a36b-69cca5cb287d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18541' max='18540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18540/18540 5:22:11, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.674800</td>\n",
       "      <td>0.693736</td>\n",
       "      <td>0.754213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.438400</td>\n",
       "      <td>0.734173</td>\n",
       "      <td>0.771201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.166300</td>\n",
       "      <td>1.020023</td>\n",
       "      <td>0.777134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>1.218053</td>\n",
       "      <td>0.785223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='601' max='928' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [601/928 08:15 < 04:29, 1.21 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 7. Initialize Trainer with EarlyStopping\n",
    "# --------------------------\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43d1aef5-49d0-448f-953d-bcb9f3e040b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ubuntu/MLexpressionsStorage/vit_final_independent_V6/preprocessor_config.json']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 8. Save Final Model\n",
    "# --------------------------\n",
    "torch.save(model.state_dict(), '/home/ubuntu/MLexpressionsStorage/final_model_V6.pth')\n",
    "model.save_pretrained(\"/home/ubuntu/MLexpressionsStorage/vit_final_independent_V6\")\n",
    "processor.save_pretrained(\"/home/ubuntu/MLexpressionsStorage/vit_final_independent_V6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b4a2a1-550c-4621-969c-7f38d642e9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
