{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf43a58f-16a3-4914-905a-6d7718d51c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#V16 changes:\n",
    "    # section #2 -> added stronger augmentation via make_transform_function\n",
    "        # added is_uncertain function\n",
    "    # section #3 -> updated to pull the hightest version model rather than\n",
    "        # the most recently modified model folder\n",
    "    # section #8 -> updated to have more aggressive augmentation\n",
    "    # section #11 -> now avoids capping majority and upsamples minority\n",
    "    #- section #19 -> added explicit prints for clustering, audit, and review\n",
    "    # section #20 -> merged old section #21 org by class with review conf mining\n",
    "    # added sections #21 and #22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2039b54e-2fdc-4268-b812-8af2286901f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 0. Imports\n",
    "# --------------------------\n",
    "# Standard Library Imports\n",
    "import csv\n",
    "import gc\n",
    "import glob\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Third-Party Imports\n",
    "import accelerate\n",
    "import dill\n",
    "import face_recognition\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import transformers\n",
    "\n",
    "# From Imports\n",
    "from collections import Counter\n",
    "from datasets import ClassLabel, Dataset, Features, Image as DatasetsImage, concatenate_datasets, load_dataset\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from imagehash import phash, hex_to_hash\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageOps, ExifTags, UnidentifiedImageError\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, log_loss, precision_recall_fscore_support\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import AdamW, LBFGS\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import (\n",
    "    GaussianBlur,\n",
    "    RandAugment,\n",
    "    RandomAffine,\n",
    "    RandomApply,\n",
    "    ToPILImage,\n",
    "    ToTensor\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    AutoModelForImageClassification,\n",
    "    EarlyStoppingCallback,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0071173a-74de-4aee-8a54-e38c48ee6971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Output directory created: /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V16_20250618_144335\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 1. Global Configurations\n",
    "# --------------------------\n",
    "RUN_INFERENCE = True  # Toggle this off to disable running inference\n",
    "IMAGE_DIR = \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/ferckjalfag_dataset\"\n",
    "BASE_PATH = IMAGE_DIR\n",
    "\n",
    "LABEL_NAMES = [\n",
    "    'anger', 'disgust', 'fear', 'happiness', 'neutral',\n",
    "    'questioning', 'sadness', 'surprise', 'contempt', 'unknown'\n",
    "]\n",
    "id2label = dict(enumerate(LABEL_NAMES))\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "HARD_CLASS_NAMES = ['contempt', 'disgust', 'fear', 'questioning']\n",
    "hard_class_ids = [label2id[n] for n in HARD_CLASS_NAMES]\n",
    "\n",
    "VALID_EXTENSIONS = (\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\")\n",
    "\n",
    "def is_valid_image(filename):\n",
    "    return filename.lower().endswith(VALID_EXTENSIONS) and not filename.startswith(\"._\")\n",
    "\n",
    "label_mapping = {name.lower(): name for name in LABEL_NAMES}\n",
    "\n",
    "# üî¢ Dynamically determine the next version\n",
    "def get_next_version(base_dir):\n",
    "\n",
    "    # Use glob to find all entries matching the pattern\n",
    "    all_entries = glob.glob(os.path.join(base_dir, \"V*_*\"))\n",
    "    \n",
    "    # Filter to include only directories\n",
    "    existing = [\n",
    "        os.path.basename(d) for d in all_entries if os.path.isdir(d)\n",
    "    ]\n",
    "\n",
    "    # Extract version numbers from the directory names\n",
    "    versions = [\n",
    "        int(d[1:].split(\"_\")[0]) for d in existing\n",
    "        if d.startswith(\"V\") and \"_\" in d and d[1:].split(\"_\")[0].isdigit()\n",
    "    ]\n",
    "    \n",
    "    # Determine the next version number\n",
    "    next_version = max(versions, default=0) + 1\n",
    "    return f\"V{next_version}\"\n",
    "\n",
    "# Automatically create a versioned output folder\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "VERSION = get_next_version(\"/Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training\")\n",
    "VERSION_TAG = VERSION + \"_\" + timestamp\n",
    "SAVE_DIR = os.path.join(\"/Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training\", VERSION_TAG)\n",
    "LOGITS_PATH = os.path.join(SAVE_DIR, f\"logits_eval_{VERSION}.npy\")\n",
    "LABELS_PATH = os.path.join(SAVE_DIR, f\"labels_eval_{VERSION}.npy\")\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "print(f\"üìÅ Output directory created: {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "342291eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 2. Utility Functions (Metrics & Calibration)\n",
    "# --------------------------\n",
    "\n",
    "# üîç Compute perceptual hash for image similarity clustering (used in REVIEW and Disgust curation)\n",
    "def compute_hash(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"L\").resize((64, 64))\n",
    "        return str(phash(img))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# üîÑ Smoothed Cross Entropy Loss (Œµ = 0.05)\n",
    "class SmoothedCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, smoothing=0.05):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        num_classes = logits.size(1)\n",
    "        with torch.no_grad():\n",
    "            smooth_labels = torch.full_like(logits, self.smoothing / (num_classes - 1))\n",
    "            smooth_labels.scatter_(1, target.unsqueeze(1), 1.0 - self.smoothing)\n",
    "        log_probs = F.log_softmax(logits, dim=1)\n",
    "        loss = -(smooth_labels * log_probs).sum(dim=1).mean()\n",
    "        return loss\n",
    "\n",
    "# ‚ö†Ô∏è Confidence Penalty to Reduce Overconfidence\n",
    "def confidence_penalty(logits, beta=0.05):\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    log_probs = F.log_softmax(logits, dim=1)\n",
    "    entropy = -torch.sum(probs * log_probs, dim=1)\n",
    "    return beta * entropy.mean()\n",
    "\n",
    "# üìä Compute Metrics with Confusion Matrix Logging\n",
    "def compute_metrics_with_confusion(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    report = classification_report(labels, preds, target_names=LABEL_NAMES, output_dict=True)\n",
    "    print(classification_report(labels, preds, target_names=LABEL_NAMES))\n",
    "\n",
    "    # Save raw logits/labels for calibration or further analysis\n",
    "    np.save(os.path.join(SAVE_DIR, f\"logits_eval_{VERSION}.npy\"), logits)\n",
    "    np.save(os.path.join(SAVE_DIR, f\"labels_eval_{VERSION}.npy\"), labels)\n",
    "\n",
    "    # Save per-class F1/precision/recall/entropy to CSV (append per epoch)\n",
    "    f1s = [report[name][\"f1-score\"] for name in LABEL_NAMES]\n",
    "    recalls = [report[name][\"recall\"] for name in LABEL_NAMES]\n",
    "    precisions = [report[name][\"precision\"] for name in LABEL_NAMES]\n",
    "\n",
    "    # Entropy per class (sorted by entropy)\n",
    "    softmax_probs = F.softmax(torch.tensor(logits), dim=-1)\n",
    "    entropies = -torch.sum(softmax_probs * torch.log(softmax_probs + 1e-12), dim=-1)\n",
    "    entropy_per_class = []\n",
    "    for idx, class_name in enumerate(LABEL_NAMES):\n",
    "        mask = (np.array(labels) == idx)\n",
    "        if mask.any():\n",
    "            class_entropy = entropies[mask].mean().item()\n",
    "            entropy_per_class.append((class_name, class_entropy))\n",
    "        else:\n",
    "            entropy_per_class.append((class_name, 0.0))\n",
    "    # Sort for display only; CSV row stays in canonical label order\n",
    "    sorted_entropy = sorted(entropy_per_class, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # CSV logging\n",
    "    epoch_metrics_path = os.path.join(SAVE_DIR, \"per_class_metrics.csv\")\n",
    "    epoch = getattr(trainer.state, \"epoch\", None) if \"trainer\" in globals() else None\n",
    "    df_row = pd.DataFrame({\n",
    "        \"epoch\": [epoch],\n",
    "        **{f\"f1_{n}\": [f] for n, f in zip(LABEL_NAMES, f1s)},\n",
    "        **{f\"recall_{n}\": [r] for n, r in zip(LABEL_NAMES, recalls)},\n",
    "        **{f\"precision_{n}\": [p] for n, p in zip(LABEL_NAMES, precisions)},\n",
    "        **{f\"entropy_{n}\": [e] for n, e in entropy_per_class}\n",
    "    })\n",
    "    if os.path.exists(epoch_metrics_path):\n",
    "        df_row.to_csv(epoch_metrics_path, mode=\"a\", header=False, index=False)\n",
    "    else:\n",
    "        df_row.to_csv(epoch_metrics_path, mode=\"w\", header=True, index=False)\n",
    "\n",
    "    # Generate and print confusion matrix heatmap\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "        xticklabels=LABEL_NAMES,\n",
    "        yticklabels=LABEL_NAMES\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(SAVE_DIR, f\"confusion_matrix_epoch_{VERSION}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Top confused pairs\n",
    "    confusion_pairs = [\n",
    "        ((LABEL_NAMES[i], LABEL_NAMES[j]), cm[i][j])\n",
    "        for i in range(len(LABEL_NAMES))\n",
    "        for j in range(len(LABEL_NAMES)) if i != j\n",
    "    ]\n",
    "    top_confusions = sorted(confusion_pairs, key=lambda x: x[1], reverse=True)[:3]\n",
    "    print(\"\\nTop 3 confused class pairs:\")\n",
    "    for (true_label, pred_label), count in top_confusions:\n",
    "        print(f\"  - {true_label} ‚Üí {pred_label}: {count} instances\")\n",
    "\n",
    "    # Compute average prediction entropy\n",
    "    avg_entropy = entropies.mean().item()\n",
    "    print(f\"\\nüß† Avg prediction entropy: {avg_entropy:.4f}\")\n",
    "\n",
    "    print(\"\\nüîç Class entropies (sorted):\")\n",
    "    for class_name, entropy in sorted_entropy:\n",
    "        print(f\"  - {class_name}: entropy = {entropy:.4f}\")\n",
    "\n",
    "    accuracy = (preds == labels).mean()\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "# üå°Ô∏è Apply Temperature Scaling for Calibration\n",
    "def apply_temperature_scaling(logits_path, labels_path):\n",
    "    if not (os.path.exists(logits_path) and os.path.exists(labels_path)):\n",
    "        print(f\"‚ùå Missing files:\\n  - {logits_path if not os.path.exists(logits_path) else ''}\\n - {labels_path if not os.path.exists(labels_path) else ''}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"üìÇ Loading logits from: {logits_path}\")\n",
    "    print(f\"üìÇ Loading labels from: {labels_path}\")\n",
    "\n",
    "    logits = torch.tensor(np.load(logits_path), dtype=torch.float32).to(device)\n",
    "    labels = torch.tensor(np.load(labels_path), dtype=torch.long).to(device)\n",
    "\n",
    "    class TemperatureScaler(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n",
    "\n",
    "        def forward(self, logits):\n",
    "            return logits / self.temperature\n",
    "\n",
    "    model = TemperatureScaler().to(device)\n",
    "    optimizer = LBFGS([model.temperature], lr=0.01, max_iter=50)\n",
    "\n",
    "    def eval_fn():\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(model(logits), labels)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(eval_fn)\n",
    "    calibrated_logits = model(logits)\n",
    "    probs = F.softmax(calibrated_logits, dim=1).detach().cpu().numpy()\n",
    "    logloss = log_loss(labels.cpu().numpy(), probs)\n",
    "\n",
    "    # Save optimal temperature\n",
    "    temperature_value = model.temperature.item()\n",
    "    torch.save(\n",
    "        torch.tensor([temperature_value]),\n",
    "        os.path.join(SAVE_DIR, f\"{VERSION}_calibrated_temperature.pt\")\n",
    "    )\n",
    "    print(f\"‚úÖ Optimal temperature: {temperature_value:.4f}\")\n",
    "    print(f\"‚úÖ Calibrated Log Loss: {logloss:.4f}\")\n",
    "    return temperature_value, logits.cpu(), labels.cpu()\n",
    "\n",
    "\n",
    "# üìà Plot Reliability Diagram (Calibration Curve)\n",
    "def plot_reliability_diagram(logits, labels, temperature, n_bins=15):\n",
    "    probs = F.softmax(logits / temperature, dim=1)\n",
    "    confidences, predictions = torch.max(probs, 1)\n",
    "    accuracies = predictions.eq(labels)\n",
    "\n",
    "    bins = torch.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers, bin_uppers = bins[:-1], bins[1:]\n",
    "\n",
    "    bin_accuracies, bin_confidences = [], []\n",
    "    for lower, upper in zip(bin_lowers, bin_uppers):\n",
    "        mask = (confidences > lower) & (confidences <= upper)\n",
    "        if mask.any():\n",
    "            bin_accuracies.append(accuracies[mask].float().mean())\n",
    "            bin_confidences.append(confidences[mask].mean())\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(bin_confidences, bin_accuracies, marker='o', label='Model')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', label='Perfect Calibration')\n",
    "    plt.title(\"Reliability Diagram (After Temperature Scaling)\")\n",
    "    plt.xlabel(\"Confidence\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(SAVE_DIR, f\"{VERSION}_reliability_diagram_calibrated.png\")\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    print(f\"üìä Saved reliability diagram to {output_path}\")\n",
    "\n",
    "# saving model and processor\n",
    "def save_model_and_processor(model, processor, save_dir, trainer=None):\n",
    "    print(f\"Saving model and processor to: {save_dir}\")\n",
    "    \n",
    "    model = model.to(\"cpu\")\n",
    "\n",
    "    # Save processor\n",
    "    processor.save_pretrained(save_dir)\n",
    "    print(f\"‚úÖ Processor saved to: {SAVE_DIR}\")\n",
    "    \n",
    "    # Save full model\n",
    "    model.save_pretrained(SAVE_DIR, safe_serialization=True)\n",
    "    print(f\"‚úÖ Full model saved to: {SAVE_DIR}\")\n",
    "\n",
    "    # Save state dict\n",
    "    final_model_path = os.path.join(SAVE_DIR, 'final_model.pth')\n",
    "    torch.save(model.state_dict(), final_model_path)\n",
    "    print(f\"‚úÖ State dict saved to: {final_model_path}\")\n",
    "\n",
    "    # Save trainer state\n",
    "    if trainer is not None:\n",
    "        try:\n",
    "            trainer.save_model(os.path.join(save_dir, \"backup_trainer_model\"))\n",
    "            print(\"‚úÖ Trainer backup saved.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to save trainer backup: {e}\")\n",
    "\n",
    "    # Memory cleanup\n",
    "    del model\n",
    "    gc.collect()\n",
    "    try:\n",
    "        torch.cuda.empty_cache()\n",
    "    except Exception:\n",
    "        pass  # Not all systems have CUDA\n",
    "    print(\"‚úÖ Memory cleanup complete after save.\")\n",
    "\n",
    "# üö¶ Prints label distribution for a dataset\n",
    "    #only calling for ad hoc debugging, experiments, sanity checks \n",
    "def check_label_integrity(dataset, LABEL_NAMES, label2id):\n",
    "    # Count all mapped labels\n",
    "    label_counts = Counter(dataset['label'])\n",
    "    print(\"\\nüö® Label distribution after mapping (before split):\")\n",
    "    for label_id in range(len(LABEL_NAMES)):\n",
    "        label_name = LABEL_NAMES[label_id]\n",
    "        print(f\"  {label_name:12}: {label_counts.get(label_id, 0)}\")\n",
    "\n",
    "    # Specifically highlight 'surprise'\n",
    "    surprise_id = label2id['surprise']\n",
    "    if label_counts.get(surprise_id, 0) == 0:\n",
    "        print(\"‚ùóWARNING: No 'surprise' images found after mapping!\")\n",
    "    elif label_counts[surprise_id] < 50:  # arbitrary threshold\n",
    "        print(f\"‚ö†Ô∏è Only {label_counts[surprise_id]} 'surprise' images found! Check curation or mapping.\")\n",
    "\n",
    "# üö¶ Prints label distribution for multiple datasets\n",
    "def check_all_label_integrity(datasets_dict, LABEL_NAMES, label2id):\n",
    "    for name, dataset in datasets_dict.items():\n",
    "        print(f\"\\nüö® Label distribution for: {name}\")\n",
    "        label_counts = Counter(dataset['label'])\n",
    "        for label_id in range(len(LABEL_NAMES)):\n",
    "            label_name = LABEL_NAMES[label_id]\n",
    "            print(f\"  {label_name:12}: {label_counts.get(label_id, 0)}\")\n",
    "        surprise_id = label2id['surprise']\n",
    "        if label_counts.get(surprise_id, 0) == 0:\n",
    "            print(\"‚ùóWARNING: No 'surprise' images found in this split!\")\n",
    "        elif label_counts[surprise_id] < 50:\n",
    "            print(f\"‚ö†Ô∏è Only {label_counts[surprise_id]} 'surprise' images in {name}! Check curation or mapping.\")\n",
    "\n",
    "# --- Stronger Augmentation Utility ---\n",
    "def make_transform_function(processor, hard_class_ids):\n",
    "    def transform_function(example):\n",
    "        label = example[\"label\"]\n",
    "        aug_pipeline = strong_aug if label in hard_class_ids else data_augment\n",
    "        if example[\"image\"].mode != \"RGB\":\n",
    "            example[\"image\"] = example[\"image\"].convert(\"RGB\")\n",
    "        augmented_image = aug_pipeline(example[\"image\"])\n",
    "        inputs = processor(augmented_image, return_tensors=\"pt\")\n",
    "        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n",
    "        inputs[\"labels\"] = example[\"label\"]\n",
    "        return inputs\n",
    "    return transform_function  \n",
    "\n",
    "# Returns a boolean tensor: True if the prediction is low-confidence\n",
    "def is_uncertain(probs, threshold=0.85, entropy_thresh=1.3):\n",
    "    conf, _ = torch.max(probs, dim=-1)\n",
    "    entropy = -torch.sum(probs * torch.log(probs + 1e-12), dim=-1)\n",
    "    return (conf < threshold) | (entropy > entropy_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "629d4736-d643-4b4e-a107-9c2707c3eb8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V15_20250616_154815 were not used when initializing ViTForImageClassification: ['classifier.1.bias', 'classifier.1.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V15_20250616_154815 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available model directories (sorted by version):\n",
      " - /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V15_20250616_154815\n",
      "   Files: ['model.safetensors', 'V15_distribution_plot_20250616_154815.png', 'review_predictions_clustered', 'confusion_matrix_epoch_V15.png', '.DS_Store', 'V15_calibrated_temperature.pt', 'contempt_clusters', 'label_snapshots', 'logits_eval_V15.npy', 'checkpoint-10245', 'fear_clusters', 'config.json', 'sadness_clusters', 'checkpoint-17075', 'V15_ferckjalf_2025_06_16.ipynb', 'disgust_clusters', 'review_predictions_by_class', 'V15_reliability_diagram_calibrated.png', 'V15_review_candidates.txt', 'logs', 'per_class_metrics.csv', 'labels_eval_V15.npy', 'V15_augmentation_snapshot.csv', 'V15_review_predictions_with_preds.csv', '.ipynb_checkpoints', 'questioning_clusters', 'final_model.pth', 'preprocessor_config.json']\n",
      " - /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V14_20250614_190959\n",
      "   Files: ['model.safetensors', 'V14_review_candidates.txt', 'confusion_matrix_epoch_V14.png', 'review_predictions_clustered', 'V14_ferckjalf_2025_06_14.ipynb', 'V14_reliability_diagram_calibrated.png', 'contempt_clusters', 'label_snapshots', 'logits_eval_V14.npy', 'checkpoint-10245', 'fear_clusters', 'config.json', 'sadness_clusters', 'V14_augmentation_snapshot.csv', 'checkpoint-17075', 'disgust_clusters', 'review_predictions_by_class', 'logs', 'labels_eval_V14.npy', '.ipynb_checkpoints', 'V14_calibrated_temperature.pt', 'questioning_clusters', 'V14_review_predictions_with_preds.csv', 'final_model.pth', 'preprocessor_config.json', 'V14_distribution_plot_20250614_190959.png']\n",
      " - /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V13_20250527_161430\n",
      "   Files: ['model.safetensors', 'logits_eval_V13.npy', 'review_predictions_clustered', 'backup_trainer_model', '.DS_Store', 'label_snapshots', 'confusion_matrix_epoch_V13.png', 'V13_review_predictions_with_preds.csv', 'config.json', 'sadness_clusters', 'V13_ferckjalf_2025_05_27.ipynb', 'V13_reliability_diagram_calibrated.png', 'disgust_clusters', 'review_predictions_by_class', 'temperature_V13.txt', 'V13_augmentation_snapshot.csv', 'labels_eval_V13.npy', 'logs', 'V13_distribution_plot_20250527_161430.png', '.ipynb_checkpoints', 'questioning_clusters', 'V13_calibrated_temperature.pt', 'final_model.pth', 'preprocessor_config.json', 'V13_review_candidates.txt']\n",
      " - /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V12_20250519_171503\n",
      "   Files: ['V12_review_predictions_with_preds.csv', 'model.safetensors', 'V12_calibrated_temperature.pt', 'logits_eval_V12.npy', 'V12_reliability_diagram_calibrated.png', 'backup_trainer_model', '.DS_Store', 'confusion_matrix_epoch_V12.png', 'label_snapshots', 'config.json', 'disgust_clusters', 'review_predictions_by_class', 'V12_ferckjalf_2025_05_19.ipynb', 'V12_review_candidates.txt', 'labels_eval_V12.npy', 'V12_augmentation_snapshot.csv', 'logs', 'V12_distribution_plot_20250519_171503.png', 'questioning_clusters', 'final_model.pth', 'preprocessor_config.json']\n",
      " - /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V11_20250516_120452\n",
      "   Files: ['logits_eval_V11.npy', 'model.safetensors', 'V14_20250531_160421_experimental', 'confusion_matrix_epoch_V11.png', 'backup_trainer_model', '.DS_Store', 'label_snapshots', 'config.json', 'disgust_clusters', 'review_predictions_by_class', 'V11_distribution_plot_20250516_120452.png', 'V11_ferckjalf_2025_05_16.ipynb', 'V11_review_predictions_with_preds.csv', 'labels_eval_V11.npy', 'logs', 'V11_calibrated_temperature.pt', '.ipynb_checkpoints', 'V11_review_candidates.txt', 'V11_reliability_diagram_calibrated.png', 'questioning_clusters', 'final_model.pth', 'preprocessor_config.json']\n",
      " - /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V10_20250515_150651\n",
      "   Files: ['logits_eval_V10.npy', 'model.safetensors', 'V10_distribution_plot_20250515_150651.png', 'backup_trainer_model', '.DS_Store', 'confusion_matrix_epoch_V10.png', 'label_snapshots', 'V10_review_candidates.txt', 'config.json', 'V10_ferckjalf_2025_05_15.ipynb', 'V10_calibrated_temperature.pt', 'disgust_clusters', 'V15_20250613_140110', 'V14_20250612_094038', 'logs', 'labels_eval_V10.npy', 'V10_reliability_diagram_calibrated.png', '.ipynb_checkpoints', 'disgust_with_AUs', 'final_model.pth', 'preprocessor_config.json']\n",
      " - /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V9_20250513_152634\n",
      "   Files: ['model.safetensors', 'backup_trainer_model', '.DS_Store', 'logits_eval_V9.npy', 'config.json', 'V9_ferckjalf_2025_05_13.ipynb', 'confusion_matrix_epoch_V9.png', 'labels_eval_V9.npy', 'V9_calibrated_temperature.pt', 'V9_review_candidates.txt', 'logs', '.ipynb_checkpoints', 'V9_distribution_plot_20250514_131858.png', 'V9_reliability_diagram_calibrated.png', 'final_model.pth', 'preprocessor_config.json']\n",
      " - /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V8_20250503_190001\n",
      "   Files: ['model.safetensors', 'V8_distribution_plot_20250503_163313.png', '.DS_Store', 'config.json', 'V8_distribution_plot_20250503_190001.png', 'confusion_matrix_epoch_V8.png', 'logs', '.ipynb_checkpoints', 'V8_ferckjalf_2025_04_26.ipynb', 'final_model.pth', 'preprocessor_config.json']\n",
      " - /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V7_vit_final_independent\n",
      "   Files: ['events.out.tfevents.1742583470.104-171-202-99.12653.0', 'distribution_plot_20250326_035318.png', 'model.safetensors', '.DS_Store', 'config.json', 'events.out.tfevents.1742410645.104-171-202-163.7809.0', 'V7_ferckjalf_2025_04_19.ipynb', 'events.out.tfevents.1744483563.104-171-203-193.3100.0', 'V7_distribution_plot_20250420_031249.png', 'events.out.tfevents.1745095524.104-171-202-110.17789.0', 'events.out.tfevents.1745091345.104-171-202-110.14599.0', 'events.out.tfevents.1742487297.104-171-203-147.4942.0', 'V7_final_model.pth', 'events.out.tfevents.1742939255.104-171-203-66.28305.1', 'events.out.tfevents.1742739108.104-171-202-168.4431.0', '.ipynb_checkpoints', 'events.out.tfevents.1742938997.104-171-203-66.28305.0', 'events.out.tfevents.1742568732.104-171-202-99.2767.0', 'events.out.tfevents.1742668544.104-171-203-203.4192.0', 'V7_confusion_matrix_epoch.png', 'events.out.tfevents.1742668324.104-171-203-203.3879.0', 'preprocessor_config.json']\n",
      " - /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V6_vit_final_independent\n",
      "   Files: ['model.safetensors', 'V6_ferckja_2025_04_12.ipynb', 'config.json', 'V6_distribution_plot_20250413_004102.png', 'V6_ferckja_2025_02_28.ipynb', 'V6_final_model.pth', 'preprocessor_config.json']\n",
      " - /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V5_vit_final_independent\n",
      "   Files: ['model.safetensors', 'V5_distribution_plot_20250326_035318.png', 'V5_ferckja_2025_03_25.ipynb', 'config.json', 'V5_final_model.pth', 'final_model_V5.pth', 'events.out.tfevents.1742586282.104-171-202-99.26463.0', 'prediction_distribution.png', 'preprocessor_config.json']\n",
      " - /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V4_vit_final_independent\n",
      "   Files: ['model.safetensors', 'V4_final_model.pth', 'config.json', 'v4_prediction_distribution.png', 'V4_ferckja_2025_02_28.ipynb', 'final_model_V4.pth', 'preprocessor_config.json']\n",
      " - /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V3_vit_final_independent\n",
      "   Files: ['model.safetensors', 'V3_final_model.pth', 'config.json', 'V3_ferckja_2025_03_21.ipynb', 'preprocessor_config.json']\n",
      " - /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V2_vit_final_independent\n",
      "   Files: ['V2_final_model.pth', 'V2_ferckja_2025_03_20.ipynb']\n",
      " - /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V1_vit_final_independent\n",
      "   Files: ['V1_ferckja_2025_02_28.ipynb', 'V1_final_model.pth']\n",
      " - /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V0_vit_final_independent\n",
      "   Files: ['V0_ferckja_2025_02_28.ipynb', '.ipynb_checkpoints']\n",
      "‚úÖ Auto-loaded model from: /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V15_20250616_154815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V15_20250616_154815 were not used when initializing ViTForImageClassification: ['classifier.1.bias', 'classifier.1.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V15_20250616_154815 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è Using device: mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ViTForImageClassification(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.1, inplace=False)\n",
       "    (1): Linear(in_features=768, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 3. Auto-Load Latest Pretrained Model and Processor\n",
    "# --------------------------\n",
    "\n",
    "MODEL_ROOT = \"/Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training\"\n",
    "\n",
    "def extract_version(dirname):\n",
    "    # Extracts the version number as an integer for sorting, e.g., V15_... ‚Üí 15\n",
    "    match = re.match(r\"V(\\d+)\", os.path.basename(dirname))\n",
    "    return int(match.group(1)) if match else -1\n",
    "\n",
    "model_dirs = [\n",
    "    os.path.join(MODEL_ROOT, d)\n",
    "    for d in os.listdir(MODEL_ROOT)\n",
    "    if d.startswith(\"V\") and os.path.isdir(os.path.join(MODEL_ROOT, d))\n",
    "]\n",
    "\n",
    "# Exclude SAVE_DIR (current output) by absolute path\n",
    "model_dirs = [d for d in model_dirs if os.path.abspath(d) != os.path.abspath(SAVE_DIR)]\n",
    "\n",
    "# Sort by version number, descending (highest first)\n",
    "model_dirs = sorted(model_dirs, key=extract_version, reverse=True)\n",
    "\n",
    "print(\"Available model directories (sorted by version):\")\n",
    "for d in model_dirs:\n",
    "    print(\" -\", d)\n",
    "    print(\"   Files:\", os.listdir(d))\n",
    "\n",
    "if len(model_dirs) < 1:\n",
    "    raise FileNotFoundError(\"‚ùå No earlier model folders found.\")\n",
    "\n",
    "model_path = model_dirs[0]\n",
    "print(f\"‚úÖ Auto-loaded model from: {model_path}\")\n",
    "\n",
    "# Load model and processor as before\n",
    "model = AutoModelForImageClassification.from_pretrained(model_path)\n",
    "processor = AutoImageProcessor.from_pretrained(model_path)\n",
    "\n",
    "# Load base model and processor\n",
    "model = AutoModelForImageClassification.from_pretrained(model_path)\n",
    "processor = AutoImageProcessor.from_pretrained(model_path)\n",
    "\n",
    "# Modify classification head with Dropout for regularization\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.1),\n",
    "    nn.Linear(model.classifier.in_features, len(id2label))\n",
    ")\n",
    "\n",
    "# Replace classification head to match current label schema\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id\n",
    "model.config.num_labels = len(LABEL_NAMES)\n",
    "\n",
    "# Define device and push model to device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"üñ•Ô∏è Using device:\", device)\n",
    "model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "081d864d-be53-4102-ae7e-ce83ba342de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d71433d6b144378e6f071e88976cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/17514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total examples after filtering: 17504\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 4. Load and Prepare Dataset\n",
    "# --------------------------\n",
    "dataset = load_dataset(\n",
    "    \"imagefolder\",\n",
    "    data_dir=\"/Users/natalyagrokh/AI/ml_expressions/img_datasets/ferckjalfag_dataset\",\n",
    "    split=\"train\",\n",
    "    cache_dir=\"/tmp/hf_cache\"\n",
    ")\n",
    "\n",
    "counter = {\"n\": 0}\n",
    "\n",
    "def reconcile_labels(example):\n",
    "    counter[\"n\"] += 1\n",
    "    if counter[\"n\"] % 1000 == 0:\n",
    "        print(f\"Processed {counter['n']} images...\")\n",
    "\n",
    "    label = example.get(\"label\", None)\n",
    "\n",
    "    if isinstance(label, int):\n",
    "        original_label = dataset.features[\"label\"].int2str(label).strip().lower()\n",
    "    elif isinstance(label, str):\n",
    "        original_label = label.strip().lower()\n",
    "    else:\n",
    "        file_path = getattr(example[\"image\"], \"filename\", None)\n",
    "        original_label = os.path.basename(os.path.dirname(file_path)).lower() if file_path else None\n",
    "\n",
    "    pretrain_label = label_mapping.get(original_label)\n",
    "    example[\"label\"] = label2id[pretrain_label] if pretrain_label is not None else -1\n",
    "    return example\n",
    "\n",
    "# Single-threaded labeling to preserve .filename\n",
    "dataset = dataset.map(reconcile_labels, desc=\"Re-labeling dataset\")\n",
    "dataset = dataset.filter(lambda x: x[\"label\"] != -1)\n",
    "\n",
    "print(f\"‚úÖ Total examples after filtering: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c46f6094-8498-494a-9891-11311592850c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label schema (from dataset): ClassLabel(names=['anger', 'contempt', 'disgust', 'fear', 'happiness', 'neutral', 'questioning', 'sadness', 'surprise', 'unknown'], id=None)\n",
      "\n",
      "üìä Full dataset label distribution (from Dataset object):\n",
      "  anger: 2302 examples\n",
      "  disgust: 309 examples\n",
      "  fear: 1432 examples\n",
      "  happiness: 2892 examples\n",
      "  neutral: 3334 examples\n",
      "  questioning: 1943 examples\n",
      "  sadness: 1706 examples\n",
      "  surprise: 2779 examples\n",
      "  contempt: 421 examples\n",
      "  unknown: 386 examples\n",
      "\n",
      "‚ö†Ô∏è  Dynamically identified minority classes: ['contempt', 'disgust', 'unknown']\n",
      "\n",
      "üìÇ Image count per label folder:\n",
      "  anger: 2302 images\n",
      "  contempt: 421 images\n",
      "  disgust: 309 images\n",
      "  fear: 1432 images\n",
      "  happiness: 2892 images\n",
      "  neutral: 3334 images\n",
      "  questioning: 1943 images\n",
      "  sadness: 1706 images\n",
      "  surprise: 2779 images\n",
      "  unknown: 386 images\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 5. Dataset Label Overview and Folder Stats\n",
    "# --------------------------\n",
    "def analyze_dataset_structure(dataset, id2label, base_path):\n",
    "    # Print label schema from the dataset\n",
    "    print(\"Label schema (from dataset):\", dataset.features[\"label\"])\n",
    "\n",
    "    # Label distribution from the dataset object\n",
    "    label_counts = Counter(dataset[\"label\"])\n",
    "    print(\"\\nüìä Full dataset label distribution (from Dataset object):\")\n",
    "    for label_id, count in sorted(label_counts.items()):\n",
    "        print(f\"  {id2label[label_id]}: {count} examples\")\n",
    "\n",
    "    # Dynamically detect minority classes (lowest 3 frequencies)\n",
    "    N = 3\n",
    "    minority_classes = set(\n",
    "        label for label, _ in sorted(label_counts.items(), key=lambda x: x[1])[:N]\n",
    "    )\n",
    "    print(f\"\\n‚ö†Ô∏è  Dynamically identified minority classes: {[id2label[i] for i in minority_classes]}\")\n",
    "\n",
    "    # Count images per directory, and store for later validation\n",
    "    folder_image_counts = {}\n",
    "    print(\"\\nüìÇ Image count per label folder:\")\n",
    "    for label in sorted(os.listdir(base_path)):\n",
    "        label_path = os.path.join(base_path, label)\n",
    "        if os.path.isdir(label_path):\n",
    "            valid_images = [img for img in os.listdir(label_path) if is_valid_image(img)]\n",
    "            folder_image_counts[label] = len(valid_images)\n",
    "            print(f\"  {label}: {len(valid_images)} images\")\n",
    "\n",
    "    return minority_classes, folder_image_counts\n",
    "\n",
    "# Example usage right after dataset loading\n",
    "minority_classes, folder_image_counts = analyze_dataset_structure(dataset, id2label, BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e1117fa-a523-4dbc-b59d-c2117f1e8c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Disgust hash clusters with more than 1 image:\n",
      "üîç Sadness hash clusters with more than 1 image:\n",
      "  - Cluster 958c52e1: 2 images copied for review\n",
      "  - Cluster ee9a8d33: 2 images copied for review\n",
      "  - Cluster d0890396: 2 images copied for review\n",
      "  - Cluster bb0d06f2: 2 images copied for review\n",
      "  - Cluster d7f00fa2: 2 images copied for review\n",
      "üîç Fear hash clusters with more than 1 image:\n",
      "  - Cluster 9ae56592: 2 images copied for review\n",
      "  - Cluster 91c8ee81: 2 images copied for review\n",
      "  - Cluster dae5a596: 2 images copied for review\n",
      "üîç Questioning hash clusters with more than 1 image:\n",
      "  - Cluster da014886: 2 images copied for review\n",
      "  - Cluster 9db42783: 2 images copied for review\n",
      "üîç Contempt hash clusters with more than 1 image:\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 6. Perceptual Clustering for Ambiguous/Confused Classes\n",
    "# --------------------------\n",
    "\n",
    "CLUSTER_TARGETS = [\"disgust\", \"sadness\", \"fear\", \"questioning\", \"contempt\"]\n",
    "\n",
    "for class_name in CLUSTER_TARGETS:\n",
    "    class_dir = os.path.join(BASE_PATH, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        print(f\"‚ö†Ô∏è Class dir not found: {class_dir} (skipping)\")\n",
    "        continue\n",
    "\n",
    "    class_images = [\n",
    "        os.path.join(class_dir, f) for f in os.listdir(class_dir)\n",
    "        if is_valid_image(f)\n",
    "    ]\n",
    "    hash_map = {}\n",
    "    for path in class_images:\n",
    "        h = compute_hash(path)\n",
    "        if h:\n",
    "            hash_map.setdefault(h, []).append(path)\n",
    "\n",
    "    cluster_dir = os.path.join(SAVE_DIR, f\"{class_name}_clusters\")\n",
    "    os.makedirs(cluster_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"üîç {class_name.capitalize()} hash clusters with more than 1 image:\")\n",
    "    for h, paths in hash_map.items():\n",
    "        if len(paths) > 1:\n",
    "            cluster_path = os.path.join(cluster_dir, h)\n",
    "            os.makedirs(cluster_path, exist_ok=True)\n",
    "            for p in paths:\n",
    "                shutil.copy(p, cluster_path)\n",
    "            print(f\"  - Cluster {h[:8]}: {len(paths)} images copied for review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "794327e8-da09-4435-b47e-54f5add8b7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Targeted minority augmentation will apply to: ['contempt', 'questioning', 'disgust']\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 7. Class Frequency-Aware Augmentation Targeting\n",
    "# --------------------------\n",
    "\n",
    "# Compute label frequencies from train split (post filtering)\n",
    "label_freqs = Counter(dataset[\"label\"])\n",
    "label_id2name = {v: k for k, v in label2id.items()}\n",
    "label_name2id = {v: k for k, v in label_id2name.items()}\n",
    "\n",
    "# Get lowest-count classes dynamically\n",
    "minority_by_count = sorted(label_freqs, key=label_freqs.get)[:3]\n",
    "minority_by_name = [label_id2name[i] for i in minority_by_count]\n",
    "minority_by_name = [n for n in minority_by_name if n != \"unknown\"]\n",
    "\n",
    "# Manually include known confused or underperforming classes\n",
    "manual_focus_classes = ['disgust', 'questioning', 'contempt']\n",
    "\n",
    "# Merge and deduplicate\n",
    "minority_class_names = list(set(minority_by_name + manual_focus_classes))\n",
    "\n",
    "# Final list as label indices\n",
    "minority_classes = [label_name2id[name] for name in minority_class_names]\n",
    "\n",
    "print(f\"üéØ Targeted minority augmentation will apply to: {minority_class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c881b20a-ded8-464d-bf03-9c9f6ab2eb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808dffc2b8874472a8721b53c4dca70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17504 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Augmentation counts: {}\n",
      "‚úÖ Saved augmentation snapshot to /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V16_20250618_144335/V16_augmentation_snapshot.csv\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 8. Define Data Augmentation and Preprocessing Transformation\n",
    "# --------------------------\n",
    "\n",
    "# --- Stronger Augmentation for Hard Classes ---\n",
    "data_augment = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(10),\n",
    "    T.ColorJitter(brightness=0.1, contrast=0.1)\n",
    "])\n",
    "\n",
    "strong_aug = T.Compose([\n",
    "    RandAugment(num_ops=3, magnitude=12),\n",
    "    T.RandomAffine(degrees=15, translate=(0.1, 0.1)),\n",
    "    T.RandomResizedCrop(224, scale=(0.5, 1.0)),\n",
    "    T.ColorJitter(0.4, 0.4, 0.4, 0.1),\n",
    "    T.RandomApply([T.GaussianBlur(5)], p=0.25),\n",
    "    T.ToTensor(),  # <-- Add this before RandomErasing\n",
    "    T.RandomApply([T.RandomErasing()], p=0.1),\n",
    "    T.ToPILImage(),  # <-- Convert back to PIL if your processor needs PIL Images\n",
    "])\n",
    "\n",
    "# Augmentation counter tracking\n",
    "aug_count = Counter()\n",
    "\n",
    "# After mapping finishes use the new make_transform_function\n",
    "dataset = dataset.map(make_transform_function(processor, hard_class_ids))\n",
    "formatted_counts = {LABEL_NAMES[k]: v for k, v in aug_count.items()}\n",
    "print(f\"‚úÖ Augmentation counts: {formatted_counts}\")\n",
    "\n",
    "# Explicitly log dataset snapshots (class distribution) to a \n",
    "# CSV or JSON after each run for easy future diffing and tracking\n",
    "snapshot_path = os.path.join(SAVE_DIR, f\"{VERSION}_augmentation_snapshot.csv\")\n",
    "aug_snapshot = pd.DataFrame.from_dict(dict(aug_count), orient='index', columns=['count'])\n",
    "aug_snapshot.to_csv(snapshot_path)\n",
    "\n",
    "print(f\"‚úÖ Saved augmentation snapshot to {snapshot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b8d986b-284c-4946-b481-da3088e95310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üö® Label distribution for: full dataset (post-aug)\n",
      "  anger       : 2302\n",
      "  disgust     : 309\n",
      "  fear        : 1432\n",
      "  happiness   : 2892\n",
      "  neutral     : 3334\n",
      "  questioning : 1943\n",
      "  sadness     : 1706\n",
      "  surprise    : 2779\n",
      "  contempt    : 421\n",
      "  unknown     : 386\n",
      "\n",
      "üö® Label distribution for: train set\n",
      "  anger       : 1888\n",
      "  disgust     : 241\n",
      "  fear        : 1151\n",
      "  happiness   : 2314\n",
      "  neutral     : 2661\n",
      "  questioning : 1556\n",
      "  sadness     : 1337\n",
      "  surprise    : 2237\n",
      "  contempt    : 327\n",
      "  unknown     : 291\n",
      "\n",
      "üö® Label distribution for: val set\n",
      "  anger       : 414\n",
      "  disgust     : 68\n",
      "  fear        : 281\n",
      "  happiness   : 578\n",
      "  neutral     : 673\n",
      "  questioning : 387\n",
      "  sadness     : 369\n",
      "  surprise    : 542\n",
      "  contempt    : 94\n",
      "  unknown     : 95\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 9. Train-Validation Split\n",
    "# --------------------------\n",
    "split_dataset = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "eval_dataset = split_dataset[\"test\"]\n",
    "\n",
    "# üö¶ Check and print label distributions across all important splits\n",
    "check_all_label_integrity(\n",
    "    {\n",
    "        \"full dataset (post-aug)\": dataset,\n",
    "        \"train set\": train_dataset,\n",
    "        \"val set\": eval_dataset,\n",
    "        # \"post-balance train\": train_dataset_balanced,\n",
    "    },\n",
    "    LABEL_NAMES, label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72e37d1e-a6fb-4e9f-aec5-ee945f11c0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Saved label distribution snapshot: /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V16_20250618_144335/label_snapshots/V16_label_distribution.csv\n",
      "\n",
      "üö® Label distribution for: full dataset (post-aug)\n",
      "  anger       : 2302\n",
      "  disgust     : 309\n",
      "  fear        : 1432\n",
      "  happiness   : 2892\n",
      "  neutral     : 3334\n",
      "  questioning : 1943\n",
      "  sadness     : 1706\n",
      "  surprise    : 2779\n",
      "  contempt    : 421\n",
      "  unknown     : 386\n",
      "\n",
      "üö® Label distribution for: train set\n",
      "  anger       : 1888\n",
      "  disgust     : 241\n",
      "  fear        : 1151\n",
      "  happiness   : 2314\n",
      "  neutral     : 2661\n",
      "  questioning : 1556\n",
      "  sadness     : 1337\n",
      "  surprise    : 2237\n",
      "  contempt    : 327\n",
      "  unknown     : 291\n",
      "\n",
      "üö® Label distribution for: val set\n",
      "  anger       : 414\n",
      "  disgust     : 68\n",
      "  fear        : 281\n",
      "  happiness   : 578\n",
      "  neutral     : 673\n",
      "  questioning : 387\n",
      "  sadness     : 369\n",
      "  surprise    : 542\n",
      "  contempt    : 94\n",
      "  unknown     : 95\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 10. Label Distribution Snapshot and Drift Monitor\n",
    "# --------------------------\n",
    "snapshot_dir = os.path.join(SAVE_DIR, \"label_snapshots\")\n",
    "os.makedirs(snapshot_dir, exist_ok=True)\n",
    "\n",
    "# Count current training labels\n",
    "train_label_names = [LABEL_NAMES[i] for i in train_dataset['label']]\n",
    "label_counts = pd.Series(train_label_names).value_counts().sort_index()\n",
    "label_counts.name = VERSION\n",
    "\n",
    "# Save snapshot CSV\n",
    "snapshot_path = os.path.join(snapshot_dir, f\"{VERSION}_label_distribution.csv\")\n",
    "label_counts.to_csv(snapshot_path)\n",
    "print(f\"üìä Saved label distribution snapshot: {snapshot_path}\")\n",
    "\n",
    "# Optionally compare to previous version\n",
    "previous_versions = sorted([\n",
    "    f for f in os.listdir(snapshot_dir) if f.endswith(\".csv\") and not f.startswith(VERSION)\n",
    "])\n",
    "if previous_versions:\n",
    "    latest_prev = previous_versions[-1]\n",
    "    prev_df = pd.read_csv(os.path.join(snapshot_dir, latest_prev), index_col=0)\n",
    "    diff = label_counts.subtract(prev_df.iloc[:, 0], fill_value=0)\n",
    "    print(\"üîç Label count change since last snapshot:\")\n",
    "    print(diff)\n",
    "\n",
    "# üö¶ Check and print label distributions across all important splits\n",
    "check_all_label_integrity(\n",
    "    {\n",
    "        \"full dataset (post-aug)\": dataset,\n",
    "        \"train set\": train_dataset,\n",
    "        \"val set\": eval_dataset,\n",
    "        # \"post-balance train\": train_dataset_balanced,\n",
    "    },\n",
    "    LABEL_NAMES, label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72643383-d4fc-466e-b91c-654e47a7a94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ca7fa1ad79443386acbf20ad27f2f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/17504 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e69812545a47429533275ffa44584d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/17504 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368b5b2359eb4ded8186790b36ab6060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/17504 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fd5d7a2a21493c859ff46eeeac614b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/17504 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef7daa5bf494c3c9e8673a5ebb553b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/17504 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764c681da62a457980c618bc06850e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/17504 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf8a13e89a546d0934ae394f384b5dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/17504 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066fc8040f64460ab189afb713ad3b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/17504 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d5218ad41644a0af367eb536cda1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/17504 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6794c48de6d4273a32c9306d758cfa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/17504 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After balancing: Counter({4: 3334, 3: 2892, 7: 2779, 0: 2302, 5: 1943, 6: 1706, 1: 1500, 8: 1500, 2: 1500, 9: 386})\n",
      "\n",
      "üö® Label distribution for: full dataset (post-aug)\n",
      "  anger       : 2302\n",
      "  disgust     : 309\n",
      "  fear        : 1432\n",
      "  happiness   : 2892\n",
      "  neutral     : 3334\n",
      "  questioning : 1943\n",
      "  sadness     : 1706\n",
      "  surprise    : 2779\n",
      "  contempt    : 421\n",
      "  unknown     : 386\n",
      "\n",
      "üö® Label distribution for: train set\n",
      "  anger       : 1888\n",
      "  disgust     : 241\n",
      "  fear        : 1151\n",
      "  happiness   : 2314\n",
      "  neutral     : 2661\n",
      "  questioning : 1556\n",
      "  sadness     : 1337\n",
      "  surprise    : 2237\n",
      "  contempt    : 327\n",
      "  unknown     : 291\n",
      "\n",
      "üö® Label distribution for: val set\n",
      "  anger       : 414\n",
      "  disgust     : 68\n",
      "  fear        : 281\n",
      "  happiness   : 578\n",
      "  neutral     : 673\n",
      "  questioning : 387\n",
      "  sadness     : 369\n",
      "  surprise    : 542\n",
      "  contempt    : 94\n",
      "  unknown     : 95\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 11. Balance Dataset (with NO oversampling for 'unknown')\n",
    "# --------------------------\n",
    "MINORITY_CAP = 1500\n",
    "balanced_subsets = []\n",
    "label_counts = Counter(dataset[\"label\"])\n",
    "\n",
    "for label, count in label_counts.items():\n",
    "    subset = dataset.filter(lambda x: x['label'] == label, num_proc=1)\n",
    "    class_name = LABEL_NAMES[label]\n",
    "    if class_name == \"unknown\":\n",
    "        balanced_subsets.append(subset)\n",
    "    elif count < MINORITY_CAP:\n",
    "        multiplier = MINORITY_CAP // len(subset)\n",
    "        remainder = MINORITY_CAP % len(subset)\n",
    "        subset = concatenate_datasets([subset] * multiplier + [subset.select(range(remainder))])\n",
    "        balanced_subsets.append(subset)\n",
    "    else:\n",
    "        # Append full set (no downsampling for majority classes)\n",
    "        balanced_subsets.append(subset)\n",
    "\n",
    "train_dataset_balanced = concatenate_datasets(balanced_subsets).shuffle(seed=42)\n",
    "\n",
    "train_dataset_balanced = concatenate_datasets(balanced_subsets).shuffle(seed=42)\n",
    "print(\"After balancing:\", Counter(train_dataset_balanced[\"label\"]))\n",
    "\n",
    "# Calculate weights: Give hard classes 2x, others 1x\n",
    "weights = [2.0 if l in hard_class_ids else 1.0 for l in train_dataset_balanced[\"label\"]]\n",
    "weights = torch.DoubleTensor(weights)\n",
    "sampler = torch.utils.data.WeightedRandomSampler(\n",
    "    weights=weights, num_samples=len(weights), replacement=True\n",
    ")\n",
    "\n",
    "# üö¶ Check and print label distributions across all important splits\n",
    "check_all_label_integrity(\n",
    "    {\n",
    "        \"full dataset (post-aug)\": dataset,\n",
    "        \"train set\": train_dataset,\n",
    "        \"val set\": eval_dataset,\n",
    "        # \"post-balance train\": train_dataset_balanced,\n",
    "    },\n",
    "    LABEL_NAMES, label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8f601ac-21c3-461b-bf29-633457616f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 12. Define Training Arguments for Robust Fine-Tuning\n",
    "# --------------------------\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=SAVE_DIR,                   # Directory to save checkpoints and the final model\n",
    "    eval_strategy=\"epoch\",                 # Evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",                 # Save checkpoint at each epoch\n",
    "    save_total_limit=2,                    # ‚úÖ (optional) Keep only last 2 checkpoints to save space\n",
    "    learning_rate=4e-5,                    # A conservative learning rate for fine-tuning\n",
    "    per_device_train_batch_size=8,         # Adjust based on your CPU memory limits\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,                    # Fine-tune for a few epochs (adjust as needed)\n",
    "    load_best_model_at_end=True,           # Automatically load the best model when training finishes\n",
    "    metric_for_best_model=\"accuracy\",      # Monitor accuracy for best model selection\n",
    "    logging_dir=os.path.join(SAVE_DIR, \"logs\"),  # ‚úÖ Save logs inside versioned folder\n",
    "    logging_strategy=\"epoch\",                 # ‚úÖ Log once per epoch\n",
    "    save_safetensors=True                  # ‚úÖ Optional: saves model weights in `.safetensors` (safe format)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4df07f1f-619e-4d8d-a2c5-3a408deafa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 13. Define Compute Metrics\n",
    "# --------------------------\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = (predictions == labels).mean()\n",
    "    return {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f67aa498-c49c-4a70-9eaa-0bef78529605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalyagrokh/miniconda3/envs/ml_expressions/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7004' max='8755' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7004/8755 3:47:38 < 56:55, 0.51 it/s, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.559500</td>\n",
       "      <td>0.532953</td>\n",
       "      <td>0.927164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.404900</td>\n",
       "      <td>0.509697</td>\n",
       "      <td>0.943445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.352000</td>\n",
       "      <td>0.521151</td>\n",
       "      <td>0.943445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.330800</td>\n",
       "      <td>0.518269</td>\n",
       "      <td>0.946015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.96      0.98      0.97       414\n",
      "     disgust       0.69      0.78      0.73        68\n",
      "        fear       0.93      0.65      0.77       281\n",
      "   happiness       0.98      1.00      0.99       578\n",
      "     neutral       0.99      0.96      0.98       673\n",
      " questioning       0.73      0.93      0.82       387\n",
      "     sadness       0.99      0.93      0.96       369\n",
      "    surprise       0.99      0.99      0.99       542\n",
      "    contempt       0.52      0.47      0.49        94\n",
      "     unknown       0.99      1.00      0.99        95\n",
      "\n",
      "    accuracy                           0.93      3501\n",
      "   macro avg       0.88      0.87      0.87      3501\n",
      "weighted avg       0.93      0.93      0.93      3501\n",
      "\n",
      "\n",
      "Top 3 confused class pairs:\n",
      "  - fear ‚Üí questioning: 76 instances\n",
      "  - contempt ‚Üí questioning: 44 instances\n",
      "  - questioning ‚Üí fear: 11 instances\n",
      "\n",
      "üß† Avg prediction entropy: 0.3843\n",
      "\n",
      "üîç Class entropies (sorted):\n",
      "  - contempt: entropy = 1.0016\n",
      "  - fear: entropy = 0.7900\n",
      "  - disgust: entropy = 0.5733\n",
      "  - questioning: entropy = 0.4531\n",
      "  - sadness: entropy = 0.3362\n",
      "  - neutral: entropy = 0.3124\n",
      "  - happiness: entropy = 0.3047\n",
      "  - anger: entropy = 0.3039\n",
      "  - surprise: entropy = 0.2829\n",
      "  - unknown: entropy = 0.2683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalyagrokh/miniconda3/envs/ml_expressions/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.96      0.99      0.98       414\n",
      "     disgust       0.86      0.54      0.67        68\n",
      "        fear       0.83      0.86      0.84       281\n",
      "   happiness       0.99      0.99      0.99       578\n",
      "     neutral       0.99      0.97      0.98       673\n",
      " questioning       0.83      0.89      0.86       387\n",
      "     sadness       0.96      0.98      0.97       369\n",
      "    surprise       1.00      0.99      0.99       542\n",
      "    contempt       0.61      0.50      0.55        94\n",
      "     unknown       0.99      1.00      0.99        95\n",
      "\n",
      "    accuracy                           0.94      3501\n",
      "   macro avg       0.90      0.87      0.88      3501\n",
      "weighted avg       0.94      0.94      0.94      3501\n",
      "\n",
      "\n",
      "Top 3 confused class pairs:\n",
      "  - contempt ‚Üí questioning: 34 instances\n",
      "  - questioning ‚Üí fear: 30 instances\n",
      "  - fear ‚Üí questioning: 27 instances\n",
      "\n",
      "üß† Avg prediction entropy: 0.3051\n",
      "\n",
      "üîç Class entropies (sorted):\n",
      "  - disgust: entropy = 0.6301\n",
      "  - contempt: entropy = 0.5650\n",
      "  - fear: entropy = 0.3935\n",
      "  - questioning: entropy = 0.3830\n",
      "  - neutral: entropy = 0.2763\n",
      "  - anger: entropy = 0.2712\n",
      "  - sadness: entropy = 0.2661\n",
      "  - unknown: entropy = 0.2655\n",
      "  - surprise: entropy = 0.2611\n",
      "  - happiness: entropy = 0.2602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalyagrokh/miniconda3/envs/ml_expressions/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.99      0.98      0.98       414\n",
      "     disgust       0.78      0.72      0.75        68\n",
      "        fear       0.84      0.81      0.83       281\n",
      "   happiness       0.98      1.00      0.99       578\n",
      "     neutral       0.99      0.99      0.99       673\n",
      " questioning       0.80      0.90      0.85       387\n",
      "     sadness       0.98      0.98      0.98       369\n",
      "    surprise       0.99      0.99      0.99       542\n",
      "    contempt       0.70      0.41      0.52        94\n",
      "     unknown       0.98      1.00      0.99        95\n",
      "\n",
      "    accuracy                           0.94      3501\n",
      "   macro avg       0.90      0.88      0.89      3501\n",
      "weighted avg       0.94      0.94      0.94      3501\n",
      "\n",
      "\n",
      "Top 3 confused class pairs:\n",
      "  - contempt ‚Üí questioning: 41 instances\n",
      "  - fear ‚Üí questioning: 38 instances\n",
      "  - questioning ‚Üí fear: 25 instances\n",
      "\n",
      "üß† Avg prediction entropy: 0.2922\n",
      "\n",
      "üîç Class entropies (sorted):\n",
      "  - contempt: entropy = 0.5290\n",
      "  - disgust: entropy = 0.4196\n",
      "  - questioning: entropy = 0.3400\n",
      "  - fear: entropy = 0.3382\n",
      "  - sadness: entropy = 0.3153\n",
      "  - unknown: entropy = 0.2789\n",
      "  - neutral: entropy = 0.2712\n",
      "  - anger: entropy = 0.2682\n",
      "  - surprise: entropy = 0.2550\n",
      "  - happiness: entropy = 0.2481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalyagrokh/miniconda3/envs/ml_expressions/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.99      0.99      0.99       414\n",
      "     disgust       0.82      0.68      0.74        68\n",
      "        fear       0.78      0.86      0.82       281\n",
      "   happiness       0.99      1.00      1.00       578\n",
      "     neutral       0.99      0.99      0.99       673\n",
      " questioning       0.83      0.85      0.84       387\n",
      "     sadness       0.98      0.99      0.98       369\n",
      "    surprise       1.00      1.00      1.00       542\n",
      "    contempt       0.68      0.48      0.56        94\n",
      "     unknown       0.99      1.00      0.99        95\n",
      "\n",
      "    accuracy                           0.95      3501\n",
      "   macro avg       0.91      0.88      0.89      3501\n",
      "weighted avg       0.95      0.95      0.94      3501\n",
      "\n",
      "\n",
      "Top 3 confused class pairs:\n",
      "  - questioning ‚Üí fear: 43 instances\n",
      "  - contempt ‚Üí questioning: 33 instances\n",
      "  - fear ‚Üí questioning: 27 instances\n",
      "\n",
      "üß† Avg prediction entropy: 0.2833\n",
      "\n",
      "üîç Class entropies (sorted):\n",
      "  - contempt: entropy = 0.4635\n",
      "  - disgust: entropy = 0.4490\n",
      "  - questioning: entropy = 0.3435\n",
      "  - fear: entropy = 0.3275\n",
      "  - sadness: entropy = 0.2704\n",
      "  - anger: entropy = 0.2638\n",
      "  - neutral: entropy = 0.2592\n",
      "  - happiness: entropy = 0.2571\n",
      "  - surprise: entropy = 0.2529\n",
      "  - unknown: entropy = 0.2486\n",
      "Saving model and processor to: /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V16_20250618_144335\n",
      "‚úÖ Processor saved to: /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V16_20250618_144335\n",
      "‚úÖ Full model saved to: /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V16_20250618_144335\n",
      "‚úÖ State dict saved to: /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V16_20250618_144335/final_model.pth\n",
      "‚úÖ Memory cleanup complete after save.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 14. Trainer with Class-Weighted Loss\n",
    "# --------------------------\n",
    "\n",
    "# Define custom Trainer to inject class weights\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        # Use smoothed CE + confidence penalty\n",
    "        smooth_ce_loss = SmoothedCrossEntropyLoss(smoothing=0.05)\n",
    "        loss = smooth_ce_loss(logits, labels) + confidence_penalty(logits, beta=0.05)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Modify training args for learning rate scheduling and early stopping\n",
    "training_args.load_best_model_at_end = True\n",
    "training_args.metric_for_best_model = \"eval_loss\"\n",
    "training_args.evaluation_strategy = \"epoch\"\n",
    "training_args.save_strategy = \"epoch\"\n",
    "\n",
    "# Add EarlyStoppingCallback\n",
    "early_stop_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=3,\n",
    "    early_stopping_threshold=0.001\n",
    ")\n",
    "\n",
    "# Initialize WeightedTrainer with focal loss, confidence penalty, and label smoothing\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics_with_confusion,\n",
    "    optimizers=(\n",
    "        AdamW(model.parameters(), lr=training_args.learning_rate, weight_decay=0.01),\n",
    "        None\n",
    "    ),\n",
    "    callbacks=[early_stop_callback]\n",
    ")\n",
    "\n",
    "# T_0 = epochs before first restart, T_mult = restart multiplier\n",
    "scheduler = CosineAnnealingWarmRestarts(trainer.optimizer, T_0=2, T_mult=2)\n",
    "\n",
    "# Add scheduler step logic inside the training loop:\n",
    "original_train = trainer.train\n",
    "\n",
    "def modified_train(*args, **kwargs):\n",
    "    result = original_train(*args, **kwargs)\n",
    "    scheduler.step(trainer.state.epoch)  # instead of eval_loss\n",
    "    return result\n",
    "\n",
    "# Fine-tune model\n",
    "trainer.train()\n",
    "\n",
    "# Save model\n",
    "save_model_and_processor(model, processor, SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9356fc7-0f49-43e3-8679-d1a4d8507ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --------------------------\n",
    "# # 15. Rescue & Save from Last Checkpoint (after training)\n",
    "# # --------------------------\n",
    "# #in case model save fails, resume from latest checkpoint\n",
    "# processor.save_pretrained(SAVE_DIR)\n",
    "# print(\"‚úÖ Processor manually re-saved.\")\n",
    "\n",
    "# # Use parent directory of SAVE_DIR to locate latest V* folder\n",
    "# parent_dir = os.path.dirname(SAVE_DIR)\n",
    "# v_folders = [\n",
    "#     d for d in os.listdir(parent_dir)\n",
    "#     if os.path.isdir(os.path.join(parent_dir, d)) and d.startswith(\"V\")\n",
    "# ]\n",
    "\n",
    "# def extract_timestamp(name):\n",
    "#     try:\n",
    "#         _, date_str, time_str = name.split(\"_\")\n",
    "#         return datetime.strptime(f\"{date_str}_{time_str}\", \"%Y%m%d_%H%M%S\")\n",
    "#     except Exception:\n",
    "#         return datetime.min\n",
    "\n",
    "# latest_version_folder = max(v_folders, key=extract_timestamp)\n",
    "# latest_version_path = os.path.join(parent_dir, latest_version_folder)\n",
    "# print(f\"üóÇÔ∏è Using latest version folder: {latest_version_path}\")\n",
    "\n",
    "# # Locate latest checkpoint within that version folder\n",
    "# checkpoint_dirs = [\n",
    "#     os.path.join(latest_version_path, d)\n",
    "#     for d in os.listdir(latest_version_path)\n",
    "#     if d.startswith(\"checkpoint-\") and os.path.isdir(os.path.join(latest_version_path, d))\n",
    "# ]\n",
    "# if not checkpoint_dirs:\n",
    "#     raise ValueError(\"‚ùå No checkpoint found in latest version folder.\")\n",
    "\n",
    "# latest_checkpoint = max(checkpoint_dirs, key=os.path.getmtime)\n",
    "# print(f\"‚úÖ Found latest checkpoint: {latest_checkpoint}\")\n",
    "\n",
    "# # Load model and processor from latest checkpoint and save them\n",
    "# model = AutoModelForImageClassification.from_pretrained(latest_checkpoint)\n",
    "# processor = AutoImageProcessor.from_pretrained(latest_version_path)\n",
    "# model = model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73965871-eced-4b6b-9e56-b98aac0bc35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V16_20250618_144335 were not used when initializing ViTForImageClassification: ['classifier.1.bias', 'classifier.1.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V16_20250618_144335 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model reloaded for inference.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 16. Inference Utilities\n",
    "# --------------------------\n",
    "\n",
    "# Reload Model for Inference\n",
    "model = AutoModelForImageClassification.from_pretrained(SAVE_DIR).to(device).eval()\n",
    "print(\"‚úÖ Model reloaded for inference.\")\n",
    "\n",
    "# Single image prediction (unbatched)\n",
    "def predict_label(image_path, threshold=0.85):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        conf, pred_idx = torch.max(probs, dim=-1)\n",
    "    return (id2label[pred_idx.item()], conf.item()) if conf.item() >= threshold else (\"REVIEW\", conf.item())\n",
    "\n",
    "# Batched prediction\n",
    "def batch_predict(image_folder, batch_size=64, threshold=0.85):\n",
    "    all_preds = []\n",
    "    error_count = 0\n",
    "    image_paths = [\n",
    "        p for p in Path(image_folder).rglob(\"*\")\n",
    "        if is_valid_image(p.name)\n",
    "    ]\n",
    "\n",
    "    for i in tqdm(range(0, len(image_paths), batch_size), desc=\"Running inference in batches\"):\n",
    "        batch_paths = image_paths[i:i + batch_size]\n",
    "        images, valid_paths = [], []\n",
    "\n",
    "        for path in batch_paths:\n",
    "            try:\n",
    "                img = Image.open(path).convert(\"RGB\")\n",
    "                images.append(img)\n",
    "                valid_paths.append(str(path))\n",
    "            except Exception:\n",
    "                error_count += 1\n",
    "                continue\n",
    "\n",
    "        if not images:\n",
    "            continue\n",
    "\n",
    "        inputs = processor(images=images, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            confs, preds = torch.max(probs, dim=-1)\n",
    "\n",
    "        for pred, conf, path in zip(preds.tolist(), confs.tolist(), valid_paths):\n",
    "            all_preds.append(LABEL_NAMES[pred] if conf >= threshold else \"REVIEW\")\n",
    "\n",
    "    print(f\"‚úÖ Inference complete. Skipped {error_count} invalid image(s).\")\n",
    "    return all_preds\n",
    "\n",
    "# Distribution plot\n",
    "def plot_distribution(predictions, output_path):\n",
    "    label_counts = Counter(predictions)\n",
    "    labels = sorted(label_counts.keys())\n",
    "    counts = [label_counts[label] for label in labels]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(labels, counts)\n",
    "    plt.title(\"Predicted Expression Distribution\")\n",
    "    plt.xlabel(\"Expression\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ebf5e58-a801-455b-af5e-3fde26bea7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference in batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [05:53<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inference complete. Skipped 0 invalid image(s).\n",
      "üìù Saved REVIEW file paths to V16_review_candidates.txt\n",
      "Distribution plot saved to: /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V16_20250618_144335/V16_distribution_plot_20250618_144335.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 17. Entry Point for Inference\n",
    "# --------------------------\n",
    "if __name__ == \"__main__\" and RUN_INFERENCE:\n",
    "\n",
    "    # Auto-locate latest model directory\n",
    "    OUTPUT_PATH = os.path.join(SAVE_DIR, f\"{VERSION}_distribution_plot_{timestamp}.png\")\n",
    "\n",
    "    predictions = batch_predict(IMAGE_DIR)\n",
    "    reviewed_paths = []\n",
    "    image_paths = [str(p) for p in Path(IMAGE_DIR).rglob(\"*\") if is_valid_image(p.name)]\n",
    "\n",
    "    for path, label in zip(image_paths, predictions):\n",
    "        if label == \"REVIEW\":\n",
    "            reviewed_paths.append(path)\n",
    "\n",
    "    # Save paths to inspect manually\n",
    "    with open(os.path.join(SAVE_DIR, f\"{VERSION}_review_candidates.txt\"), \"w\") as f:\n",
    "        f.write(\"\\n\".join(reviewed_paths))\n",
    "    print(f\"üìù Saved REVIEW file paths to {VERSION}_review_candidates.txt\")\n",
    "\n",
    "    plot_distribution(predictions, OUTPUT_PATH)\n",
    "    print(f\"Distribution plot saved to: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a67976db-f36f-49cf-84c2-04292b75dd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Using calibration files from: /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V16_20250618_144335\n",
      "üìÇ Loading logits from: /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V16_20250618_144335/logits_eval_V16.npy\n",
      "üìÇ Loading labels from: /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V16_20250618_144335/labels_eval_V16.npy\n",
      "‚úÖ Optimal temperature: 1.2230\n",
      "‚úÖ Calibrated Log Loss: 0.2804\n",
      "üìä Saved reliability diagram to /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V16_20250618_144335/V16_reliability_diagram_calibrated.png\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 18. Temperature Scaling Calibration \n",
    "# --------------------------\n",
    "\n",
    "# Wrapper model for calibrated inference\n",
    "class ModelWithTemperature(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n",
    "\n",
    "    def forward(self, input_ids=None, pixel_values=None, **kwargs):\n",
    "        logits = self.model(pixel_values=pixel_values).logits\n",
    "        return logits / self.temperature\n",
    "\n",
    "    def set_temperature(self, logits, labels):\n",
    "        nll_criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = LBFGS([self.temperature], lr=0.01, max_iter=50)\n",
    "\n",
    "        def eval_fn():\n",
    "            optimizer.zero_grad()\n",
    "            loss = nll_criterion(logits / self.temperature, labels)\n",
    "            loss.backward()\n",
    "            return loss\n",
    "\n",
    "        optimizer.step(eval_fn)\n",
    "        print(f\"Optimal temperature (wrapped): {self.temperature.item():.4f}\")\n",
    "        return self\n",
    "\n",
    "# Dynamically locate the most recent V* folder that contains logits/labels\n",
    "base_dir = os.path.dirname(SAVE_DIR)\n",
    "v_folders = sorted([\n",
    "    d for d in os.listdir(base_dir)\n",
    "    if os.path.isdir(os.path.join(base_dir, d)) and d.startswith(\"V\")\n",
    "], key=lambda d: os.path.getmtime(os.path.join(base_dir, d)), reverse=True)\n",
    "\n",
    "logits_path, labels_path = None, None\n",
    "for v in v_folders:\n",
    "    version_tag = v.split('_')[0]\n",
    "    folder_path = os.path.join(base_dir, v)\n",
    "    logits_candidate = os.path.join(folder_path, f\"logits_eval_{version_tag}.npy\")\n",
    "    labels_candidate = os.path.join(folder_path, f\"labels_eval_{version_tag}.npy\")\n",
    "    if os.path.exists(logits_candidate) and os.path.exists(labels_candidate):\n",
    "        INFER_SAVE_DIR = folder_path\n",
    "        INFER_VERSION = version_tag\n",
    "        print(f\"üìÅ Using calibration files from: {SAVE_DIR}\")\n",
    "        logits_path = logits_candidate\n",
    "        labels_path = labels_candidate\n",
    "        break\n",
    "\n",
    "# --------------------------\n",
    "# Run calibration\n",
    "# --------------------------\n",
    "if logits_path and labels_path:\n",
    "    result = apply_temperature_scaling(logits_path, labels_path)\n",
    "    if result is not None:\n",
    "        temperature, logits, labels = result\n",
    "        plot_reliability_diagram(logits, labels, temperature)\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Skipping temperature scaling and diagram (missing logits or labels in {SAVE_DIR})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adaeec19-d4c7-43a6-80cb-86aafd573989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Completed tagging + copying REVIEW predictions to: /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V16_20250618_144335/review_predictions_by_class\n",
      "üìÑ CSV log saved to: /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V16_20250618_144335/V16_review_predictions_with_preds.csv\n",
      "‚úÖ Review assignments (with audit) complete.\n",
      "‚ö†Ô∏è No clusters found for review. /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V16_20250618_144335/review_predictions_clustered will remain empty.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 19. Review & Relabel 'REVIEW' Predictions (with Audit Logging & Clustering)\n",
    "# --------------------------\n",
    "\n",
    "REVIEW_THRESHOLD = 0.85\n",
    "REVIEW_BY_CLASS_DIR = os.path.join(SAVE_DIR, \"review_predictions_by_class\")\n",
    "REVIEW_CSV_LOG = os.path.join(SAVE_DIR, f\"{VERSION}_review_predictions_with_preds.csv\")\n",
    "REVIEW_CLUSTER_DIR = os.path.join(SAVE_DIR, \"review_predictions_clustered\")\n",
    "\n",
    "os.makedirs(REVIEW_BY_CLASS_DIR, exist_ok=True)\n",
    "os.makedirs(REVIEW_CLUSTER_DIR, exist_ok=True)\n",
    "\n",
    "# ---- If you HAVE NOT already generated review CSV (inference stage) ----\n",
    "if not os.path.exists(REVIEW_CSV_LOG):\n",
    "    review_log = []\n",
    "    image_paths = [\n",
    "        p for p in Path(IMAGE_DIR).rglob(\"*\")\n",
    "        if p.is_file() and p.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]\n",
    "    ]\n",
    "    for img_path in image_paths:\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            inputs = processor(image, return_tensors=\"pt\").to(device)\n",
    "            with torch.no_grad():\n",
    "                logits = model(**inputs).logits\n",
    "                probs = F.softmax(logits, dim=-1)\n",
    "                conf, pred_idx = torch.max(probs, dim=-1)\n",
    "            conf_val = conf.item()\n",
    "            pred_label = id2label[pred_idx.item()]\n",
    "            tag = \"REVIEW\" if conf_val < REVIEW_THRESHOLD else pred_label\n",
    "            review_log.append({\n",
    "                \"image_path\": str(img_path),\n",
    "                \"predicted_label\": pred_label,\n",
    "                \"confidence\": round(conf_val, 4),\n",
    "                \"tag\": tag\n",
    "            })\n",
    "            if tag == \"REVIEW\":\n",
    "                target_dir = os.path.join(REVIEW_BY_CLASS_DIR, pred_label)\n",
    "                os.makedirs(target_dir, exist_ok=True)\n",
    "                shutil.copy(str(img_path), target_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error with image: {img_path} | {e}\")\n",
    "    pd.DataFrame(review_log).to_csv(REVIEW_CSV_LOG, index=False)\n",
    "    print(f\"‚úÖ Completed tagging + copying REVIEW predictions to: {REVIEW_BY_CLASS_DIR}\")\n",
    "    print(f\"üìÑ CSV log saved to: {REVIEW_CSV_LOG}\")\n",
    "\n",
    "# ---- If you already HAVE a review CSV (assignment/audit stage) ----\n",
    "df = pd.read_csv(REVIEW_CSV_LOG)\n",
    "review_assignment_log = []\n",
    "for _, row in df.iterrows():\n",
    "    path = row[\"image_path\"]\n",
    "    pred_label = row[\"predicted_label\"]\n",
    "    conf = float(row[\"confidence\"])\n",
    "    true_label = os.path.basename(os.path.dirname(path))\n",
    "    assigned = \"unknown\" if conf < REVIEW_THRESHOLD else pred_label\n",
    "    dest_dir = os.path.join(REVIEW_BY_CLASS_DIR, assigned)\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    shutil.copy(path, dest_dir)\n",
    "    review_assignment_log.append([path, true_label, pred_label, conf, assigned])\n",
    "\n",
    "log_df = pd.DataFrame(\n",
    "    review_assignment_log,\n",
    "    columns=[\"image_path\", \"true_label\", \"pred_label\", \"confidence\", \"assigned_folder\"]\n",
    ")\n",
    "log_df.to_csv(os.path.join(SAVE_DIR, \"review_assignment_audit.csv\"), index=False)\n",
    "print(\"‚úÖ Review assignments (with audit) complete.\")\n",
    "\n",
    "# ---- Perceptual hash clustering of review pool ----\n",
    "def phash_distance(hash1, hash2):\n",
    "    return hash1 - hash2\n",
    "\n",
    "PHASH_CLUSTER_THRESHOLD = 6\n",
    "image_paths = [row[0] for row in review_assignment_log if row[4] != \"unknown\"]  # assigned to a class\n",
    "\n",
    "hashes = []\n",
    "for img_path in image_paths:\n",
    "    try:\n",
    "        img = Image.open(img_path).convert(\"L\").resize((64, 64))\n",
    "        hashes.append(hex_to_hash(str(phash(img))))\n",
    "    except Exception as e:\n",
    "        print(f\"phash error: {img_path} | {e}\")\n",
    "\n",
    "clusters = []\n",
    "used = set()\n",
    "for i, h1 in enumerate(hashes):\n",
    "    if i in used:\n",
    "        continue\n",
    "    cluster = [image_paths[i]]\n",
    "    used.add(i)\n",
    "    for j, h2 in enumerate(hashes):\n",
    "        if j <= i or j in used:\n",
    "            continue\n",
    "        if phash_distance(h1, h2) <= PHASH_CLUSTER_THRESHOLD:\n",
    "            cluster.append(image_paths[j])\n",
    "            used.add(j)\n",
    "    if len(cluster) > 1:\n",
    "        clusters.append(cluster)\n",
    "\n",
    "if not clusters:\n",
    "    print(f\"‚ö†Ô∏è No clusters found for review. {REVIEW_CLUSTER_DIR} will remain empty.\")\n",
    "else:\n",
    "    for idx, cluster in enumerate(clusters):\n",
    "        out_dir = os.path.join(REVIEW_CLUSTER_DIR, f\"cluster_{idx}\")\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        for p in cluster:\n",
    "            shutil.copy(p, out_dir)\n",
    "    print(f\"‚úÖ Saved {len(clusters)} clusters to {REVIEW_CLUSTER_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc464dc0-3204-453c-9a4c-4e63700ad6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Flagged 181 hard negatives for ('contempt', 'questioning'):\n",
      "  Saved list: /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V16_20250618_144335/review_hardneg_contempt_questioning.txt\n",
      "\n",
      "Flagged 40 hard negatives for ('fear', 'surprise'):\n",
      "  Saved list: /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V16_20250618_144335/review_hardneg_fear_surprise.txt\n",
      "üîç Found 17364 total predictions (CSV) and 17505 REVIEW-tagged paths.\n",
      "üìÇ Grouped 17364 REVIEW images into folders by predicted label in: /Users/natalyagrokh/AI/ml_expressions/img_expressions/sup_training/V16_20250618_144335/review_predictions_by_class\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 20. REVIEW Pool Diagnostics & Hard Confusion Mining\n",
    "# --------------------------\n",
    "\n",
    "# A. Flag hard confusion pairs for manual review\n",
    "REVIEW_CONFUSION_PAIRS = [(\"contempt\", \"questioning\"), (\"fear\", \"surprise\")]\n",
    "\n",
    "def parse_review_confusions(csv_path, confusion_pairs):\n",
    "    import csv\n",
    "    flagged_imgs = {pair: [] for pair in confusion_pairs}\n",
    "    with open(csv_path) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            pred = row[\"predicted_label\"]\n",
    "            true = os.path.basename(os.path.dirname(row[\"image_path\"]))\n",
    "            conf = float(row[\"confidence\"])\n",
    "            for a, b in confusion_pairs:\n",
    "                if ((pred == a and true == b) or (pred == b and true == a)) and conf < 0.8:\n",
    "                    flagged_imgs[(a, b)].append(row[\"image_path\"])\n",
    "    return flagged_imgs\n",
    "\n",
    "confusion_candidates = parse_review_confusions(REVIEW_CSV_LOG, REVIEW_CONFUSION_PAIRS)\n",
    "for pair, imgs in confusion_candidates.items():\n",
    "    print(f\"\\nFlagged {len(imgs)} hard negatives for {pair}:\")\n",
    "    out_path = os.path.join(SAVE_DIR, f\"review_hardneg_{pair[0]}_{pair[1]}.txt\")\n",
    "    with open(out_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(imgs))\n",
    "    print(f\"  Saved list: {out_path}\")\n",
    "\n",
    "# B. Organize REVIEW-tagged images by predicted class (for curation)\n",
    "REVIEW_SORT_DIR = os.path.join(SAVE_DIR, \"review_predictions_by_class\")\n",
    "os.makedirs(REVIEW_SORT_DIR, exist_ok=True)\n",
    "review_txt_path = os.path.join(SAVE_DIR, f\"{VERSION}_review_candidates.txt\")\n",
    "csv_path = os.path.join(SAVE_DIR, f\"{VERSION}_review_predictions_with_preds.csv\")\n",
    "\n",
    "if os.path.exists(review_txt_path) and os.path.exists(csv_path):\n",
    "    with open(review_txt_path, \"r\") as f:\n",
    "        review_paths = {line.strip() for line in f.readlines()}\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    count = 0\n",
    "\n",
    "    print(f\"üîç Found {len(df)} total predictions (CSV) and {len(review_paths)} REVIEW-tagged paths.\")\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        path = row[\"image_path\"]\n",
    "        label = row[\"predicted_label\"]\n",
    "        conf = row[\"confidence\"]\n",
    "\n",
    "        if path in review_paths and label != \"REVIEW\":\n",
    "            dest_dir = os.path.join(REVIEW_SORT_DIR, label)\n",
    "            os.makedirs(dest_dir, exist_ok=True)\n",
    "            shutil.copy(path, dest_dir)\n",
    "            count += 1\n",
    "\n",
    "    print(f\"üìÇ Grouped {count} REVIEW images into folders by predicted label in: {REVIEW_SORT_DIR}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Missing review candidates file or prediction CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30b0f4cc-6bc8-4bff-b5e1-f5dfdb685a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label name/id mapping:\n",
      "0: anger\n",
      "1: disgust\n",
      "2: fear\n",
      "3: happiness\n",
      "4: neutral\n",
      "5: questioning\n",
      "6: sadness\n",
      "7: surprise\n",
      "8: contempt\n",
      "9: unknown\n",
      "Sample review predictions (audit):\n",
      "                                          image_path true_label pred_label  \\\n",
      "0  /Users/natalyagrokh/AI/ml_expressions/img_data...   contempt       fear   \n",
      "1  /Users/natalyagrokh/AI/ml_expressions/img_data...   contempt   surprise   \n",
      "2  /Users/natalyagrokh/AI/ml_expressions/img_data...   contempt    unknown   \n",
      "3  /Users/natalyagrokh/AI/ml_expressions/img_data...   contempt   surprise   \n",
      "4  /Users/natalyagrokh/AI/ml_expressions/img_data...   contempt   surprise   \n",
      "\n",
      "   confidence assigned_folder  \n",
      "0      0.1819         unknown  \n",
      "1      0.1790         unknown  \n",
      "2      0.1499         unknown  \n",
      "3      0.1673         unknown  \n",
      "4      0.1715         unknown  \n",
      "Sample review predictions (audit):\n",
      "                                          image_path true_label pred_label  \\\n",
      "0  /Users/natalyagrokh/AI/ml_expressions/img_data...   contempt       fear   \n",
      "1  /Users/natalyagrokh/AI/ml_expressions/img_data...   contempt   surprise   \n",
      "2  /Users/natalyagrokh/AI/ml_expressions/img_data...   contempt    unknown   \n",
      "3  /Users/natalyagrokh/AI/ml_expressions/img_data...   contempt   surprise   \n",
      "4  /Users/natalyagrokh/AI/ml_expressions/img_data...   contempt   surprise   \n",
      "\n",
      "   confidence assigned_folder  \n",
      "0      0.1819         unknown  \n",
      "1      0.1790         unknown  \n",
      "2      0.1499         unknown  \n",
      "3      0.1673         unknown  \n",
      "4      0.1715         unknown  \n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 21. Visualization & Error Tracking\n",
    "# --------------------------\n",
    "\n",
    "print(\"Label name/id mapping:\")\n",
    "for idx, name in enumerate(LABEL_NAMES):\n",
    "    print(f\"{idx}: {name}\")\n",
    "\n",
    "# Defensive: Check that metrics file exists before plotting\n",
    "per_class_csv = os.path.join(SAVE_DIR, \"per_class_metrics.csv\")\n",
    "if not os.path.exists(per_class_csv):\n",
    "    print(f\"‚ö†Ô∏è Metrics file {per_class_csv} not found.\")\n",
    "else:\n",
    "    metrics_df = pd.read_csv(per_class_csv)\n",
    "    last_row = metrics_df.iloc[-1]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    f1s = [last_row[f\"f1_{n}\"] for n in LABEL_NAMES]\n",
    "    ax.bar(LABEL_NAMES, f1s)\n",
    "    ax.set_title(\"Per-Class F1 (Last Epoch)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(SAVE_DIR, \"per_class_f1.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Bar plot of per-class entropy\n",
    "    entropies = [last_row[f\"entropy_{n}\"] for n in LABEL_NAMES]\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    ax.bar(LABEL_NAMES, entropies)\n",
    "    ax.set_title(\"Per-Class Mean Entropy (Last Epoch)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(SAVE_DIR, \"per_class_entropy.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Histogram for REVIEW pool\n",
    "    review_counts = Counter()\n",
    "    if os.path.exists(REVIEW_SORT_DIR):\n",
    "        for label_dir in os.listdir(REVIEW_SORT_DIR):\n",
    "            count = len(os.listdir(os.path.join(REVIEW_SORT_DIR, label_dir)))\n",
    "            review_counts[label_dir] = count\n",
    "        plt.bar(review_counts.keys(), review_counts.values())\n",
    "        plt.title(\"REVIEW Pool Distribution by Predicted Class\")\n",
    "        plt.savefig(os.path.join(SAVE_DIR, \"review_pool_distribution.png\"))\n",
    "        plt.close()\n",
    "        # Flag if >70% in one class\n",
    "        total = sum(review_counts.values())\n",
    "        for label, count in review_counts.items():\n",
    "            if total > 0 and count / total > 0.7:\n",
    "                print(f\"‚ö†Ô∏è REVIEW pool highly imbalanced: {count/total:.1%} in '{label}'\")\n",
    "\n",
    "    # Audit print block (as before)\n",
    "    print(\"Sample review predictions (audit):\")\n",
    "    if 'log_df' in locals():\n",
    "        print(log_df[[\"image_path\", \"true_label\", \"pred_label\", \"confidence\", \"assigned_folder\"]].head())\n",
    "    elif 'df' in locals():\n",
    "        print(df[[\"image_path\", \"true_label\", \"predicted_label\", \"confidence\"]].head())\n",
    "    else:\n",
    "        print(\"No review/audit DataFrame found for printing.\")\n",
    "\n",
    "# ‚úÖ AUDIT BLOCK\n",
    "print(\"Sample review predictions (audit):\")\n",
    "if 'log_df' in locals():\n",
    "    print(log_df[[\"image_path\", \"true_label\", \"pred_label\", \"confidence\", \"assigned_folder\"]].head())\n",
    "elif 'df' in locals():\n",
    "    print(df[[\"image_path\", \"true_label\", \"predicted_label\", \"confidence\"]].head())\n",
    "else:\n",
    "    print(\"No review/audit DataFrame found for printing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55576ae4-91ae-4d68-b538-2b57a0b46089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö® F1 < 0.8 for class 'disgust': 0.74\n",
      "üö® Entropy > 0.4 for class 'disgust': 0.45\n",
      "üö® F1 < 0.8 for class 'contempt': 0.56\n",
      "üö® Entropy > 0.4 for class 'contempt': 0.46\n",
      "‚ö†Ô∏è Some classes not deployment-ready! Address above issues before production.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 22. Deployment Readiness Assertions and Flags\n",
    "# --------------------------\n",
    "\n",
    "# Load metrics\n",
    "metrics_df = pd.read_csv(os.path.join(SAVE_DIR, \"per_class_metrics.csv\"))\n",
    "last = metrics_df.iloc[-1]\n",
    "warn = False\n",
    "\n",
    "for cname in LABEL_NAMES:\n",
    "    f1 = last[f\"f1_{cname}\"]\n",
    "    entropy = last[f\"entropy_{cname}\"]\n",
    "    if f1 < 0.8:\n",
    "        print(f\"üö® F1 < 0.8 for class '{cname}': {f1:.2f}\")\n",
    "        warn = True\n",
    "    if entropy > 0.4:\n",
    "        print(f\"üö® Entropy > 0.4 for class '{cname}': {entropy:.2f}\")\n",
    "        warn = True\n",
    "\n",
    "if not warn:\n",
    "    print(\"‚úÖ All classes ready for deployment: F1 >= 0.8 and entropy <= 0.4\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Some classes not deployment-ready! Address above issues before production.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e53267-5a68-47f7-b0c9-babcecdcfe4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_expressions",
   "language": "python",
   "name": "ml_expressions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
