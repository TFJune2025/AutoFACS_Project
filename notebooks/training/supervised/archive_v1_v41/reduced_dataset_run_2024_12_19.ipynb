{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af7af4e3-7f60-4f22-94e7-d2aa40317a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model accuracy very low:  Test Accuracy: 0.3369\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01f1d00-eeaf-4958-849d-b990be33a230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 2872\n",
      "Validation samples: 385\n",
      "Test samples: 377\n"
     ]
    }
   ],
   "source": [
    "# Load the Reduced FER2013 dataset\n",
    "train_data = pd.read_csv(\"DATA/Reduced_train.csv\")\n",
    "test_data = pd.read_csv(\"DATA/Reduced_test.csv\")\n",
    "full_data = pd.read_csv(\"DATA/Reduced_fer20131.csv\")\n",
    "\n",
    "# Function to preprocess pixel data\n",
    "def preprocess_pixels(pixels):\n",
    "    # Convert space-separated string into a numpy array\n",
    "    array = np.array([int(p) for p in pixels.split()], dtype=np.uint8)\n",
    "    return array.reshape(48, 48, 1)  # FER2013 images are 48x48 pixels, grayscale\n",
    "\n",
    "# Preprocess training data\n",
    "X_train = np.array([preprocess_pixels(row) for row in train_data[\"pixels\"]])\n",
    "y_train = to_categorical(train_data[\"emotion\"].values, num_classes=7)\n",
    "\n",
    "# Preprocess full data for validation/testing\n",
    "X_full = np.array([preprocess_pixels(row) for row in full_data[\"pixels\"]])\n",
    "y_full = to_categorical(full_data[\"emotion\"].values, num_classes=7)\n",
    "\n",
    "# Split the full dataset into validation and test sets based on the `Usage` column\n",
    "validation_mask = full_data[\"Usage\"] == \"PublicTest\"\n",
    "test_mask = full_data[\"Usage\"] == \"PrivateTest\"\n",
    "\n",
    "X_val, y_val = X_full[validation_mask], y_full[validation_mask]\n",
    "X_test, y_test = X_full[test_mask], y_full[test_mask]\n",
    "\n",
    "print(\"Training samples:\", X_train.shape[0])\n",
    "print(\"Validation samples:\", X_val.shape[0])\n",
    "print(\"Test samples:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "209329a6-f4fc-4d42-85c7-5b626353b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Input(shape=(48, 48, 1)),  # Define input shape explicitly\n",
    "    Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    MaxPool2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation=\"relu\", kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(7, activation=\"softmax\")  # 7 output classes for emotions\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e2bdd58-3d52-46a0-9490-dd4150fd271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model during training\n",
    "checkpoint = ModelCheckpoint(\"model_checkpoint.keras\", save_best_only=True, monitor=\"val_loss\", verbose=1)\n",
    "\n",
    "# Stop training early if validation loss stops improving\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1)\n",
    "\n",
    "# Reduce learning rate when validation loss plateaus\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de56cec0-e7b0-4fcd-bb25-1355df4260f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.2243 - loss: 7.2843  \n",
      "Epoch 1: val_loss improved from inf to 23.77011, saving model to model_checkpoint.keras\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 261ms/step - accuracy: 0.2245 - loss: 7.2510 - val_accuracy: 0.1610 - val_loss: 23.7701 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.2616 - loss: 2.5824 \n",
      "Epoch 2: val_loss improved from 23.77011 to 15.83511, saving model to model_checkpoint.keras\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 308ms/step - accuracy: 0.2614 - loss: 2.5819 - val_accuracy: 0.1714 - val_loss: 15.8351 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.2333 - loss: 2.4353 \n",
      "Epoch 3: val_loss improved from 15.83511 to 3.46714, saving model to model_checkpoint.keras\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 282ms/step - accuracy: 0.2336 - loss: 2.4351 - val_accuracy: 0.1974 - val_loss: 3.4671 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.2426 - loss: 2.3538 \n",
      "Epoch 4: val_loss improved from 3.46714 to 3.00394, saving model to model_checkpoint.keras\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 273ms/step - accuracy: 0.2428 - loss: 2.3535 - val_accuracy: 0.2286 - val_loss: 3.0039 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.2521 - loss: 2.3104 \n",
      "Epoch 5: val_loss improved from 3.00394 to 2.84554, saving model to model_checkpoint.keras\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 264ms/step - accuracy: 0.2522 - loss: 2.3101 - val_accuracy: 0.2364 - val_loss: 2.8455 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.2807 - loss: 2.2170 \n",
      "Epoch 6: val_loss did not improve from 2.84554\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 260ms/step - accuracy: 0.2805 - loss: 2.2170 - val_accuracy: 0.2026 - val_loss: 2.9853 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.2782 - loss: 2.1830 \n",
      "Epoch 7: val_loss did not improve from 2.84554\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 269ms/step - accuracy: 0.2780 - loss: 2.1830 - val_accuracy: 0.2026 - val_loss: 2.8469 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.2686 - loss: 2.1427 \n",
      "Epoch 8: val_loss did not improve from 2.84554\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 260ms/step - accuracy: 0.2687 - loss: 2.1427 - val_accuracy: 0.2442 - val_loss: 2.8977 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.2455 - loss: 2.1231 \n",
      "Epoch 9: val_loss improved from 2.84554 to 2.60698, saving model to model_checkpoint.keras\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 271ms/step - accuracy: 0.2458 - loss: 2.1229 - val_accuracy: 0.1896 - val_loss: 2.6070 - learning_rate: 5.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.2792 - loss: 2.0884 \n",
      "Epoch 10: val_loss improved from 2.60698 to 2.15089, saving model to model_checkpoint.keras\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 286ms/step - accuracy: 0.2792 - loss: 2.0882 - val_accuracy: 0.2468 - val_loss: 2.1509 - learning_rate: 5.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.2903 - loss: 2.0452 \n",
      "Epoch 11: val_loss did not improve from 2.15089\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 264ms/step - accuracy: 0.2902 - loss: 2.0452 - val_accuracy: 0.2390 - val_loss: 2.3498 - learning_rate: 5.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.2995 - loss: 2.0115 \n",
      "Epoch 12: val_loss improved from 2.15089 to 2.12382, saving model to model_checkpoint.keras\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 262ms/step - accuracy: 0.2995 - loss: 2.0114 - val_accuracy: 0.2545 - val_loss: 2.1238 - learning_rate: 5.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.3105 - loss: 1.9834 \n",
      "Epoch 13: val_loss did not improve from 2.12382\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 264ms/step - accuracy: 0.3103 - loss: 1.9835 - val_accuracy: 0.2727 - val_loss: 2.1799 - learning_rate: 5.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.3013 - loss: 1.9476 \n",
      "Epoch 14: val_loss did not improve from 2.12382\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 249ms/step - accuracy: 0.3013 - loss: 1.9478 - val_accuracy: 0.2130 - val_loss: 3.1312 - learning_rate: 5.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.3312 - loss: 1.9434 \n",
      "Epoch 15: val_loss did not improve from 2.12382\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 240ms/step - accuracy: 0.3310 - loss: 1.9436 - val_accuracy: 0.2286 - val_loss: 2.4881 - learning_rate: 5.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.3492 - loss: 1.8643 \n",
      "Epoch 16: val_loss did not improve from 2.12382\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 269ms/step - accuracy: 0.3490 - loss: 1.8646 - val_accuracy: 0.2883 - val_loss: 2.1430 - learning_rate: 2.5000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.3495 - loss: 1.8695 \n",
      "Epoch 17: val_loss did not improve from 2.12382\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 253ms/step - accuracy: 0.3494 - loss: 1.8695 - val_accuracy: 0.2935 - val_loss: 2.1312 - learning_rate: 2.5000e-04\n",
      "Epoch 17: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=30,  # Reduced from 45 for time optimization\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6773a6ea-ccda-4b3b-8cab-aa5d4d73ab2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.2688 - loss: 2.1154\n",
      "Test Loss: 2.0460\n",
      "Test Accuracy: 0.3369\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85932a02-51ec-4ad3-9534-94ce3c5d4b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save locally and download\n",
    "model.save(\"reduced_fer2013_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca94c1d6-7f9b-4bbd-9bd8-35e3d870da92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_expressions)",
   "language": "python",
   "name": "ml_expressions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
