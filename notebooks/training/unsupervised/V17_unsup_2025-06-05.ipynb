{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2c4d2b-421d-4aed-8b78-b1ad767cd028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V16_unsup changes\n",
    "    # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2df23ee-83b8-4152-96b6-b8c13c476ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalyagrokh/miniconda3/envs/ml_unsupervised/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import datetime\n",
    "import glob\n",
    "import platform\n",
    "import psutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import entropy\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "# Optionally: import umap\n",
    "try:\n",
    "    import umap\n",
    "    HAVE_UMAP = True\n",
    "except ImportError:\n",
    "    HAVE_UMAP = False\n",
    "\n",
    "from transformers import AutoImageProcessor, AutoModel, ViTForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a20e76bf-d5d2-4a81-8353-858eff6b91f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CONFIG SECTION (Version-controlled) ==========\n",
    "CFG_VERSION = \"V16_unsup_2025_06_04\"\n",
    "V13_MODEL_PATH = \"V13_20250527_161430\"\n",
    "V13_PROCESSOR_PATH = V13_MODEL_PATH\n",
    "UNSUP_BASE_DIR = \"/Users/natalyagrokh/AI/ml_expressions/img_expressions_unsup\"\n",
    "IMAGE_DIR = \"/Users/natalyagrokh/AI/ml_expressions/img_datasets/temp_autogluon_images\"\n",
    "DATASET_NAME = os.path.basename(os.path.normpath(IMAGE_DIR))\n",
    "DATESTAMP = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "N_CLUSTERS = 20\n",
    "KL_OOD_THRESHOLD = 0.55\n",
    "EUCLIDEAN_OUTLIER_PERCENTILE = 98\n",
    "BATCH_SIZE = 32\n",
    "VALID_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp', '.jfif')\n",
    "T_SNE_SUBSAMPLE = 5000\n",
    "CLUSTER_N_INIT = 10\n",
    "\n",
    "# Auto-versioned output filenames\n",
    "OUT_PREFIX = f\"{CFG_VERSION}_{DATASET_NAME}_clusters{N_CLUSTERS}_kl{KL_OOD_THRESHOLD}_eu{EUCLIDEAN_OUTLIER_PERCENTILE}_{DATESTAMP}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbe1da61-9dd2-4679-ae82-0f5a32d54652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Unsupervised output directory created: ./V16_unsup_20250604_142640\n"
     ]
    }
   ],
   "source": [
    "# ======= DYNAMIC UNSUPERVISED OUTPUT FOLDER CREATION ========\n",
    "def get_next_unsup_version(base_dir=\".\", prefix=\"V\"):\n",
    "    all_entries = glob.glob(os.path.join(base_dir, f\"{prefix}*_*\"))\n",
    "    existing = [\n",
    "        os.path.basename(d) for d in all_entries if os.path.isdir(d)\n",
    "    ]\n",
    "    versions = [\n",
    "        int(d[1:].split(\"_\")[0]) for d in existing\n",
    "        if d.startswith(prefix) and \"_\" in d and d[1:].split(\"_\")[0].isdigit()\n",
    "    ]\n",
    "    next_version = max(versions, default=0) + 1\n",
    "    return f\"{prefix}{next_version}\"\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "VERSION = get_next_unsup_version(base_dir=\".\")\n",
    "VERSION_TAG = VERSION + \"_unsup_\" + timestamp\n",
    "SAVE_DIR = os.path.join(\".\", VERSION_TAG)\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "print(f\"ðŸ“ Unsupervised output directory created: {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa19316a-a936-4a1a-9b90-b8c600f02a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== ARTIFACT PREFIXES ==========\n",
    "OUT_PREFIX = os.path.join(\n",
    "    SAVE_DIR, f\"{VERSION_TAG}_{DATASET_NAME}_clusters{N_CLUSTERS}_kl{KL_OOD_THRESHOLD}_eu{EUCLIDEAN_OUTLIER_PERCENTILE}\"\n",
    ")\n",
    "EMBED_FILE = f\"{OUT_PREFIX}_embeddings.npy\"\n",
    "PATHS_FILE = f\"{OUT_PREFIX}_paths.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1e696c3-13e8-4753-ac73-bcf5c64d2128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== SYSTEM INFO =====\n",
      "Python: 3.10.16\n",
      "Platform: macOS-15.5-arm64-arm-64bit\n",
      "CPU: arm\n",
      "RAM (GB): 17.18\n",
      "=======================\n",
      "ðŸ–¥ï¸ Using CPU only for feature extraction (edit if using GPU)\n"
     ]
    }
   ],
   "source": [
    "# ========== HARDWARE/ENV LOG ==========\n",
    "print(\"===== SYSTEM INFO =====\")\n",
    "print(\"Python:\", platform.python_version())\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"CPU:\", platform.processor())\n",
    "print(\"RAM (GB):\", round(psutil.virtual_memory().total / 1e9, 2))\n",
    "print(\"=======================\")\n",
    "print(\"ðŸ–¥ï¸ Using CPU only for feature extraction (edit if using GPU)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92b31e90-3cdb-426c-ba93-3a9954defab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at V13_20250527_161430 were not used when initializing ViTForImageClassification: ['classifier.1.bias', 'classifier.1.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at V13_20250527_161430 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Loading V13 backbone: V13_20250527_161430\n",
      "âœ… Model config loaded:\n",
      "  Model arch: ['ViTForImageClassification']\n",
      "  # Labels: 8\n",
      "  id2label: {0: 'anger', 1: 'disgust', 2: 'fear', 3: 'happiness', 4: 'sadness', 5: 'surprise', 6: 'neutral', 7: 'questioning'}\n",
      "âœ… Processor loaded: ViTImageProcessorFast\n",
      "ðŸ–¥ï¸ Model device: cpu\n"
     ]
    }
   ],
   "source": [
    "# ========== 1. LOAD SUPERVISED (V13) MODEL ==========\n",
    "print(f\"ðŸ”„ Loading V13 backbone: {V13_MODEL_PATH}\")\n",
    "device = torch.device(\"cpu\")  # Change to \"cuda\" if using GPU\n",
    "model = ViTForImageClassification.from_pretrained(V13_MODEL_PATH, local_files_only=True).to(device).eval()\n",
    "processor = AutoImageProcessor.from_pretrained(V13_MODEL_PATH, local_files_only=True)\n",
    "\n",
    "# Print model info\n",
    "print(\"âœ… Model config loaded:\")\n",
    "print(f\"  Model arch: {model.config.architectures}\")\n",
    "print(f\"  # Labels: {model.config.num_labels}\")\n",
    "if hasattr(model.config, \"id2label\"):\n",
    "    print(f\"  id2label: {model.config.id2label}\")\n",
    "print(\"âœ… Processor loaded:\", type(processor).__name__)\n",
    "print(\"ðŸ–¥ï¸ Model device:\", model.device)\n",
    "model = model.to(\"cpu\").eval()  # Or use CUDA/MPS as available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92eddf46-e74b-4ec9-a0e9-c86b2712b5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ–¼ï¸ Found 31002 images.\n"
     ]
    }
   ],
   "source": [
    "# ========== 2. IMAGE PATHS ==========\n",
    "image_paths = [\n",
    "    os.path.join(IMAGE_DIR, f)\n",
    "    for f in os.listdir(IMAGE_DIR)\n",
    "    if f.lower().endswith(VALID_EXTENSIONS)\n",
    "]\n",
    "print(f\"ðŸ–¼ï¸ Found {len(image_paths)} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4e0cd8e-8414-45b8-8418-f42d05cfa38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings: (31002, 768)\n",
      "Loaded file paths: 31002\n"
     ]
    }
   ],
   "source": [
    "# # ========== LOADING SAVED NPY FILES WHEN CODE FAILS ==========\n",
    "\n",
    "# # Adjust these to your actual saved file locations (if you use dynamic folders, fill in SAVE_DIR and OUT_PREFIX accordingly)\n",
    "# EMBED_FILE = \"/Users/natalyagrokh/AI/ml_expressions/img_expressions/V16_unsup_2025_06_04_temp_autogluon_images_clusters20_kl0.55_eu98_20250604_embeddings.npy\"  # e.g., \"/Users/natalyagrokh/AI/ml_expressions/img_expressions_unsup/V16_unsup_20250604_191044/V16_unsup_20250604_191044_temp_autogluon_images_clusters20_kl0.55_eu98_embeddings.npy\"\n",
    "# PATHS_FILE = \"/Users/natalyagrokh/AI/ml_expressions/img_expressions/V16_unsup_2025_06_04_temp_autogluon_images_clusters20_kl0.55_eu98_20250604_paths.npy\"\n",
    "\n",
    "# # Load arrays\n",
    "# all_embeddings = np.load(EMBED_FILE)\n",
    "# all_files = np.load(PATHS_FILE, allow_pickle=True).tolist()\n",
    "\n",
    "# print(\"Loaded embeddings:\", all_embeddings.shape)\n",
    "# print(\"Loaded file paths:\", len(all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d730c9-f0f3-4dd1-a8e8-32329889cf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 3. EMBEDDING EXTRACTION (SUPERVISED BACKBONE) ==========\n",
    "EMBED_FILE = f\"{OUT_PREFIX}_embeddings.npy\"\n",
    "PATHS_FILE = f\"{OUT_PREFIX}_paths.npy\"\n",
    "if os.path.exists(EMBED_FILE) and os.path.exists(PATHS_FILE):\n",
    "    all_embeddings = np.load(EMBED_FILE)\n",
    "    all_files = np.load(PATHS_FILE, allow_pickle=True).tolist()\n",
    "    print(f\"âœ… Loaded embeddings: {all_embeddings.shape}\")\n",
    "    print(f\"âœ… Loaded image paths: {len(all_files)}\")\n",
    "else:\n",
    "    all_embeddings = []\n",
    "    all_files = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(image_paths), BATCH_SIZE)):\n",
    "            batch_paths = image_paths[i:i+BATCH_SIZE]\n",
    "            images = []\n",
    "            for path in batch_paths:\n",
    "                try:\n",
    "                    img = Image.open(path).convert(\"RGB\")\n",
    "                    images.append(img)\n",
    "                    all_files.append(path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Skip: {path} ({e})\")\n",
    "            if not images:\n",
    "                continue\n",
    "            inputs = processor(images=images, return_tensors=\"pt\").to(device)\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "            # outputs.hidden_states is a tuple: (layer_0, ..., layer_N)\n",
    "            # Use the last layer's [CLS] token or mean-pool all tokens (recommended for ViT)\n",
    "            last_hidden = outputs.hidden_states[-1]  # [batch, seq, dim]\n",
    "            feats = last_hidden.mean(dim=1).cpu().numpy()\n",
    "            all_embeddings.append(feats)\n",
    "\n",
    "    all_embeddings = np.vstack(all_embeddings)\n",
    "    assert all_embeddings.shape[0] == len(all_files), \"Some images were skipped unexpectedly.\"\n",
    "    print(\"âœ… Extracted embeddings shape:\", all_embeddings.shape)\n",
    "    np.save(EMBED_FILE, all_embeddings)\n",
    "    np.save(PATHS_FILE, np.array(all_files))\n",
    "    print(f\"ðŸ’¾ Saved embeddings and image paths to disk as {EMBED_FILE}, {PATHS_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ad5d690-1e4d-4d55-baea-e31dae4fa7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Starting MiniBatchKMeans clustering...\n",
      "Init 1/10 with method random\n",
      "Inertia for init 1/10: 225331920.0\n",
      "Init 2/10 with method random\n",
      "Inertia for init 2/10: 242456064.0\n",
      "Init 3/10 with method random\n",
      "Inertia for init 3/10: 183423856.0\n",
      "Init 4/10 with method random\n",
      "Inertia for init 4/10: 187563840.0\n",
      "Init 5/10 with method random\n",
      "Inertia for init 5/10: 204947136.0\n",
      "Init 6/10 with method random\n",
      "Inertia for init 6/10: 179880256.0\n",
      "Init 7/10 with method random\n",
      "Inertia for init 7/10: 223376432.0\n",
      "Init 8/10 with method random\n",
      "Inertia for init 8/10: 202090608.0\n",
      "Init 9/10 with method random\n",
      "Inertia for init 9/10: 183129440.0\n",
      "Init 10/10 with method random\n",
      "Inertia for init 10/10: 195172272.0\n",
      "Minibatch step 1/3027: mean batch inertia: 57913.8828125\n",
      "Minibatch step 2/3027: mean batch inertia: 35938.33984375, ewa inertia: 35938.33984375\n",
      "Minibatch step 3/3027: mean batch inertia: 33940.296875, ewa inertia: 35806.352874747\n",
      "Minibatch step 4/3027: mean batch inertia: 34400.15625, ewa inertia: 35713.462164574375\n",
      "Minibatch step 5/3027: mean batch inertia: 33854.51171875, ewa inertia: 35590.663386615845\n",
      "Minibatch step 6/3027: mean batch inertia: 34248.53515625, ewa inertia: 35502.004914345765\n",
      "Minibatch step 7/3027: mean batch inertia: 33735.078125, ewa inertia: 35385.28504644329\n",
      "Minibatch step 8/3027: mean batch inertia: 33030.42578125, ewa inertia: 35229.72746249606\n",
      "Minibatch step 9/3027: mean batch inertia: 32892.34765625, ewa inertia: 35075.32453880507\n",
      "Minibatch step 10/3027: mean batch inertia: 33582.578125, ewa inertia: 34976.716511985964\n",
      "Minibatch step 11/3027: mean batch inertia: 34135.8828125, ewa inertia: 34921.17261570021\n",
      "Minibatch step 12/3027: mean batch inertia: 33562.30859375, ewa inertia: 34831.408608444326\n",
      "Minibatch step 13/3027: mean batch inertia: 33842.32421875, ewa inertia: 34766.07154976955\n",
      "Minibatch step 14/3027: mean batch inertia: 33052.96875, ewa inertia: 34652.90719361279\n",
      "Minibatch step 15/3027: mean batch inertia: 33875.95703125, ewa inertia: 34601.583323906016\n",
      "Minibatch step 16/3027: mean batch inertia: 33350.28125, ewa inertia: 34518.92465708798\n",
      "Minibatch step 17/3027: mean batch inertia: 33653.49609375, ewa inertia: 34461.756070250696\n",
      "Minibatch step 18/3027: mean batch inertia: 33280.078125, ewa inertia: 34383.696642715506\n",
      "Minibatch step 19/3027: mean batch inertia: 33434.390625, ewa inertia: 34320.987268645855\n",
      "Minibatch step 20/3027: mean batch inertia: 32215.26171875, ewa inertia: 34181.88699040869\n",
      "Minibatch step 21/3027: mean batch inertia: 33832.875, ewa inertia: 34158.83191327561\n",
      "Minibatch step 22/3027: mean batch inertia: 33107.671875, ewa inertia: 34089.39425374626\n",
      "Minibatch step 23/3027: mean batch inertia: 32969.4765625, ewa inertia: 34015.41459269176\n",
      "Minibatch step 24/3027: mean batch inertia: 33464.60546875, ewa inertia: 33979.029175608484\n",
      "Minibatch step 25/3027: mean batch inertia: 33567.35546875, ewa inertia: 33951.83478307724\n",
      "Minibatch step 26/3027: mean batch inertia: 32563.064453125, ewa inertia: 33860.095221236705\n",
      "Minibatch step 27/3027: mean batch inertia: 33185.98046875, ewa inertia: 33815.56446572618\n",
      "Minibatch step 28/3027: mean batch inertia: 33523.80078125, ewa inertia: 33796.29110425125\n",
      "Minibatch step 29/3027: mean batch inertia: 33612.84375, ewa inertia: 33784.17291628535\n",
      "Minibatch step 30/3027: mean batch inertia: 33211.86328125, ewa inertia: 33746.36721578694\n",
      "Minibatch step 31/3027: mean batch inertia: 34721.0, ewa inertia: 33810.749628523394\n",
      "Minibatch step 32/3027: mean batch inertia: 34734.2109375, ewa inertia: 33871.75174963374\n",
      "Minibatch step 33/3027: mean batch inertia: 33296.5703125, ewa inertia: 33833.7563432779\n",
      "Minibatch step 34/3027: mean batch inertia: 33160.984375, ewa inertia: 33789.31428957234\n",
      "Minibatch step 35/3027: mean batch inertia: 32845.32421875, ewa inertia: 33726.95607697859\n",
      "Minibatch step 36/3027: mean batch inertia: 33298.25390625, ewa inertia: 33698.636816079576\n",
      "Minibatch step 37/3027: mean batch inertia: 31815.62890625, ewa inertia: 33574.24884719492\n",
      "Minibatch step 38/3027: mean batch inertia: 32726.03515625, ewa inertia: 33518.21744252262\n",
      "Minibatch step 39/3027: mean batch inertia: 32899.234375, ewa inertia: 33477.32858266111\n",
      "Minibatch step 40/3027: mean batch inertia: 33860.0078125, ewa inertia: 33502.60765445126\n",
      "Minibatch step 41/3027: mean batch inertia: 32723.521484375, ewa inertia: 33451.14268408336\n",
      "Minibatch step 42/3027: mean batch inertia: 33275.6171875, ewa inertia: 33439.547799168904\n",
      "Minibatch step 43/3027: mean batch inertia: 33125.0859375, ewa inertia: 33418.775038703854\n",
      "Minibatch step 44/3027: mean batch inertia: 32824.16796875, ewa inertia: 33379.49641149792\n",
      "Minibatch step 45/3027: mean batch inertia: 32706.828125, ewa inertia: 33335.061206816186\n",
      "Minibatch step 46/3027: mean batch inertia: 33702.23828125, ewa inertia: 33359.316235311504\n",
      "Minibatch step 47/3027: mean batch inertia: 34227.640625, ewa inertia: 33416.67611500321\n",
      "Minibatch step 48/3027: mean batch inertia: 33285.95703125, ewa inertia: 33408.04105763694\n",
      "Minibatch step 49/3027: mean batch inertia: 33227.5625, ewa inertia: 33396.11898280417\n",
      "Minibatch step 50/3027: mean batch inertia: 32880.77734375, ewa inertia: 33362.07648121455\n",
      "Minibatch step 51/3027: mean batch inertia: 33563.8515625, ewa inertia: 33375.40536443464\n",
      "Minibatch step 52/3027: mean batch inertia: 33120.90625, ewa inertia: 33358.59363052624\n",
      "Minibatch step 53/3027: mean batch inertia: 32939.42578125, ewa inertia: 33330.904189010325\n",
      "Minibatch step 54/3027: mean batch inertia: 33359.8046875, ewa inertia: 33332.81330170609\n",
      "Minibatch step 55/3027: mean batch inertia: 33427.76953125, ewa inertia: 33339.0859320356\n",
      "Minibatch step 56/3027: mean batch inertia: 32615.162109375, ewa inertia: 33291.264882820724\n",
      "Minibatch step 57/3027: mean batch inertia: 33250.5078125, ewa inertia: 33288.572547239746\n",
      "Minibatch step 58/3027: mean batch inertia: 34182.24609375, ewa inertia: 33347.606944661056\n",
      "Minibatch step 59/3027: mean batch inertia: 32540.33203125, ewa inertia: 33294.27987880724\n",
      "Minibatch step 60/3027: mean batch inertia: 34711.46875, ewa inertia: 33387.8967161521\n",
      "Minibatch step 61/3027: mean batch inertia: 33616.7109375, ewa inertia: 33403.01175422327\n",
      "Minibatch step 62/3027: mean batch inertia: 33609.421875, ewa inertia: 33416.64681945407\n",
      "Minibatch step 63/3027: mean batch inertia: 34217.65625, ewa inertia: 33469.55999926757\n",
      "Minibatch step 64/3027: mean batch inertia: 33221.2421875, ewa inertia: 33453.15659061357\n",
      "Minibatch step 65/3027: mean batch inertia: 33879.3203125, ewa inertia: 33481.308166345705\n",
      "Minibatch step 66/3027: mean batch inertia: 32551.29296875, ewa inertia: 33419.87310765216\n",
      "Minibatch step 67/3027: mean batch inertia: 33290.546875, ewa inertia: 33411.330059415806\n",
      "Converged (lack of improvement in inertia) at step 67/3027\n",
      "âœ… MiniBatchKMeans done in 0.42 sec\n"
     ]
    }
   ],
   "source": [
    "# ========== 4. MINI-BATCH KMEANS CLUSTERING ==========\n",
    "print(\"â³ Starting MiniBatchKMeans clustering...\")\n",
    "start = time.perf_counter()\n",
    "\n",
    "kmeans = MiniBatchKMeans(\n",
    "    n_clusters=N_CLUSTERS,\n",
    "    batch_size=1024,\n",
    "    max_iter=100,\n",
    "    n_init=CLUSTER_N_INIT,\n",
    "    init=\"random\",\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "cluster_labels = kmeans.fit_predict(all_embeddings)\n",
    "\n",
    "end = time.perf_counter()\n",
    "print(f\"âœ… MiniBatchKMeans done in {end - start:.2f} sec\")\n",
    "np.save(f\"{OUT_PREFIX}_cluster_labels.npy\", cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8714d68d-877e-4b2b-b892-83598b559f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ–¼ï¸ Saved TSNE visualization to ./V16_unsup_20250604_142640/V16_unsup_20250604_142640_temp_autogluon_images_clusters20_kl0.55_eu98_tsne.png\n"
     ]
    }
   ],
   "source": [
    "# ========== 5. CLUSTER VISUALIZATION (t-SNE/UMAP, subsampled) ==========\n",
    "def visualize_embeddings(embeddings, cluster_labels, method=\"tsne\", out_path=\"embedding_grid.png\", subsample=T_SNE_SUBSAMPLE):\n",
    "    n_points = embeddings.shape[0]\n",
    "    if n_points > subsample:\n",
    "        idx = np.random.choice(n_points, subsample, replace=False)\n",
    "        emb = embeddings[idx]\n",
    "        lbl = np.array(cluster_labels)[idx]\n",
    "    else:\n",
    "        emb = embeddings\n",
    "        lbl = np.array(cluster_labels)\n",
    "    if method == \"tsne\":\n",
    "        reducer = TSNE(n_components=2, perplexity=50, random_state=42)\n",
    "    elif method == \"umap\" and HAVE_UMAP:\n",
    "        reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "    else:\n",
    "        print(\"Unknown or unavailable method; using t-SNE.\")\n",
    "        reducer = TSNE(n_components=2, perplexity=50, random_state=42)\n",
    "    coords = reducer.fit_transform(emb)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    for k in range(N_CLUSTERS):\n",
    "        mask = (lbl == k)\n",
    "        plt.scatter(coords[mask, 0], coords[mask, 1], s=7, alpha=0.7, label=f\"C{k}\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"{V13_MODEL_PATH} SSL {method.upper()} by cluster\")\n",
    "    plt.savefig(out_path)\n",
    "    print(f\"ðŸ–¼ï¸ Saved {method.upper()} visualization to {out_path}\")\n",
    "    plt.close()\n",
    "\n",
    "visualize_embeddings(\n",
    "    all_embeddings, cluster_labels,\n",
    "    method=\"tsne\",\n",
    "    out_path=f\"{OUT_PREFIX}_tsne.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe7e5395-cfd0-4462-a624-8a0442ef28bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flagged 621 outlier images by Euclidean distance.\n"
     ]
    }
   ],
   "source": [
    "# ========== 6. EUCLIDEAN OUTLIER DETECTION ==========\n",
    "distances = np.linalg.norm(all_embeddings - kmeans.cluster_centers_[cluster_labels], axis=1)\n",
    "distance_threshold = np.percentile(distances, EUCLIDEAN_OUTLIER_PERCENTILE)\n",
    "euclid_outlier_indices = np.where(distances > distance_threshold)[0]\n",
    "print(f\"Flagged {len(euclid_outlier_indices)} outlier images by Euclidean distance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dedc0338-e67c-4a06-b922-76e00d22850d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flagged 3019 OOD images by KL-divergence.\n"
     ]
    }
   ],
   "source": [
    "# ========== 7. KL-DIVERGENCE OOD DETECTION ==========\n",
    "def compute_kl_divergence(feats, cluster_centers, labels):\n",
    "    kl_scores = []\n",
    "    for f, lbl in zip(feats, labels):\n",
    "        p = torch.softmax(torch.tensor(f), dim=0)\n",
    "        q = torch.softmax(torch.tensor(cluster_centers[lbl]), dim=0)\n",
    "        kl = torch.sum(p * torch.log((p + 1e-8) / (q + 1e-8))).item()\n",
    "        kl_scores.append(kl)\n",
    "    return kl_scores\n",
    "\n",
    "kl_scores = compute_kl_divergence(all_embeddings, kmeans.cluster_centers_, cluster_labels)\n",
    "kl_outlier_indices = np.where(np.array(kl_scores) > KL_OOD_THRESHOLD)[0]\n",
    "print(f\"Flagged {len(kl_outlier_indices)} OOD images by KL-divergence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de4f7e5b-4b0b-4480-80ee-b25328b97746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved pseudo-labels and OOD flags to ./V16_unsup_20250604_142640/V16_unsup_20250604_142640_temp_autogluon_images_clusters20_kl0.55_eu98_ssl_pseudolabels.csv\n"
     ]
    }
   ],
   "source": [
    "# ========== 8. SAVE LABELS/OUTLIERS ==========\n",
    "out_csv = f\"{OUT_PREFIX}_ssl_pseudolabels.csv\"\n",
    "with open(out_csv, \"w\") as f:\n",
    "    f.write(\"path,cluster,euclid_dist,kl,euclid_ood,kl_ood\\n\")\n",
    "    for idx, (p, c, dist, kl) in enumerate(zip(all_files, cluster_labels, distances, kl_scores)):\n",
    "        euclid_flag = int(idx in euclid_outlier_indices)\n",
    "        kl_flag = int(idx in kl_outlier_indices)\n",
    "        f.write(f\"{p},{c},{dist:.3f},{kl:.3f},{euclid_flag},{kl_flag}\\n\")\n",
    "print(f\"âœ… Saved pseudo-labels and OOD flags to {out_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ed9b5a1-87e0-4409-941c-44111f28f047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 1524 samples\n",
      "Cluster 1: 2085 samples\n",
      "Cluster 2: 2374 samples\n",
      "Cluster 3: 850 samples\n",
      "Cluster 4: 790 samples\n",
      "Cluster 5: 1055 samples\n",
      "Cluster 6: 2324 samples\n",
      "Cluster 7: 984 samples\n",
      "Cluster 8: 2694 samples\n",
      "Cluster 9: 1263 samples\n",
      "Cluster 10: 1371 samples\n",
      "Cluster 11: 1509 samples\n",
      "Cluster 12: 1579 samples\n",
      "Cluster 13: 658 samples\n",
      "Cluster 14: 2371 samples\n",
      "Cluster 15: 1505 samples\n",
      "Cluster 16: 599 samples\n",
      "Cluster 17: 1728 samples\n",
      "Cluster 18: 1071 samples\n",
      "Cluster 19: 2668 samples\n"
     ]
    }
   ],
   "source": [
    "# ========== 9. PER-CLUSTER REPORT ==========\n",
    "for c in range(N_CLUSTERS):\n",
    "    cluster_indices = np.where(cluster_labels == c)[0]\n",
    "    print(f\"Cluster {c}: {len(cluster_indices)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "364613b4-0941-48eb-bc96-bcbb68195b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OOD (junk) images symlinked to ./V16_unsup_20250604_142640/V16_unsup_20250604_142640_ood_flagged\n"
     ]
    }
   ],
   "source": [
    "# ========== 10. SAVE OOD/JUNK FILES ==========\n",
    "OOD_DIR = os.path.join(SAVE_DIR, f\"{VERSION_TAG}_ood_flagged\")\n",
    "os.makedirs(OOD_DIR, exist_ok=True)\n",
    "for idx in set(list(euclid_outlier_indices) + list(kl_outlier_indices)):\n",
    "    src = all_files[idx]\n",
    "    try:\n",
    "        fname = os.path.basename(src)\n",
    "        os.symlink(src, os.path.join(OOD_DIR, fname))\n",
    "    except FileExistsError:\n",
    "        continue\n",
    "\n",
    "print(f\"âœ… OOD (junk) images symlinked to {OOD_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b57d4a8d-d9f9-413d-88e6-06bfef1ccb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 00: 1524 total, 40 centroid faces exported\n",
      "Cluster 01: 2085 total, 40 centroid faces exported\n",
      "Cluster 02: 2374 total, 40 centroid faces exported\n",
      "Cluster 03: 850 total, 40 centroid faces exported\n",
      "Cluster 04: 790 total, 40 centroid faces exported\n",
      "Cluster 05: 1055 total, 40 centroid faces exported\n",
      "Cluster 06: 2324 total, 40 centroid faces exported\n",
      "Cluster 07: 984 total, 40 centroid faces exported\n",
      "Cluster 08: 2694 total, 40 centroid faces exported\n",
      "Cluster 09: 1263 total, 40 centroid faces exported\n",
      "Cluster 10: 1371 total, 40 centroid faces exported\n",
      "Cluster 11: 1509 total, 40 centroid faces exported\n",
      "Cluster 12: 1579 total, 40 centroid faces exported\n",
      "Cluster 13: 658 total, 40 centroid faces exported\n",
      "Cluster 14: 2371 total, 40 centroid faces exported\n",
      "Cluster 15: 1505 total, 40 centroid faces exported\n",
      "Cluster 16: 599 total, 40 centroid faces exported\n",
      "Cluster 17: 1728 total, 40 centroid faces exported\n",
      "Cluster 18: 1071 total, 40 centroid faces exported\n",
      "Cluster 19: 2668 total, 40 centroid faces exported\n",
      "âœ… Cluster browser and centroid faces exported to ./V16_unsup_20250604_142640/V16_unsup_20250604_142640_cluster_browser/cluster_##/ and centroid_faces/\n"
     ]
    }
   ],
   "source": [
    "# ========== 11. CLUSTER EXPLORER & CENTROID FACES ==========\n",
    "N_PER_CENTROID = 40   # Or adjust to your preferred # of centroids per cluster\n",
    "CLUSTER_BROWSER_ROOT = os.path.join(SAVE_DIR, f\"{VERSION_TAG}_cluster_browser\")\n",
    "\n",
    "centroids = np.vstack([\n",
    "    all_embeddings[cluster_labels == c].mean(axis=0)\n",
    "    for c in range(N_CLUSTERS)\n",
    "])\n",
    "\n",
    "for c in range(N_CLUSTERS):\n",
    "    cdir = os.path.join(CLUSTER_BROWSER_ROOT, f\"cluster_{c:02d}\")\n",
    "    centroids_dir = os.path.join(cdir, \"centroid_faces\")\n",
    "    os.makedirs(cdir, exist_ok=True)\n",
    "    os.makedirs(centroids_dir, exist_ok=True)\n",
    "    indices = np.where(cluster_labels == c)[0]\n",
    "    if len(indices) == 0:\n",
    "        continue\n",
    "    # 1. Symlink/copy all cluster images\n",
    "    for idx in indices:\n",
    "        src = all_files[idx]\n",
    "        dst = os.path.join(cdir, os.path.basename(src))\n",
    "        try:\n",
    "            os.symlink(src, dst)\n",
    "        except FileExistsError:\n",
    "            continue\n",
    "        except OSError:\n",
    "            shutil.copy(src, dst)\n",
    "    # 2. Find and symlink/copy centroid images\n",
    "    c_embeds = all_embeddings[indices]\n",
    "    dists = np.linalg.norm(c_embeds - centroids[c], axis=1)\n",
    "    sorted_idx = np.argsort(dists)\n",
    "    chosen = indices[sorted_idx[:N_PER_CENTROID]]\n",
    "    for idx in chosen:\n",
    "        src = all_files[idx]\n",
    "        dst = os.path.join(centroids_dir, os.path.basename(src))\n",
    "        try:\n",
    "            os.symlink(src, dst)\n",
    "        except FileExistsError:\n",
    "            continue\n",
    "        except OSError:\n",
    "            shutil.copy(src, dst)\n",
    "    print(f\"Cluster {c:02d}: {len(indices)} total, {len(chosen)} centroid faces exported\")\n",
    "\n",
    "print(f\"âœ… Cluster browser and centroid faces exported to {CLUSTER_BROWSER_ROOT}/cluster_##/ and centroid_faces/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243c6e3c-a9ae-4eb2-83ce-4acbefde499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 12. V13 PREDICTION EXTRACTION FOR ALL IMAGES ==========\n",
    "\n",
    "# Store logits and predict V13 softmax for all images\n",
    "all_logits = []\n",
    "all_probs = []\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(all_files), BATCH_SIZE), desc=\"V13 Prediction Extraction\"):\n",
    "        batch_paths = all_files[i:i+BATCH_SIZE]\n",
    "        images = []\n",
    "        for path in batch_paths:\n",
    "            try:\n",
    "                img = Image.open(path).convert(\"RGB\")\n",
    "                images.append(img)\n",
    "            except Exception as e:\n",
    "                print(f\"Skip: {path} ({e})\")\n",
    "        if not images:\n",
    "            continue\n",
    "        inputs = processor(images=images, return_tensors=\"pt\").to(model.device)\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits.cpu().numpy()\n",
    "        probs = torch.softmax(torch.tensor(logits), dim=1).numpy()\n",
    "        all_logits.append(logits)\n",
    "        all_probs.append(probs)\n",
    "\n",
    "all_logits = np.vstack(all_logits)\n",
    "all_probs = np.vstack(all_probs)\n",
    "np.save(os.path.join(SAVE_DIR, \"v13_logits.npy\"), all_logits)\n",
    "np.save(os.path.join(SAVE_DIR, \"v13_probs.npy\"), all_probs)\n",
    "print(\"âœ… Saved V13 logits/probabilities for all images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ab9739-6371-415d-b3d7-a5620c4bb0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 13. LABEL CONSISTENCY HEATMAP ==========\n",
    "\n",
    "# V13_preds = np.argmax(V13_probs, axis=1)\n",
    "n_clusters = np.max(cluster_labels) + 1\n",
    "n_labels = len(id2label)  # As defined at top\n",
    "\n",
    "cluster_label_counts = np.zeros((n_clusters, n_labels), dtype=int)\n",
    "for cl, lab in zip(cluster_labels, V13_preds):\n",
    "    cluster_label_counts[cl, lab] += 1\n",
    "\n",
    "cluster_label_perc = cluster_label_counts / cluster_label_counts.sum(axis=1, keepdims=True)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.heatmap(cluster_label_perc, annot=True, fmt=\".2f\", xticklabels=LABEL_NAMES, yticklabels=[f\"C{k}\" for k in range(n_clusters)])\n",
    "plt.xlabel(\"V13 Predicted Label\")\n",
    "plt.ylabel(\"Cluster\")\n",
    "plt.title(\"Cluster Label Consistency Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SAVE_DIR, f\"{VERSION_TAG}_cluster_label_heatmap.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37f9f3d-a9d5-40b3-9d2b-d72a2d9057b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 14. CLUSTER ENTROPY BARPLOT ==========\n",
    "entropy_per_image = entropy(V13_probs, axis=1)\n",
    "avg_entropy_per_cluster = [\n",
    "    np.mean(entropy_per_image[cluster_labels == k])\n",
    "    for k in range(n_clusters)\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(range(n_clusters), avg_entropy_per_cluster)\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Avg Entropy\")\n",
    "plt.title(\"Mean Prediction Entropy per Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SAVE_DIR, f\"{VERSION_TAG}_cluster_entropy_barplot.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d574a3-1ff6-4c95-8de4-8099d562455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 15. CLUSTER REFINEMENT: REMOVE LOW-CONFIDENCE SAMPLES ==========\n",
    "CONFIDENCE_THRESH = 0.80\n",
    "\n",
    "pred_confidences = all_probs.max(axis=1)\n",
    "keep_mask = pred_confidences >= CONFIDENCE_THRESH\n",
    "\n",
    "# Filter arrays\n",
    "refined_embeddings = all_embeddings[keep_mask]\n",
    "refined_files = [all_files[i] for i, keep in enumerate(keep_mask) if keep]\n",
    "refined_cluster_labels = cluster_labels[keep_mask]\n",
    "refined_probs = all_probs[keep_mask]\n",
    "refined_preds = np.argmax(refined_probs, axis=1)\n",
    "print(f\"Retained {len(refined_files)}/{len(all_files)} images with confidence >= {CONFIDENCE_THRESH:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf89e3-b082-4f24-9e3c-b06e3fe9d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 16. KMEANS ON PCA-REDUCED EMBEDDINGS ==========\n",
    "PCA_DIM = 64\n",
    "pca = PCA(n_components=PCA_DIM, random_state=42)\n",
    "pca_embeds = pca.fit_transform(refined_embeddings)\n",
    "\n",
    "kmeans_pca = MiniBatchKMeans(\n",
    "    n_clusters=N_CLUSTERS,\n",
    "    batch_size=1024,\n",
    "    max_iter=100,\n",
    "    n_init=CLUSTER_N_INIT,\n",
    "    init=\"random\",\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "refined_cluster_labels_pca = kmeans_pca.fit_predict(pca_embeds)\n",
    "np.save(os.path.join(SAVE_DIR, \"refined_pca_cluster_labels.npy\"), refined_cluster_labels_pca)\n",
    "print(\"âœ… KMeans on PCA-reduced, confidence-filtered embeddings complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b728c603-4a08-439a-9620-639d341fd02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 17. SUMMARY/EXPORT/README ==========\n",
    "summary_path = os.path.join(SAVE_DIR, \"run_summary.md\")\n",
    "with open(summary_path, \"w\") as f:\n",
    "    f.write(f\"# V17_unsup Run Summary\\n\")\n",
    "    f.write(f\"Date: {datetime.datetime.now()}\\n\\n\")\n",
    "    f.write(f\"Model: {V13_MODEL_PATH}\\n\")\n",
    "    f.write(f\"Image Dir: {IMAGE_DIR}\\n\")\n",
    "    f.write(f\"Num Images: {len(all_files)}\\n\")\n",
    "    f.write(f\"Num Clusters: {N_CLUSTERS}\\n\")\n",
    "    f.write(f\"Confidence threshold: {CONFIDENCE_THRESH}\\n\")\n",
    "    f.write(f\"Kept after filtering: {len(refined_files)} images\\n\\n\")\n",
    "\n",
    "    # (Add confusion/purity stats here as you compute them)\n",
    "    f.write(\"## Cluster Sizes (after refinement):\\n\")\n",
    "    unique, counts = np.unique(refined_cluster_labels, return_counts=True)\n",
    "    for cid, sz in zip(unique, counts):\n",
    "        f.write(f\"- Cluster {cid}: {sz} images\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    # If you have cluster entropy/purity, include those stats as well.\n",
    "\n",
    "    f.write(\"\\n## Next Steps\\n- Review high-entropy clusters\\n- Use pure clusters for semi-supervised fine-tuning\\n\")\n",
    "print(f\"âœ… Summary file written to {summary_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_unsupervised)",
   "language": "python",
   "name": "ml_unsupervised"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
