{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81ebb98-d7e5-4b56-bfd7-f1f40c00acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V9 changes: \n",
    "    # section 2 - create_review_queue updated renamed to certainty_review_queue\n",
    "\n",
    "def analyze_video_with_filters(video_path, save_dir, emotion_model, gatekeeper_model, processor, device, static_threshold, process_every_n_frames=1):\n",
    "    \"\"\"\n",
    "    Processes video with all filters, including a corrected static object filter.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"❌ Error: Video file not found at {video_path}\")\n",
    "        return []\n",
    "\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = video_capture.get(cv2.CAP_PROP_FPS) if video_capture.get(cv2.CAP_PROP_FPS) > 0 else 30\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        print(\"❌ Error: Could not read the first frame.\")\n",
    "        return []\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "    video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    print(f\"✅ Opened video: {os.path.basename(video_path)} ({total_frames} frames at {fps:.2f} fps)\")\n",
    "\n",
    "    face_crop_dir = os.path.join(save_dir, \"face_crops\")\n",
    "    os.makedirs(face_crop_dir, exist_ok=True)\n",
    "    \n",
    "    static_object_tracker, ignored_locations = {}, set()\n",
    "    known_face_encodings, known_face_ids = [], []\n",
    "    next_person_id = 1\n",
    "    all_results_log = []\n",
    "    \n",
    "    pbar = tqdm(total=total_frames, desc=\"Analyzing Video\")\n",
    "\n",
    "    for frame_count in range(total_frames):\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret: break\n",
    "\n",
    "        if frame_count % process_every_n_frames == 0:\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            face_locations = face_recognition.face_locations(rgb_frame)\n",
    "            current_face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "            current_frame_locations = set(face_locations)\n",
    "\n",
    "            if current_face_encodings:\n",
    "                for i, face_encoding in enumerate(current_face_encodings):\n",
    "                    top, right, bottom, left = face_locations[i]\n",
    "                    loc_key = (top, right, bottom, left)\n",
    "                    \n",
    "                    # --- PADDED FACE CROPPING LOGIC (MOVED TO CORRECT LOCATION) ---\n",
    "                    face_height = bottom - top\n",
    "                    face_width = right - left\n",
    "                    v_pad = int(face_height * 0.40)\n",
    "                    h_pad = int(face_width * 0.15)\n",
    "                    top_pad = max(0, top - v_pad)\n",
    "                    bottom_pad = min(frame_height, bottom + int(v_pad * 0.1))\n",
    "                    left_pad = max(0, left - h_pad)\n",
    "                    right_pad = min(frame_width, right + h_pad)\n",
    "                    face_image = Image.fromarray(rgb_frame[top_pad:bottom_pad, left_pad:right_pad])\n",
    "                    \n",
    "                    # --- Static Object Filter ---\n",
    "                    if loc_key in ignored_locations: continue\n",
    "                    if loc_key not in static_object_tracker:\n",
    "                        static_object_tracker[loc_key] = {\"count\": 1, \"last_frame\": frame_count}\n",
    "                    else:\n",
    "                        if frame_count == static_object_tracker[loc_key][\"last_frame\"] + process_every_n_frames:\n",
    "                            static_object_tracker[loc_key][\"count\"] += 1\n",
    "                        else:\n",
    "                            static_object_tracker[loc_key][\"count\"] = 1\n",
    "                        static_object_tracker[loc_key][\"last_frame\"] = frame_count\n",
    "                    if static_object_tracker[loc_key][\"count\"] > static_threshold:\n",
    "                        if loc_key not in ignored_locations:\n",
    "                            ignored_locations.add(loc_key)\n",
    "                        continue\n",
    "\n",
    "                    # --- Gatekeeper Filter ---\n",
    "                    gatekeeper_inputs = processor(images=face_image, return_tensors=\"pt\").to(device)\n",
    "                    with torch.no_grad():\n",
    "                        gatekeeper_logits = gatekeeper_model(**gatekeeper_inputs).logits\n",
    "                    gatekeeper_pred = gatekeeper_model.config.id2label[gatekeeper_logits.argmax(-1).item()]\n",
    "                    \n",
    "                    if \"Non-Emotional\" in gatekeeper_pred:\n",
    "                        continue\n",
    "\n",
    "                    # --- Face Identification ---\n",
    "                    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "                    person_id = \"Unknown\"\n",
    "                    if True in matches:\n",
    "                        person_id = known_face_ids[matches.index(True)]\n",
    "                    else:\n",
    "                        person_id = f\"Person_{next_person_id}\"\n",
    "                        known_face_encodings.append(face_encoding)\n",
    "                        known_face_ids.append(person_id)\n",
    "                        next_person_id += 1\n",
    "                    \n",
    "                    # --- Emotion Classification and Logging ---\n",
    "                    emotion_results = get_emotion_predictions(face_image, emotion_model, processor, device)\n",
    "                    face_filename = os.path.join(face_crop_dir, f\"frame_{frame_count}_{person_id}.png\")\n",
    "                    face_image.save(face_filename)\n",
    "                    \n",
    "                    log_entry = {\"timestamp\": frame_count / fps, \"person_id\": person_id, \"face_crop_path\": face_filename, **emotion_results}\n",
    "                    all_results_log.append(log_entry)\n",
    "            \n",
    "            stale_keys = [k for k in static_object_tracker if k not in current_frame_locations]\n",
    "            for k in stale_keys:\n",
    "                del static_object_tracker[k]\n",
    "                \n",
    "        pbar.update(1)\n",
    "        \n",
    "    pbar.close()\n",
    "    video_capture.release()\n",
    "    \n",
    "    print(\"\\n--- Video Processing Summary ---\")\n",
    "    print(f\"✅ Discovered {len(known_face_ids)} unique person(s).\")\n",
    "    print(f\"⚠️ Detected and ignored {len(ignored_locations)} static object(s).\")\n",
    "    print(f\"✅ Logged {len(all_results_log)} potentially emotional events.\")\n",
    "    \n",
    "    return all_results_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4c02768-e8ef-4d7c-a36f-11c6bf688f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcc2af65-36c5-43b1-a420-d40d16c60428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. CONFIGURATION\n",
    "# ==============================================================================\n",
    "ANALYSIS_OUTPUT_ROOT = \"/Users/natalyagrokh/AI/ml_expressions/img_expressions/data_flywheel\"\n",
    "\n",
    "# Find Top 200 most CERTAIN predictions\n",
    "TOP_N_TO_REVIEW = 200      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37ae3873-1cd0-4e94-9286-0deb3ca7a75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 2. UTILITY FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "#  Extracts integer version number (e.g., V1, V2) from directory name.\n",
    "def extract_version_from_path(path):\n",
    "    match = re.search(r\"V(\\d+)\", os.path.basename(path))\n",
    "    return int(match.group(1)) if match else -1\n",
    "\n",
    "# Analyzes log to find Top N most CERTAIN predictions (high confidence,\n",
    "    # low entropy) for ground-truth audit.\n",
    "def certainty_review_queue(log_df, run_dir, top_n, queue_name, description):\n",
    "    print(f\"\\n--- Creating Top-{top_n} Certainty Review Queue for '{description}' ---\")\n",
    "\n",
    "    if log_df.empty:\n",
    "        print(f\"⚠️ The log file for '{description}' is empty. Nothing to review.\")\n",
    "        return\n",
    "\n",
    "    # --- Step 1: Calculate a \"certainty score\" ---\n",
    "    # A higher score means higher confidence and lower entropy.\n",
    "    log_df['certainty_score'] = log_df['confidence'] - log_df['entropy']\n",
    " \n",
    "    # --- Step 2: Sort by the new score and take the top N ---\n",
    "    review_df = log_df.sort_values(by='certainty_score', ascending=False).head(top_n)\n",
    "    \n",
    "    print(f\"-> Selected the Top {len(review_df)} most certain images for review.\")\n",
    "    \n",
    "    # --- Step 3: Copy images and create the simplified CSV ---\n",
    "    review_folder_path = os.path.join(run_dir, queue_name)\n",
    "    os.makedirs(review_folder_path, exist_ok=True)\n",
    "    \n",
    "    copied_count = 0\n",
    "    for _, row in review_df.iterrows():\n",
    "        source_path = row.get('face_crop_path')\n",
    "        if source_path and os.path.exists(source_path):\n",
    "            try:\n",
    "                shutil.copy(source_path, review_folder_path)\n",
    "                copied_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Could not copy file {source_path}. Error: {e}\")\n",
    "        else:\n",
    "            print(f\"⚠️ File not found and could not be copied: {source_path}\")\n",
    "\n",
    "    print(f\"\\n✅ Success! Copied {copied_count} images to: {review_folder_path}\")\n",
    "    \n",
    "    # Step 4: Create and save the simplified, sortable CSV\n",
    "    if not review_df.empty:\n",
    "        # Select columns needed for review\n",
    "        simplified_df = review_df.copy().sort_values(by='frame_number').reset_index(drop=True)\n",
    "        \n",
    "        # Simplify the path to just the filename\n",
    "        simplified_df['face_crop_path'] = simplified_df['face_crop_path'].apply(os.path.basename)\n",
    "\n",
    "        # Add blank columns for your manual labels and notes\n",
    "        simplified_df['actual_label'] = \"\"\n",
    "        simplified_df['notes'] = \"\"\n",
    "        \n",
    "        # Select and reorder columns for the final sheet\n",
    "        final_columns = ['frame_number', 'face_crop_path', 'predicted_label', 'actual_label', 'notes', 'confidence', 'entropy', 'certainty_score']\n",
    "        simplified_df = simplified_df[final_columns]\n",
    "       \n",
    "        # Save the new CSV inside the manual_review_queue folder\n",
    "        simplified_csv_path = os.path.join(review_folder_path, \"simplified_review_log.csv\")\n",
    "        simplified_df.to_csv(simplified_csv_path, index=False)\n",
    "        print(f\"✅ Created a log for the certainty audit at: {simplified_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90fd866c-6a4b-470d-a944-ad6fef466490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Automatically analyzing latest run: V9_20250725_154347\n",
      "\n",
      "--- Creating Top-200 Certainty Review Queue for 'Micro-Expressions (from raw log)' ---\n",
      "-> Selected the Top 200 most certain images for review.\n",
      "\n",
      "✅ Success! Copied 200 images to: /Users/natalyagrokh/AI/ml_expressions/img_expressions/data_flywheel/V9_20250725_154347/certainty_micro_expression_review\n",
      "✅ Created a log for the certainty audit at: /Users/natalyagrokh/AI/ml_expressions/img_expressions/data_flywheel/V9_20250725_154347/certainty_micro_expression_review/simplified_review_log.csv\n",
      "\n",
      "--- Creating Top-200 Certainty Review Queue for 'Stable Emotions (from filtered log)' ---\n",
      "-> Selected the Top 200 most certain images for review.\n",
      "\n",
      "✅ Success! Copied 200 images to: /Users/natalyagrokh/AI/ml_expressions/img_expressions/data_flywheel/V9_20250725_154347/certainty_stable_emotion_review\n",
      "✅ Created a log for the certainty audit at: /Users/natalyagrokh/AI/ml_expressions/img_expressions/data_flywheel/V9_20250725_154347/certainty_stable_emotion_review/simplified_review_log.csv\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 3. MAIN EXECUTION BLOCK\n",
    "# ==============================================================================\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    all_run_dirs = [os.path.join(ANALYSIS_OUTPUT_ROOT, d) for d in os.listdir(ANALYSIS_OUTPUT_ROOT) if d.startswith(\"V\") and os.path.isdir(os.path.join(ANALYSIS_OUTPUT_ROOT, d))]\n",
    "\n",
    "    if not all_run_dirs:\n",
    "        print(f\"❌ Error: No run directories found in {ANALYSIS_OUTPUT_ROOT}\")\n",
    "    else:\n",
    "        latest_run_dir = max(all_run_dirs, key=extract_version_from_path)\n",
    "        print(f\"✅ Automatically analyzing latest run: {os.path.basename(latest_run_dir)}\")\n",
    "\n",
    "        # --- Define paths to both log files ---\n",
    "        raw_log_path = os.path.join(latest_run_dir, \"emotion_log_before_stability_filter.csv\")\n",
    "        stable_log_path = os.path.join(latest_run_dir, \"final_stable_emotion_log.csv\")\n",
    "\n",
    "        # --- Process Micro-Expressions from the RAW log ---\n",
    "        if os.path.exists(raw_log_path):\n",
    "            raw_log_df = pd.read_csv(raw_log_path)\n",
    "            certainty_review_queue(\n",
    "                log_df=raw_log_df,\n",
    "                run_dir=latest_run_dir,\n",
    "                top_n=TOP_N_TO_REVIEW,\n",
    "                queue_name=\"certainty_micro_expression_review\",\n",
    "                description=\"Micro-Expressions (from raw log)\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"❌ Error: Could not find raw log file: {raw_log_path}\")\n",
    "            \n",
    "        # --- Process Stable Emotions from the STABLE log ---\n",
    "        if os.path.exists(stable_log_path):\n",
    "            stable_log_df = pd.read_csv(stable_log_path)\n",
    "            certainty_review_queue(\n",
    "                log_df=stable_log_df,\n",
    "                run_dir=latest_run_dir,\n",
    "                top_n=TOP_N_TO_REVIEW,\n",
    "                queue_name=\"certainty_stable_emotion_review\",\n",
    "                description=\"Stable Emotions (from filtered log)\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"❌ Error: Could not find stable log file: {stable_log_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e67ddd-cdf1-4fcf-a363-3f851a73a4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_expressions",
   "language": "python",
   "name": "ml_expressions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
