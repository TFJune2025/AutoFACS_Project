{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1de2fbf6-25df-41c8-b92d-96cbd352c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "from facenet_pytorch import MTCNN\n",
    "from transformers import AutoModelForImageClassification, AutoImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97760ff7-fcf1-4baf-84a6-01c3862698ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Config\n",
    "# --------------------------\n",
    "model_path = \"/Users/natalyagrokh/AI/ml_expressions/img_expressions/V13_20250527_161430\"\n",
    "celeba_sample_dir = \"/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated\"\n",
    "TEMPERATURE_PATH = os.path.join(model_path, \"temperature_V13.txt\")\n",
    "NUM_IMAGES = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "744ebcb9-d6e2-4791-8a90-4a4abf7f6ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /Users/natalyagrokh/AI/ml_expressions/img_expressions/V13_20250527_161430 were not used when initializing ViTForImageClassification: ['classifier.1.bias', 'classifier.1.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at /Users/natalyagrokh/AI/ml_expressions/img_expressions/V13_20250527_161430 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Load model, processor, temp\n",
    "# --------------------------\n",
    "model = AutoModelForImageClassification.from_pretrained(model_path)\n",
    "processor = AutoImageProcessor.from_pretrained(model_path)\n",
    "id2label = model.config.id2label\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device).eval()\n",
    "\n",
    "with open(TEMPERATURE_PATH) as f:\n",
    "    TEMPERATURE = float(f.read().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1264336-ab0d-460d-9dcd-08bc599d0423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Face alignment\n",
    "# --------------------------\n",
    "mtcnn = MTCNN(image_size=224, post_process=True)\n",
    "\n",
    "def align_face(image):\n",
    "    aligned = mtcnn(image)\n",
    "    if aligned is None:\n",
    "        return image\n",
    "    return T.ToPILImage()(aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2172050-e4ee-4548-9e49-528aa93d5201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Inference with TTA\n",
    "# --------------------------\n",
    "def predict_with_metadata(image_path, num_aug=3):\n",
    "    image = align_face(Image.open(image_path).convert(\"RGB\"))\n",
    "    aug = T.Compose([T.RandomHorizontalFlip(), T.ColorJitter(0.2, 0.2, 0.2)])\n",
    "    probs_all = []\n",
    "\n",
    "    for _ in range(num_aug):\n",
    "        aug_img = aug(image)\n",
    "        inputs = processor(aug_img, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "            probs = F.softmax(logits / TEMPERATURE, dim=-1)\n",
    "            probs_all.append(probs)\n",
    "\n",
    "    final_probs = torch.mean(torch.stack(probs_all), dim=0).squeeze()\n",
    "    entropy = -torch.sum(final_probs * torch.log(final_probs + 1e-8)).item()\n",
    "    conf, pred_idx = torch.max(final_probs, dim=-1)\n",
    "    top3 = [(id2label[i.item()], round(final_probs[i].item(), 3)) for i in torch.topk(final_probs, 3).indices]\n",
    "    return id2label[pred_idx.item()], conf.item(), entropy, top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d33d21f6-8f2f-4b7e-a4ad-a4d24a144140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Inspecting 25 CelebA images with V13 model:\n",
      "\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/28_Sports_Fan_Sports_Fan_28_875.jpg_face1.jpg\n",
      "‚Üí Pred: surprise | Conf: 0.201 | Entropy: 2.048\n",
      "‚Üí Top3: [('surprise', 0.201), ('questioning', 0.131), ('sadness', 0.13)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/51_Dresses_wearingdress_51_204.jpg_face1.jpg\n",
      "‚Üí Pred: surprise | Conf: 0.196 | Entropy: 2.051\n",
      "‚Üí Top3: [('surprise', 0.196), ('questioning', 0.147), ('sadness', 0.125)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/49_Greeting_peoplegreeting_49_381.jpg_face2.jpg\n",
      "‚Üí Pred: surprise | Conf: 0.209 | Entropy: 2.038\n",
      "‚Üí Top3: [('surprise', 0.209), ('sadness', 0.147), ('questioning', 0.126)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/55_Sports_Coach_Trainer_sportcoaching_55_327.jpg_face2.jpg\n",
      "‚Üí Pred: surprise | Conf: 0.184 | Entropy: 2.045\n",
      "‚Üí Top3: [('surprise', 0.184), ('disgust', 0.16), ('fear', 0.139)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/21_Festival_Festival_21_84.jpg_face1.jpg\n",
      "‚Üí Pred: disgust | Conf: 0.155 | Entropy: 2.059\n",
      "‚Üí Top3: [('disgust', 0.155), ('surprise', 0.147), ('questioning', 0.138)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/30_Surgeons_Surgeons_30_347.jpg_face2.jpg\n",
      "‚Üí Pred: surprise | Conf: 0.201 | Entropy: 2.047\n",
      "‚Üí Top3: [('surprise', 0.201), ('sadness', 0.14), ('questioning', 0.131)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/40_Gymnastics_Gymnastics_40_729.jpg_face1.jpg\n",
      "‚Üí Pred: surprise | Conf: 0.190 | Entropy: 2.047\n",
      "‚Üí Top3: [('surprise', 0.19), ('sadness', 0.141), ('disgust', 0.138)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/30_Surgeons_Surgeons_30_149.jpg_face1.jpg\n",
      "‚Üí Pred: surprise | Conf: 0.188 | Entropy: 2.046\n",
      "‚Üí Top3: [('surprise', 0.188), ('disgust', 0.156), ('fear', 0.133)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/2_Demonstration_Protesters_2_69.jpg_face4.jpg\n",
      "‚Üí Pred: disgust | Conf: 0.174 | Entropy: 2.051\n",
      "‚Üí Top3: [('disgust', 0.174), ('sadness', 0.139), ('happiness', 0.131)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/33_Running_Running_33_577.jpg_face2.jpg\n",
      "‚Üí Pred: surprise | Conf: 0.193 | Entropy: 2.051\n",
      "‚Üí Top3: [('surprise', 0.193), ('sadness', 0.135), ('disgust', 0.135)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/2_Demonstration_Protesters_2_457.jpg_face2.jpg\n",
      "‚Üí Pred: surprise | Conf: 0.198 | Entropy: 2.039\n",
      "‚Üí Top3: [('surprise', 0.198), ('sadness', 0.15), ('disgust', 0.142)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/12_Group_Team_Organized_Group_12_Group_Team_Organized_Group_12_156.jpg_face3.jpg\n",
      "‚Üí Pred: surprise | Conf: 0.188 | Entropy: 2.051\n",
      "‚Üí Top3: [('surprise', 0.188), ('disgust', 0.15), ('questioning', 0.129)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/11_Meeting_Meeting_11_Meeting_Meeting_11_443.jpg_face5.jpg\n",
      "‚Üí Pred: surprise | Conf: 0.187 | Entropy: 2.047\n",
      "‚Üí Top3: [('surprise', 0.187), ('sadness', 0.157), ('disgust', 0.135)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/20_Family_Group_Family_Group_20_739.jpg_face2.jpg\n",
      "‚Üí Pred: surprise | Conf: 0.211 | Entropy: 2.040\n",
      "‚Üí Top3: [('surprise', 0.211), ('questioning', 0.138), ('sadness', 0.135)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/53_Raid_policeraid_53_490.jpg_face2.jpg\n",
      "‚Üí Pred: surprise | Conf: 0.189 | Entropy: 2.048\n",
      "‚Üí Top3: [('surprise', 0.189), ('disgust', 0.15), ('sadness', 0.133)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/40_Gymnastics_Gymnastics_40_523.jpg_face1.jpg\n",
      "‚Üí Pred: sadness | Conf: 0.178 | Entropy: 2.057\n",
      "‚Üí Top3: [('sadness', 0.178), ('disgust', 0.144), ('surprise', 0.139)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/29_Students_Schoolkids_Students_Schoolkids_29_180.jpg_face1.jpg\n",
      "‚Üí Pred: surprise | Conf: 0.148 | Entropy: 2.072\n",
      "‚Üí Top3: [('surprise', 0.148), ('questioning', 0.146), ('neutral', 0.136)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/40_Gymnastics_Gymnastics_40_250.jpg_face5.jpg\n",
      "‚Üí Pred: surprise | Conf: 0.200 | Entropy: 2.040\n",
      "‚Üí Top3: [('surprise', 0.2), ('sadness', 0.148), ('disgust', 0.146)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/40_Gymnastics_Gymnastics_40_165.jpg_face3.jpg\n",
      "‚Üí Pred: disgust | Conf: 0.176 | Entropy: 2.052\n",
      "‚Üí Top3: [('disgust', 0.176), ('surprise', 0.161), ('sadness', 0.136)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/12_Group_Group_12_Group_Group_12_587.jpg_face2.jpg\n",
      "‚Üí Pred: surprise | Conf: 0.191 | Entropy: 2.051\n",
      "‚Üí Top3: [('surprise', 0.191), ('questioning', 0.135), ('sadness', 0.135)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/15_Stock_Market_Stock_Market_15_65.jpg_face18.jpg\n",
      "‚Üí Pred: surprise | Conf: 0.191 | Entropy: 2.049\n",
      "‚Üí Top3: [('surprise', 0.191), ('disgust', 0.144), ('sadness', 0.138)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/25_Soldier_Patrol_Soldier_Patrol_25_1028.jpg_face2.jpg\n",
      "‚Üí Pred: fear | Conf: 0.152 | Entropy: 2.074\n",
      "‚Üí Top3: [('fear', 0.152), ('anger', 0.139), ('sadness', 0.125)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/56_Voter_peoplevoting_56_138.jpg_face1.jpg\n",
      "‚Üí Pred: surprise | Conf: 0.185 | Entropy: 2.054\n",
      "‚Üí Top3: [('surprise', 0.185), ('questioning', 0.138), ('sadness', 0.135)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/2_Demonstration_Demonstrators_2_682.jpg_face10.jpg\n",
      "‚Üí Pred: surprise | Conf: 0.196 | Entropy: 2.049\n",
      "‚Üí Top3: [('surprise', 0.196), ('sadness', 0.134), ('questioning', 0.132)]\n",
      "------------------------------------------------------------\n",
      "/Volumes/JavaAOT/Documents/AI/ml_expressions/img_datasets/wider_face_dataset_curated/12_Group_Team_Organized_Group_12_Group_Team_Organized_Group_12_10.jpg_face6.jpg\n",
      "‚Üí Pred: surprise | Conf: 0.206 | Entropy: 2.041\n",
      "‚Üí Top3: [('surprise', 0.206), ('disgust', 0.136), ('sadness', 0.136)]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Run on random sample\n",
    "# --------------------------\n",
    "all_images = [os.path.join(dp, f) for dp, _, fn in os.walk(celeba_sample_dir) for f in fn if f.lower().endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
    "sample_images = random.sample(all_images, min(NUM_IMAGES, len(all_images)))\n",
    "\n",
    "print(f\"üß™ Inspecting {len(sample_images)} CelebA images with V13 model:\\n\")\n",
    "\n",
    "for img_path in sample_images:\n",
    "    try:\n",
    "        label, conf, entropy, top3 = predict_with_metadata(img_path)\n",
    "        print(f\"{img_path}\")\n",
    "        print(f\"‚Üí Pred: {label} | Conf: {conf:.3f} | Entropy: {entropy:.3f}\")\n",
    "        print(f\"‚Üí Top3: {top3}\")\n",
    "        print(\"-\" * 60)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error on {img_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e596ce9a-1f5b-4533-8b75-da606d35555f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80df3536-89c0-4323-bd38-98f44b7182e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_expressions)",
   "language": "python",
   "name": "ml_expressions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
